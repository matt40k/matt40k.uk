{"data":{"posts":[{"id":18,"title":"Should I purchase Full SQL or is Express enough?","slug":"should-i-purchase-full-sql-or-is-express-enough","markdown":"\nOne of the common\u00a0questions I used to get asked whilst supporting [SIMS .net](http:\/\/www.capita-sims.co.uk\/) was, do I need Full SQL. [SIMS .net](http:\/\/www.capita-sims.co.uk\/) uses [Microsoft SQL Server](http:\/\/www.microsoft.com\/en-gb\/server-cloud\/products\/sql-server\/default.aspx)\u00a0as it\u2019s\u00a0relational database management system (RDBMS) so it\u2019s important to ensure the engine is correctly sized for job at hand. [Microsoft SQL Server](http:\/\/www.microsoft.com\/en-gb\/server-cloud\/products\/sql-server\/default.aspx) has come in a number of editions over the years, I won\u2019t detail all the various editions\u00a0but the two editions\u00a0schools should be concerned\u00a0with is Express and Standard. Express is the free edition\u00a0that [Capita ](http:\/\/www.capita-sims.co.uk\/)bundles as part of their installation media and Standard edition requires purchasing additional [Microsoft](http:\/\/www.microsoft.com\/) licenses.\n\nStandard edition can either be licensed by the number of processor (cores) or by users. I personally tend to go for processor licenses so I don\u2019t need to worry about buying new licenses when adding new users\u00a0later on down the road. It does\u00a0however come down to pricing \u2013 I tend to find processor licenses break even around the 30 user mark (based on Academic licensing anyway).\n\nSo why should you shell out of Standard edition? Now to be fair to [Capita](http:\/\/www.capita-sims.co.uk\/) a number of features that Standard has over Express, like SSIS and the SQL Agent [Capita](http:\/\/www.capita-sims.co.uk\/) has created tools to workaround the limitations, they\u2019ve created a data transfer tool to extract the data from the [SIMS .net](http:\/\/www.capita-sims.co.uk\/) database into the [SIMS Discover](http:\/\/www.capita-sims.co.uk\/our-products\/sims-discover-primary-schools-and-academies) database for example, they\u2019ve created routines within [SIMS .net](http:\/\/www.capita-sims.co.uk\/) to create Windows Scheduled \u00a0Tasks for SQL jobs like B2B. With that said, the one thing [Capita](http:\/\/www.capita-sims.co.uk\/) can\u2019t get around is the hard resource limits [Microsoft](http:\/\/www.microsoft.com\/en-gb\/) has set. Express is\u00a0limited to\u00a01GB RAM and 1 CPU (max of 4 cores).\n\nWhen deciding what edition\u00a0of SQL to use, I normally follow the following diagram\n\n![Which SQL Edition is right for me?](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/SQL_Edition_Decision_Tree.png?resize=415%2C543)\n\nI simply believe a Primary school doesn\u2019t need SQL Standard edition. Secondary schools who use [Lesson Monitor](http:\/\/www.capita-sims.co.uk\/our-products\/sims-lesson-monitor-secondary-schools-and-academies), a [Capita](http:\/\/www.capita-sims.co.uk\/) bolt-on module that is used for recording attendance for individual lessons rather then just AMPM, will be using the system pretty much all day rather then just morning and afternoons, so your concurrent users will be alot higher and therefore require more then 1GB RAM. It\u2019s rare that a Secondary school will not be recording individual lessons, however other bolt-ons exist from third parties that will allow the same thing but not have the same impact on the server, so you may be able to get away with Express by using a web based bolt-on.\n\n\n","html":"<p>One of the common\u00a0questions I used to get asked whilst supporting <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a> was, do I need Full SQL. <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a> uses <a href=\"http:\/\/www.microsoft.com\/en-gb\/server-cloud\/products\/sql-server\/default.aspx\" target=\"_blank\" rel=\"nofollow\">Microsoft SQL Server<\/a>\u00a0as it&#8217;s\u00a0relational database management system (RDBMS) so it&#8217;s important to ensure the engine is correctly sized for job at hand. <a href=\"http:\/\/www.microsoft.com\/en-gb\/server-cloud\/products\/sql-server\/default.aspx\" target=\"_blank\" rel=\"nofollow\">Microsoft SQL Server<\/a> has come in a number of editions over the years, I won&#8217;t detail all the various editions\u00a0but the two editions\u00a0schools should be concerned\u00a0with is Express and Standard. Express is the free edition\u00a0that <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita <\/a>bundles as part of their installation media and Standard edition requires purchasing additional <a href=\"http:\/\/www.microsoft.com\/\" target=\"_blank\" rel=\"nofollow\">Microsoft<\/a> licenses.<\/p>\n<p>Standard edition can either be licensed by the number of processor (cores) or by users. I personally tend to go for processor licenses so I don&#8217;t need to worry about buying new licenses when adding new users\u00a0later on down the road. It does\u00a0however come down to pricing &#8211; I tend to find processor licenses break even around the 30 user mark (based on Academic licensing anyway).<\/p>\n<p>So why should you shell out of Standard edition? Now to be fair to <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> a number of features that Standard has over Express, like SSIS and the SQL Agent <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> has created tools to workaround the limitations, they&#8217;ve created a data transfer tool to extract the data from the <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a> database into the <a href=\"http:\/\/www.capita-sims.co.uk\/our-products\/sims-discover-primary-schools-and-academies\" target=\"_blank\" rel=\"nofollow\">SIMS Discover<\/a> database for example, they&#8217;ve created routines within <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a> to create Windows Scheduled \u00a0Tasks for SQL jobs like B2B. With that said, the one thing <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> can&#8217;t get around is the hard resource limits <a href=\"http:\/\/www.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Microsoft<\/a> has set. Express is\u00a0limited to\u00a01GB RAM and 1 CPU (max of 4 cores).<\/p>\n<p>When deciding what edition\u00a0of SQL to use, I normally follow the following diagram<\/p>\n<p><img class=\"aligncenter wp-image-16 size-full\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/SQL_Edition_Decision_Tree.png?resize=415%2C543\" alt=\"Which SQL Edition is right for me?\" data-recalc-dims=\"1\" \/><\/p>\n<p>I simply believe a Primary school doesn&#8217;t need SQL Standard edition. Secondary schools who use <a href=\"http:\/\/www.capita-sims.co.uk\/our-products\/sims-lesson-monitor-secondary-schools-and-academies\" target=\"_blank\" rel=\"nofollow\">Lesson Monitor<\/a>, a <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> bolt-on module that is used for recording attendance for individual lessons rather then just AMPM, will be using the system pretty much all day rather then just morning and afternoons, so your concurrent users will be alot higher and therefore require more then 1GB RAM. It&#8217;s rare that a Secondary school will not be recording individual lessons, however other bolt-ons exist from third parties that will allow the same thing but not have the same impact on the server, so you may be able to get away with Express by using a web based bolt-on.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 20 May 2014 18:15:35 +0000","created_by":1,"updated_at":"Tue, 20 May 2014 18:15:35 +0000","updated_by":1,"published_at":"Tue, 20 May 2014 18:15:35 +0000","published_by":1},{"id":31,"title":"DfE big plans for big data","slug":"dfe-big-plans-for-big-data","markdown":"\nAn interesting debate erupted on [EduGeek](http:\/\/www.edugeek.net\/forums\/mis-systems\/136314-data-transfer-changing-sims.html)\u00a0this month after [Graham Reed](http:\/\/www.eduwarenetwork.com\/), <span style=\"color: #555555;\">a technologist, made a post on [Eduware Consulting](http:\/\/www.eduwarenetwork.com\/)\u00a0[blog](http:\/\/www.eduwarenetwork.com\/the_edu_blog\/)\u00a0about the [changing data landscape](http:\/\/www.eduwarenetwork.com\/2014\/04\/22\/the_data_landscape_is_changing\/)\u00a0and how he saw [Department of Education (DfE)](https:\/\/www.gov.uk\/government\/organisations\/department-for-education)\u00a0data exchange and warehouse projects changing the way MIS work and the way they are used. Now of course we need to take it with a pinch of salt, firstly, this is very much early days. At the moment it\u2019s a vision looking to become a project, [and we all know how government projects end up post\u00a0election time](http:\/\/www.theguardian.com\/commentisfree\/libertycentral\/2010\/aug\/13\/closure-contactpoint-database-contrasting-views). Add the fact\u00a0[Graham Reed](http:\/\/www.zinetdatasolutions.com\/key-personnel\/) is [one of those folks](http:\/\/www.zinetdatasolutions.com\/key-personnel\/) trying to push [SIF](https:\/\/www.sifassociation.org\/)\u00a0and the\u00a0interoperability agenda and you start to get the feeling your walking into a sales pitch. With that said, I think the [DfE](https:\/\/www.gov.uk\/government\/organisations\/department-for-education) onto a winner.<\/span>\n\nThe crux of the [DfE](https:\/\/www.gov.uk\/government\/organisations\/department-for-education)\u00a0goal is turn the very manual processes they have:\n\n[![DfE_Current](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/DfE_Current.png?resize=700%2C525)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/DfE_Current1.png?ssl=1)\n\ninto something a lot more streamlined:\n\n[![DfE_Future](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/DfE_Future.png?resize=700%2C525)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/DfE_Future1.png?ssl=1)\n\n(Thanks to\u00a0[Phillip Hamlyn](http:\/\/www.edugeek.net\/forums\/mis-systems\/136314-data-transfer-changing-sims-3.html#post1169933) at [Capita](http:\/\/www.capita-sims.co.uk\/) for sharing the link to [DfE documents](https:\/\/online.contractsfinder.businesslink.gov.uk\/Common\/View%20Notice.aspx?site=1000&lang=en&noticeid=1282858&fs=true))\n\nIn short, it won\u2019t take them months to produce something useful that by the time they\u2019ve produced it, it\u2019s already out-of-date. On paper this makes complete sense, it\u2019s what happening in industry across the board, it\u2019s what the cloud is all about, automation.\n\nIt also starts to solve a lot of other issues, generating [ULNs](https:\/\/www.gov.uk\/government\/publications\/lrs-unique-learner-numbers) for example requires manually generating a [CTF](https:\/\/www.gov.uk\/government\/collections\/common-transfer-file) then uploading to [S2S](https:\/\/www.gov.uk\/school-to-school-service-how-to-transfer-information) and finally manually updating your MIS, with the new system, your MIS could do API call to the [DfE](https:\/\/www.gov.uk\/government\/organisations\/department-for-education) [<span style=\"color: #202020;\">Learning Records Service (LRS)<\/span>](https:\/\/www.gov.uk\/government\/organisations\/skills-funding-agency) web service and automatically request and update the record with the [ULN](https:\/\/www.gov.uk\/government\/publications\/lrs-unique-learner-numbers)\u00a0all without leaving\u00a0your MIS application and a few clicks of a button. Simple. Take it a step further and pupil transfers could be done the same way, select the pupil who\u2019s leaving, select\u00a0the new school and it automatically sends the pupil records to the new school! Dual registered could occur the same way, just add the other school and the pupil records are synced between the two, regardless of [MIS supplier](http:\/\/eduwarenetwork.com\/what_is_the_mis_challenge\/), via the [DfE](https:\/\/www.gov.uk\/government\/organisations\/department-for-education).\n\nUnfortunately, like most things, the problems appear when you start\u00a0digging into the detail, how is this data used and how is the data currently gathered and why is it so manual?\n\nThe main issue, in one word, is [Census](https:\/\/www.gov.uk\/school-census). The [Census](https:\/\/www.gov.uk\/school-census), to put it bluntly, is used for funding. Now in a world where budgets are on the decrease the last thing you want is to see it drop even further because of an admin error, so you can see why the idea of gathering the raw data in near real-time is a bit worrying. For me, I don\u2019t see this a show stopper. I accept data will be inputted incorrectly or not at all. I know the pains of ethnicity data. I also know the importance of a \u201capprove\u201d button. I know a Local Authority (LA) will most likely have access to most of their schools MIS systems and be able to produce a [School Census](https:\/\/www.gov.uk\/school-census) return, I also know they would have\u00a0enough data in their own systems to produce\u00a0a [School Census](https:\/\/www.gov.uk\/school-census) return. The key fact here is that they don\u2019t hit that approve button.\u00a0That approve button is always\u00a0hit by the school. Period.\n\nSo long as decisions aren\u2019t formed on unconfirmed facts I don\u2019t see a problem and I\u2019m not just talking about funding, many other decisions are formed from the [School Census](https:\/\/www.gov.uk\/school-census) data, just have a look at the [free reports from Arbor](http:\/\/www.arbor-education.com\/free_analyst_reports.php) and your see what data there is on your school in the public domain. The general public are becoming better informed and schools are almost having to sell themselves to [get more pupils on-roll](http:\/\/www.theguardian.com\/education\/2012\/jul\/09\/free-schools-academies-opposition), to get more funding or [even stay open](http:\/\/www.theguardian.com\/education\/2012\/jul\/09\/free-schools-academies-opposition). This is even before we start looking at how services use the [School Census](https:\/\/www.gov.uk\/school-census) data to support schools such as transportation, and not forgetting how\u00a0[researchers use the data for analysis](http:\/\/eduwarenetwork.com\/mis_market_statistics\/). As long as that approve button still exists in the new [DfE](https:\/\/www.gov.uk\/government\/organisations\/department-for-education) system, it\u2019ll be no different then what happens now.\n\nPersonally, I quite like the idea. The buttons will change but core processes will remain. You will still submit data which will be used for funding,\u00a0<span style=\"color: #0b0c0c;\">[performance tables](https:\/\/www.gov.uk\/school-performance-tables) and various research purposes. How you do it will change, but that is always changing. It\u2019s one of the joys of IT. It\u2019s just this change is the [DfE](https:\/\/www.gov.uk\/government\/organisations\/department-for-education) getting his house in order, it\u2019s bring all the various siloed services into one roof, like the [government](https:\/\/gds.blog.gov.uk\/about\/) is\u00a0doing with [all it\u2019s\u00a0websites](https:\/\/gds.blog.gov.uk\/about\/). So really, the only people who have to worry are [MIS suppliers](https:\/\/ccs.cabinetoffice.gov.uk\/suppliers?sm_field_contract_id=%22RM1500%3A1%22) and if you are a supplier, I know a [company who can help you out](http:\/\/www.zinetdatasolutions.com\/) \ud83d\ude09<\/span>\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\n","html":"<p>An interesting debate erupted on <a href=\"http:\/\/www.edugeek.net\/forums\/mis-systems\/136314-data-transfer-changing-sims.html\" target=\"_blank\" rel=\"nofollow\">EduGeek<\/a>\u00a0this month after <a href=\"http:\/\/www.eduwarenetwork.com\/\" target=\"_blank\" rel=\"nofollow\">Graham Reed<\/a>, <span style=\"color: #555555;\">a technologist, made a post on <a href=\"http:\/\/www.eduwarenetwork.com\/\" target=\"_blank\" rel=\"nofollow\">Eduware Consulting<\/a>\u00a0<a href=\"http:\/\/www.eduwarenetwork.com\/the_edu_blog\/\" target=\"_blank\" rel=\"nofollow\">blog<\/a>\u00a0about the <a href=\"http:\/\/www.eduwarenetwork.com\/2014\/04\/22\/the_data_landscape_is_changing\/\" target=\"_blank\" rel=\"nofollow\">changing data landscape<\/a>\u00a0and how he saw <a href=\"https:\/\/www.gov.uk\/government\/organisations\/department-for-education\" target=\"_blank\" rel=\"nofollow\">Department of Education (DfE)<\/a>\u00a0data exchange and warehouse projects changing the way MIS work and the way they are used. Now of course we need to take it with a pinch of salt, firstly, this is very much early days. At the moment it&#8217;s a vision looking to become a project, <a href=\"http:\/\/www.theguardian.com\/commentisfree\/libertycentral\/2010\/aug\/13\/closure-contactpoint-database-contrasting-views\" target=\"_blank\" rel=\"nofollow\">and we all know how government projects end up post\u00a0election time<\/a>. Add the fact\u00a0<a href=\"http:\/\/www.zinetdatasolutions.com\/key-personnel\/\" target=\"_blank\" rel=\"nofollow\">Graham Reed<\/a> is <a href=\"http:\/\/www.zinetdatasolutions.com\/key-personnel\/\" target=\"_blank\" rel=\"nofollow\">one of those folks<\/a> trying to push <a href=\"https:\/\/www.sifassociation.org\/\" target=\"_blank\" rel=\"nofollow\">SIF<\/a>\u00a0and the\u00a0interoperability agenda and you start to get the feeling your walking into a sales pitch. With that said, I think the <a href=\"https:\/\/www.gov.uk\/government\/organisations\/department-for-education\" target=\"_blank\" rel=\"nofollow\">DfE<\/a> onto a winner.<\/span><\/p>\n<p>The crux of the <a href=\"https:\/\/www.gov.uk\/government\/organisations\/department-for-education\" target=\"_blank\" rel=\"nofollow\">DfE<\/a>\u00a0goal is turn the very manual processes they have:<\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/DfE_Current1.png?ssl=1\"><img class=\"alignnone wp-image-27 size-full\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/DfE_Current.png?resize=700%2C525\" alt=\"DfE_Current\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>into something a lot more streamlined:<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/DfE_Future1.png?ssl=1\"><img class=\"alignnone wp-image-28 size-full\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/DfE_Future.png?resize=700%2C525\" alt=\"DfE_Future\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>(Thanks to\u00a0<a href=\"http:\/\/www.edugeek.net\/forums\/mis-systems\/136314-data-transfer-changing-sims-3.html#post1169933\" target=\"_blank\" rel=\"nofollow\">Phillip Hamlyn<\/a> at <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> for sharing the link to <a href=\"https:\/\/online.contractsfinder.businesslink.gov.uk\/Common\/View%20Notice.aspx?site=1000&amp;lang=en&amp;noticeid=1282858&amp;fs=true\" target=\"_blank\" rel=\"nofollow\">DfE documents<\/a>)<\/p>\n<p>In short, it won&#8217;t take them months to produce something useful that by the time they&#8217;ve produced it, it&#8217;s already out-of-date. On paper this makes complete sense, it&#8217;s what happening in industry across the board, it&#8217;s what the cloud is all about, automation.<\/p>\n<p>It also starts to solve a lot of other issues, generating <a href=\"https:\/\/www.gov.uk\/government\/publications\/lrs-unique-learner-numbers\" target=\"_blank\" rel=\"nofollow\">ULNs<\/a> for example requires manually generating a <a href=\"https:\/\/www.gov.uk\/government\/collections\/common-transfer-file\" target=\"_blank\" rel=\"nofollow\">CTF<\/a> then uploading to <a href=\"https:\/\/www.gov.uk\/school-to-school-service-how-to-transfer-information\" target=\"_blank\" rel=\"nofollow\">S2S<\/a> and finally manually updating your MIS, with the new system, your MIS could do API call to the <a href=\"https:\/\/www.gov.uk\/government\/organisations\/department-for-education\" target=\"_blank\" rel=\"nofollow\">DfE<\/a><a href=\"https:\/\/www.gov.uk\/government\/organisations\/skills-funding-agency\" target=\"_blank\" rel=\"nofollow\"><span style=\"color: #202020;\">Learning Records Service (LRS)<\/span><\/a> web service and automatically request and update the record with the <a href=\"https:\/\/www.gov.uk\/government\/publications\/lrs-unique-learner-numbers\" target=\"_blank\" rel=\"nofollow\">ULN<\/a>\u00a0all without leaving\u00a0your MIS application and a few clicks of a button. Simple. Take it a step further and pupil transfers could be done the same way, select the pupil who&#8217;s leaving, select\u00a0the new school and it automatically sends the pupil records to the new school! Dual registered could occur the same way, just add the other school and the pupil records are synced between the two, regardless of <a href=\"http:\/\/eduwarenetwork.com\/what_is_the_mis_challenge\/\" target=\"_blank\" rel=\"nofollow\">MIS supplier<\/a>, via the <a href=\"https:\/\/www.gov.uk\/government\/organisations\/department-for-education\" target=\"_blank\" rel=\"nofollow\">DfE<\/a>.<\/p>\n<p>Unfortunately, like most things, the problems appear when you start\u00a0digging into the detail, how is this data used and how is the data currently gathered and why is it so manual?<\/p>\n<p>The main issue, in one word, is <a href=\"https:\/\/www.gov.uk\/school-census\" target=\"_blank\" rel=\"nofollow\">Census<\/a>. The <a href=\"https:\/\/www.gov.uk\/school-census\" target=\"_blank\" rel=\"nofollow\">Census<\/a>, to put it bluntly, is used for funding. Now in a world where budgets are on the decrease the last thing you want is to see it drop even further because of an admin error, so you can see why the idea of gathering the raw data in near real-time is a bit worrying. For me, I don&#8217;t see this a show stopper. I accept data will be inputted incorrectly or not at all. I know the pains of ethnicity data. I also know the importance of a &#8220;approve&#8221; button. I know a Local Authority (LA) will most likely have access to most of their schools MIS systems and be able to produce a <a href=\"https:\/\/www.gov.uk\/school-census\" target=\"_blank\" rel=\"nofollow\">School Census<\/a> return, I also know they would have\u00a0enough data in their own systems to produce\u00a0a <a href=\"https:\/\/www.gov.uk\/school-census\" target=\"_blank\" rel=\"nofollow\">School Census<\/a> return. The key fact here is that they don&#8217;t hit that approve button.\u00a0That approve button is always\u00a0hit by the school. Period.<\/p>\n<p>So long as decisions aren&#8217;t formed on unconfirmed facts I don&#8217;t see a problem and I&#8217;m not just talking about funding, many other decisions are formed from the <a href=\"https:\/\/www.gov.uk\/school-census\" target=\"_blank\" rel=\"nofollow\">School Census<\/a> data, just have a look at the <a href=\"http:\/\/www.arbor-education.com\/free_analyst_reports.php\" target=\"_blank\" rel=\"nofollow\">free reports from Arbor<\/a> and your see what data there is on your school in the public domain. The general public are becoming better informed and schools are almost having to sell themselves to <a href=\"http:\/\/www.theguardian.com\/education\/2012\/jul\/09\/free-schools-academies-opposition\" target=\"_blank\" rel=\"nofollow\">get more pupils on-roll<\/a>, to get more funding or <a href=\"http:\/\/www.theguardian.com\/education\/2012\/jul\/09\/free-schools-academies-opposition\" target=\"_blank\" rel=\"nofollow\">even stay open<\/a>. This is even before we start looking at how services use the <a href=\"https:\/\/www.gov.uk\/school-census\" target=\"_blank\" rel=\"nofollow\">School Census<\/a> data to support schools such as transportation, and not forgetting how\u00a0<a href=\"http:\/\/eduwarenetwork.com\/mis_market_statistics\/\" target=\"_blank\" rel=\"nofollow\">researchers use the data for analysis<\/a>. As long as that approve button still exists in the new <a href=\"https:\/\/www.gov.uk\/government\/organisations\/department-for-education\" target=\"_blank\" rel=\"nofollow\">DfE<\/a> system, it&#8217;ll be no different then what happens now.<\/p>\n<p>Personally, I quite like the idea. The buttons will change but core processes will remain. You will still submit data which will be used for funding,\u00a0<span style=\"color: #0b0c0c;\"><a href=\"https:\/\/www.gov.uk\/school-performance-tables\" target=\"_blank\" rel=\"nofollow\">performance tables<\/a> and various research purposes. How you do it will change, but that is always changing. It&#8217;s one of the joys of IT. It&#8217;s just this change is the <a href=\"https:\/\/www.gov.uk\/government\/organisations\/department-for-education\" target=\"_blank\" rel=\"nofollow\">DfE<\/a> getting his house in order, it&#8217;s bring all the various siloed services into one roof, like the <a href=\"https:\/\/gds.blog.gov.uk\/about\/\" target=\"_blank\" rel=\"nofollow\">government<\/a> is\u00a0doing with <a href=\"https:\/\/gds.blog.gov.uk\/about\/\" target=\"_blank\" rel=\"nofollow\">all it&#8217;s\u00a0websites<\/a>. So really, the only people who have to worry are <a href=\"https:\/\/ccs.cabinetoffice.gov.uk\/suppliers?sm_field_contract_id=%22RM1500%3A1%22\" target=\"_blank\" rel=\"nofollow\">MIS suppliers<\/a> and if you are a supplier, I know a <a href=\"http:\/\/www.zinetdatasolutions.com\/\" target=\"_blank\" rel=\"nofollow\">company who can help you out<\/a> \ud83d\ude09<\/span><\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 20 May 2014 21:34:32 +0000","created_by":1,"updated_at":"Wed, 22 Jul 2015 13:04:12 +0000","updated_by":1,"published_at":"Tue, 20 May 2014 21:34:32 +0000","published_by":1},{"id":54,"title":"The cost of trust","slug":"temp-slug-2","markdown":"\nI was recently taking to a friend about how my son\u2019s school was looking at becoming an Academy and how schools are using this as a time to introduce a new MIS system. The usual question arose of what MIS systems would I recommend and after giving my 3-4 recommend systems, he asked me why I didn\u2019t include one particular supplier, after pausing for a while, I simply replied, because I don\u2019t trust them.\n\n\u00a0\n\nHe then followed it up usual probing questions trying to form some logical answer around my emotional response. I detailed a few cases that if this was a pupil in a school would have filled a few sheets of paper in the nagging doubt files, but I doubt it would have been enough to create a case from on it\u2019s own. I tried to engage his response but he\u2019s a hard man to read, I\u2019m just thankful I\u2019ve never played him at poke, I often find the only time you find out his true response is when the PO goes in, even then it can sometimes be 50\/50 as to whether his hand was forced. Afterwards it got me thinking, how important is trust and how can it be benchmark it?\n\n\u00a0\n\nAll the other data I\u2019ve been collecting so far is a solid fact, what MIS system did you use to submit the Autumn Census in 2012, you could be mid-transfer between two (or more!) MIS systems, but you can only submit it from one of them. Are you an Academy on this particular date, yes or no? Trust is a very different beast. It\u2019s much harder to engage, it has a very analog response and it can\u2019t be truly awarded. It varies person to person and can change in a flash. It is hard thing to estimate it\u2019s value as well, I\u2019m sure you could look at the downturn in business as attribute it down to lack of trust but it will undoubtedly be intertwined with other factors. In the discussion with my friend I was bold enough to say that if he\u2019s school was to select that particular supplier, I would have my son transfer schools and invoke my right be to be forgotten, effectually stating they have no legal right to the data going forward and should not transfer the data to the new MIS system. In terms of cost, even at a per pupil cost, it\u2019s negotiable. I don\u2019t think either party would particular batter a eye lid at the price difference. He of course raised the question of why I wouldn\u2019t force the school to reconsider their choice in MIS if I had such strong objects, of course it is one thing to drop the school head count down by one, it\u2019s another to drop the MIS system of choice, especially when my emotions of trust are stacked up against the weight of schools professionals logical facts when selecting such a critical system.\n\n\u00a0\n\nSo, when selecting a new MIS system, how do you benchmark the suppliers and your levels of trust you have with them and what sort of impact can that have? It\u2019s hard one to answer. The main problem is your in the public sector. You choices will become public knowledge and will be open to integration by everyone, including the supplier. So how can you put \u201cI don\u2019t trust Supplier A\u201d without the supplier taking offence? They will undoubtedly want hard facts that explain how you got to that conclusion and the problem is, trust is emotional, it isn\u2019t always logical, it can sometimes but it isn\u2019t always. Even if you list logical reasons, it will undoubtedly be seen as a list of problems to be solved, however the damage maybe already done or maybe it\u2019s highlighting a larger problem that isn\u2019t vulnerable now, but may lead to future problems.\u00a0 This isn\u2019t helped when suppliers have thrown legal action at Local Authorities (LAs) who have used different procurement frameworks to avoid the discussion of trust for reasons of discounting suppliers from selection. Love or hate your LA, they are not for profit and their sole goal is to help schools and the community which is a stark contrast to a company who\u2019s number 1 goal is to make money.\n\n\u00a0\n\nAt this point you may be thing, who cares about trusting the supplier, it\u2019s more hassle then it\u2019s worth. Let\u2019s add a bit of context. Let\u2019s thinking about how we shopping online. When we go online we use something called HyperText Transfer Protocol, or HTTP, this is unencrypted data connection, if we want to create a secure, encrypted data connection we had the Secure Socket Layer (SSL), this then becomes HTTPS as it is commonly known. In most modern web browsers a padlock is displayed to show the user that the data is now encrypted between your computer and the website. Without over complicating things, approximately 17% of the web servers use a open-source cryptographic\u00a0 software library called OpenSSL, simply put because it\u2019s free and it works. However back in April 2014 a serious vulnerability was discovered that basically render OpenSSL useless. Any web servers that had been using the library was in fact not secure and may never have been.\n\n\n","html":"<p>I was recently taking to a friend about how my son\u2019s school was looking at becoming an Academy and how schools are using this as a time to introduce a new MIS system. The usual question arose of what MIS systems would I recommend and after giving my 3-4 recommend systems, he asked me why I didn\u2019t include one particular supplier, after pausing for a while, I simply replied, because I don\u2019t trust them.<\/p>\n<p>&nbsp;<\/p>\n<p>He then followed it up usual probing questions trying to form some logical answer around my emotional response. I detailed a few cases that if this was a pupil in a school would have filled a few sheets of paper in the nagging doubt files, but I doubt it would have been enough to create a case from on it\u2019s own. I tried to engage his response but he\u2019s a hard man to read, I\u2019m just thankful I\u2019ve never played him at poke, I often find the only time you find out his true response is when the PO goes in, even then it can sometimes be 50\/50 as to whether his hand was forced. Afterwards it got me thinking, how important is trust and how can it be benchmark it?<\/p>\n<p>&nbsp;<\/p>\n<p>All the other data I\u2019ve been collecting so far is a solid fact, what MIS system did you use to submit the Autumn Census in 2012, you could be mid-transfer between two (or more!) MIS systems, but you can only submit it from one of them. Are you an Academy on this particular date, yes or no? Trust is a very different beast. It\u2019s much harder to engage, it has a very analog response and it can\u2019t be truly awarded. It varies person to person and can change in a flash. It is hard thing to estimate it\u2019s value as well, I\u2019m sure you could look at the downturn in business as attribute it down to lack of trust but it will undoubtedly be intertwined with other factors. In the discussion with my friend I was bold enough to say that if he\u2019s school was to select that particular supplier, I would have my son transfer schools and invoke my right be to be forgotten, effectually stating they have no legal right to the data going forward and should not transfer the data to the new MIS system. In terms of cost, even at a per pupil cost, it\u2019s negotiable. I don\u2019t think either party would particular batter a eye lid at the price difference. He of course raised the question of why I wouldn\u2019t force the school to reconsider their choice in MIS if I had such strong objects, of course it is one thing to drop the school head count down by one, it\u2019s another to drop the MIS system of choice, especially when my emotions of trust are stacked up against the weight of schools professionals logical facts when selecting such a critical system.<\/p>\n<p>&nbsp;<\/p>\n<p>So, when selecting a new MIS system, how do you benchmark the suppliers and your levels of trust you have with them and what sort of impact can that have? It\u2019s hard one to answer. The main problem is your in the public sector. You choices will become public knowledge and will be open to integration by everyone, including the supplier. So how can you put \u201cI don\u2019t trust Supplier A\u201d without the supplier taking offence? They will undoubtedly want hard facts that explain how you got to that conclusion and the problem is, trust is emotional, it isn\u2019t always logical, it can sometimes but it isn\u2019t always. Even if you list logical reasons, it will undoubtedly be seen as a list of problems to be solved, however the damage maybe already done or maybe it\u2019s highlighting a larger problem that isn\u2019t vulnerable now, but may lead to future problems.\u00a0 This isn\u2019t helped when suppliers have thrown legal action at Local Authorities (LAs) who have used different procurement frameworks to avoid the discussion of trust for reasons of discounting suppliers from selection. Love or hate your LA, they are not for profit and their sole goal is to help schools and the community which is a stark contrast to a company who\u2019s number 1 goal is to make money.<\/p>\n<p>&nbsp;<\/p>\n<p>At this point you may be thing, who cares about trusting the supplier, it\u2019s more hassle then it\u2019s worth. Let\u2019s add a bit of context. Let\u2019s thinking about how we shopping online. When we go online we use something called HyperText Transfer Protocol, or HTTP, this is unencrypted data connection, if we want to create a secure, encrypted data connection we had the Secure Socket Layer (SSL), this then becomes HTTPS as it is commonly known. In most modern web browsers a padlock is displayed to show the user that the data is now encrypted between your computer and the website. Without over complicating things, approximately 17% of the web servers use a open-source cryptographic\u00a0 software library called OpenSSL, simply put because it\u2019s free and it works. However back in April 2014 a serious vulnerability was discovered that basically render OpenSSL useless. Any web servers that had been using the library was in fact not secure and may never have been.<\/p>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 20 May 2014 22:19:37 +0000","created_by":1,"updated_at":"Tue, 20 May 2014 22:19:37 +0000","updated_by":1,"published_at":"","published_by":1},{"id":29,"title":"Why I like Twitter","slug":"why-i-like-twitter","markdown":"\n![Applications crash and \"AccessViolationException\" exception occurs when you use System.Data.SqlClient after you install Visual Studio 2013 or .NET Framework 4.5.1](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/451error.png?resize=700%2C250)\n\nI have to say I\u2019m really liking [Twitter](http:\/\/twitter.com\/matt40k). A lot of my friends can\u2019t see the point. As a social tool it allows gossip to flow really well, how often do we hear that a celeb has tweeted\u00a0a inappropriate comment or photo. It allows us fans to be alot more closer. As a business tool it allows a new way of interaction, take this example \u2013 there is a bug in [.net framework 4.5.1 that occurs if your using a certain type of third party firewall](http:\/\/support.microsoft.com\/kb\/2915689) (often bundled with anti-virus software these days), it breaks [SIMS .net](http:\/\/www.capita-sims.co.uk\/), that uses [.net 4.0](http:\/\/en.wikipedia.org\/wiki\/.NET_Framework_version_history#.NET_Framework_4). [Capita](http:\/\/www.capita-sims.co.uk\/) have spend ages trying to resolve it, then, [@timbo343 posts on\u00a0Edugeek](http:\/\/www.edugeek.net\/forums\/mis-systems\/129997-microsoft-net-4-5-1-update-borking-sims-net-anyone-else-2.html#post1166917) that [4.5.2](http:\/\/en.wikipedia.org\/wiki\/.NET_Framework_version_history#.NET_Framework_4.5.2) has resolve it, a [quick tweet](http:\/\/twitter.com\/matt40k\/status\/464869385816268800) to the Microsoft [@dotnet](http:\/\/twitter.com\/DotNet) twitter guys and [it turns out that it is](http:\/\/twitter.com\/PreetiKr007\/status\/466661569221238784)\u00a0fixed in the new version. Awesome.\n\n\n","html":"<p><img class=\"size-full wp-image-58\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/451error.png?resize=700%2C250\" alt=\"Applications crash and &quot;AccessViolationException&quot; exception occurs when you use System.Data.SqlClient after you install Visual Studio 2013 or .NET Framework 4.5.1\" data-recalc-dims=\"1\" \/><\/p>\n<p>I have to say I&#8217;m really liking <a href=\"http:\/\/twitter.com\/matt40k\" target=\"_blank\" rel=\"nofollow\">Twitter<\/a>. A lot of my friends can&#8217;t see the point. As a social tool it allows gossip to flow really well, how often do we hear that a celeb has tweeted\u00a0a inappropriate comment or photo. It allows us fans to be alot more closer. As a business tool it allows a new way of interaction, take this example &#8211; there is a bug in <a href=\"http:\/\/support.microsoft.com\/kb\/2915689\" target=\"_blank\" rel=\"nofollow\">.net framework 4.5.1 that occurs if your using a certain type of third party firewall<\/a> (often bundled with anti-virus software these days), it breaks <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a>, that uses <a href=\"http:\/\/en.wikipedia.org\/wiki\/.NET_Framework_version_history#.NET_Framework_4\" target=\"_blank\" rel=\"nofollow\">.net 4.0<\/a>. <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> have spend ages trying to resolve it, then, <a href=\"http:\/\/www.edugeek.net\/forums\/mis-systems\/129997-microsoft-net-4-5-1-update-borking-sims-net-anyone-else-2.html#post1166917\" target=\"_blank\" rel=\"nofollow\">@timbo343 posts on\u00a0Edugeek<\/a> that <a href=\"http:\/\/en.wikipedia.org\/wiki\/.NET_Framework_version_history#.NET_Framework_4.5.2\" target=\"_blank\" rel=\"nofollow\">4.5.2<\/a> has resolve it, a <a href=\"http:\/\/twitter.com\/matt40k\/status\/464869385816268800\" target=\"_blank\" rel=\"nofollow\">quick tweet<\/a> to the Microsoft <a href=\"http:\/\/twitter.com\/DotNet\" target=\"_blank\" rel=\"nofollow\">@dotnet<\/a> twitter guys and <a href=\"http:\/\/twitter.com\/PreetiKr007\/status\/466661569221238784\" target=\"_blank\" rel=\"nofollow\">it turns out that it is<\/a>\u00a0fixed in the new version. Awesome.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 20 May 2014 22:35:08 +0000","created_by":1,"updated_at":"Tue, 20 May 2014 22:35:08 +0000","updated_by":1,"published_at":"Tue, 20 May 2014 22:35:08 +0000","published_by":1},{"id":61,"title":"Want a job? Head to Superdrug","slug":"want-a-job-head-to-superdrug","markdown":"\nOne of the things you\u2019ll find when your going to\u00a0interviews for your first job\u00a0after leaving education is that they ask the same types of questions. The main one that feels me with dread is \u201cGive an example of good customer service you have provided\u201d. I hate that question. Hopefully your interviewer would have been kinda enough to at least\u00a0state that, as you are ill experienced, you might want to give examples of good customer service you have received. Sounds simple enough, but what is good customer service?\n\nThe first thing that jumps to my mind is examples bad customer service. We all\u00a0remember bad customer service, they stick with us, they are almost etched in our mind and often good customer service is overlooked and quickly forgotten. It\u2019s harsh fact in the\u00a0IT world that the best people are those that no-one knows what they do and only after they leave do people realise how good they were.\n\nThe example that prompted me to write this post was after visiting my local [Superdrug](http:\/\/www.superdrug.com\/). Now\u00a0you have to understand, I\u2019m not a fan of shopping, in fact, that\u2019s an understatement. I\u2019m often messing about if I\u2019m not too busy daydreaming. So when the missus has dragged me shopping, and if I\u2019m being honest,\u00a0[Superdrug](http:\/\/www.superdrug.com\/)\u00a0is possibility the worse shop she could drag me to. The idea of spending any length of time looking at make-up horrifies me, combine that\u00a0with the lack\u00a0of entertainment (trolley racingiPad \u201ctesting\u201dcomfy chairs) combined with the prospect of holding bright print bags and your pretty much got a full-on sulk for the rest of the day.\n\n![Superdrug Ipswich](https:\/\/i1.wp.com\/s3.amazonaws.com\/ldc\/large\/2139\/21391404.jpg?resize=400%2C300)\n\nThe thing that impressed me was one of the staff, he clearly had spotted my sulky face and had been watching us as my missus\u00a0perused the\u00a0aisles. As we ventured near the final stretch towards the tills he moved from the shelves he was stacking at\u00a0the back of the store, not to the tills but the boxes near the tills and continued unpacking stock. When we finally came to queuing for the tills after what felt like an eternity, he stopped unboxing and headed for the till. He opened the till, despite us being the only person in the queue. He stated that they have a 2 for 1 offer on fizzy drinks and would we be interested \u2013 the fizzy drinks being stored next to the tills \u2013 when we collected a pair and placed them on the counter, he asked if we wanted them out or bagged.\n\nThis was good customer service.\n\nHe spotted a unhappy customer, me.\u00a0<span style=\"line-height: 1.5;\">He decided the best way he could help was to get me out of the shop as quickly as possible, the less time I spend in the shop, the more likely I was to return and more importantly, with my money.<\/span>\n\nHe stayed\u00a0efficient. He didn\u2019t stop working, he carried on even when waiting for us to pay \u2013 it also meant the missus didn\u2019t feel rushed (at least by the staff!)\n\nHe saw a sales opening, he took it.\n\nFor me, the ticks all the boxes. It shows common sense, that your able to put your feet into the customers shoes, right up to the end this guy is thinking of me, the customer \u2013 I can\u2019t tell you the number of times I\u2019ve had shop assistance put items into a bag when you both know your going to take it straight out of the bag (a rant for another day perhaps).\u00a0It shows this guy can see the real benefit of good customer service, not only has he increased his sales today, but future sales by turning a unwilling customer, into a sightly more willing customer.\n\nFor more helpful tips on Customer Service read [Tricia Morris](http:\/\/twitter.com\/TriciaEMorris)\u2018s\u00a0[7 Customer Service Lessons from a Jedi Master](http:\/\/www.linkedin.com\/today\/post\/article\/20140430134959-27855475-7-customer-service-lessons-from-a-jedi-master).\n\n\n","html":"<p>One of the things you&#8217;ll find when your going to\u00a0interviews for your first job\u00a0after leaving education is that they ask the same types of questions. The main one that feels me with dread is &#8220;Give an example of good customer service you have provided&#8221;. I hate that question. Hopefully your interviewer would have been kinda enough to at least\u00a0state that, as you are ill experienced, you might want to give examples of good customer service you have received. Sounds simple enough, but what is good customer service?<\/p>\n<p>The first thing that jumps to my mind is examples bad customer service. We all\u00a0remember bad customer service, they stick with us, they are almost etched in our mind and often good customer service is overlooked and quickly forgotten. It&#8217;s harsh fact in the\u00a0IT world that the best people are those that no-one knows what they do and only after they leave do people realise how good they were.<\/p>\n<p>The example that prompted me to write this post was after visiting my local <a href=\"http:\/\/www.superdrug.com\/\" target=\"_blank\" rel=\"nofollow\">Superdrug<\/a>. Now\u00a0you have to understand, I&#8217;m not a fan of shopping, in fact, that&#8217;s an understatement. I&#8217;m often messing about if I&#8217;m not too busy daydreaming. So when the missus has dragged me shopping, and if I&#8217;m being honest,\u00a0<a href=\"http:\/\/www.superdrug.com\/\" target=\"_blank\" rel=\"nofollow\">Superdrug<\/a>\u00a0is possibility the worse shop she could drag me to. The idea of spending any length of time looking at make-up horrifies me, combine that\u00a0with the lack\u00a0of entertainment (trolley racingiPad &#8220;testing&#8221;comfy chairs) combined with the prospect of holding bright print bags and your pretty much got a full-on sulk for the rest of the day.<\/p>\n<p><img class=\"aligncenter\" src=\"https:\/\/i1.wp.com\/s3.amazonaws.com\/ldc\/large\/2139\/21391404.jpg?resize=400%2C300\" alt=\"Superdrug Ipswich\" data-recalc-dims=\"1\" \/><\/p>\n<p>The thing that impressed me was one of the staff, he clearly had spotted my sulky face and had been watching us as my missus\u00a0perused the\u00a0aisles. As we ventured near the final stretch towards the tills he moved from the shelves he was stacking at\u00a0the back of the store, not to the tills but the boxes near the tills and continued unpacking stock. When we finally came to queuing for the tills after what felt like an eternity, he stopped unboxing and headed for the till. He opened the till, despite us being the only person in the queue. He stated that they have a 2 for 1 offer on fizzy drinks and would we be interested &#8211; the fizzy drinks being stored next to the tills &#8211; when we collected a pair and placed them on the counter, he asked if we wanted them out or bagged.<\/p>\n<p>This was good customer service.<\/p>\n<p>He spotted a unhappy customer, me.\u00a0<span style=\"line-height: 1.5;\">He decided the best way he could help was to get me out of the shop as quickly as possible, the less time I spend in the shop, the more likely I was to return and more importantly, with my money.<\/span><\/p>\n<p>He stayed\u00a0efficient. He didn&#8217;t stop working, he carried on even when waiting for us to pay &#8211; it also meant the missus didn&#8217;t feel rushed (at least by the staff!)<\/p>\n<p>He saw a sales opening, he took it.<\/p>\n<p>For me, the ticks all the boxes. It shows common sense, that your able to put your feet into the customers shoes, right up to the end this guy is thinking of me, the customer &#8211; I can&#8217;t tell you the number of times I&#8217;ve had shop assistance put items into a bag when you both know your going to take it straight out of the bag (a rant for another day perhaps).\u00a0It shows this guy can see the real benefit of good customer service, not only has he increased his sales today, but future sales by turning a unwilling customer, into a sightly more willing customer.<\/p>\n<p>For more helpful tips on Customer Service read <a href=\"http:\/\/twitter.com\/TriciaEMorris\" target=\"_blank\" rel=\"nofollow\">Tricia Morris<\/a>&#8216;s\u00a0<a href=\"http:\/\/www.linkedin.com\/today\/post\/article\/20140430134959-27855475-7-customer-service-lessons-from-a-jedi-master\" target=\"_blank\" rel=\"nofollow\">7 Customer Service Lessons from a Jedi Master<\/a>.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 21 May 2014 00:12:01 +0000","created_by":1,"updated_at":"Fri, 23 Oct 2015 08:45:42 +0000","updated_by":1,"published_at":"Wed, 21 May 2014 00:12:01 +0000","published_by":1},{"id":87,"title":"I'm sorry, but SIMS8 can't come fast enough","slug":"im-sorry-but-sims8-cant-come-fast-enough","markdown":"\nI haven\u2019t really been on [SupportNet](http:\/\/support.capitaes.co.uk\/), [Capita SIMS](http:\/\/www.capita-sims.co.uk\/) support portal, regularly since changing roles about 20 months ago, the only time I pop on nowadays is to find something when I\u2019m helping out my old team during busyhard times (you never really escape at my work). On this occasion I stopped by the forum and one thing jumped out at me. The lack of progress. Now I appreciate I\u2019m about to unload both barrels into my foot, but I think it needs to be said.\n\nThe same issues exist today that exists when I was dealing with [SIMS .net](http:\/\/www.capita-sims.co.uk\/)\u00a0on daily bases over 20 months ago. That\u2019s nearly 2 years. There are still people who aren\u2019t using [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus) \u2013 you know that free tool [Capita](http:\/\/www.capita-sims.co.uk\/) created to ease the woes of upgrades and deployments. Despite a large number of users already using it and all the major bugs being resolve. More worrying, [Capita](http:\/\/www.capita-sims.co.uk\/) has even issued [SOLUS2](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus) with it\u2019s marching orders. It\u2019s not a question of if, but when. The last release will be Autumn 2014 unless they are forced to push it back. Again.\n\nI don\u2019t think pushing it back is the answer. Pushing the date back is like putting a plaster over a gunshot wound. OK, it might help stop the bleeding, but it\u2019s not the answer. Now I accept my approach of nagging my boss until he allowed me get on top of [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus) whilst [Capita](http:\/\/www.capita-sims.co.uk\/) was throwing major development time at it so I can make sure it works for our\u00a0schools might not be possible for everyone. In fact it\u2019s impossible, there aren\u2019t enough developers to go around. But something has epically failed. Why, why, why hasn\u2019t someone gone. Right, this needs to happen. It\u2019s not going to go away. We have these problems:\n\n- [SIMS Discover](http:\/\/www.capita-sims.co.uk\/our-products\/sims-discover-primary-schools-and-academies) needs [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus)\u00a0\u2013 Sorry, you don\u2019t install SIMS manually why? So why is installing Discover manually an option?\n- [SIMS .net](http:\/\/www.capita-sims.co.uk\/)\u00a0needs MORE access rights to installupgrade \u2013 switching UAC off is just plain stupid\n- Upgrades are just a pain\n\nWe need to resolve. Lets get [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus) setup.\n\nNow if your one of the support teams I\u2019m attacking, before you start defending yourselves. Step back. Being busy\u00a0isn\u2019t an valid excuse. If you weren\u2019t busy, you\u2019ll be at the job centre. Someone, either yourself or your boss should be reviewing whats happening. Regularly. If your trying to do workarounds, you\u2019re never going to have time to implement a fix. See what your doing is a putting a plaster on a gunshot wound and stop, get to the hospital. I know smaller support teams this will be a lot harder, especially when schools are\u00a0doing their own thing, but I think this actually makes it easier.\n\n[SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus) is a bit of a different beast. The way I explain [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus) to new IT staff is,\u00a0[SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus)\u00a0is your tool. It\u2019s a IT technician\u2019s tool. This tool will manage [SIMS\u00a0.net](http:\/\/www.capita-sims.co.uk\/)\u00a0across your network \u2013 it also keeps [SIMS .net](http:\/\/www.capita-sims.co.uk\/) at a safe distance so you don\u2019t enter the mists of MIS land. At the same time it keeps the MIS manager away from any sort of Windows permissions \u2013 you\u2019re not giving any non-IT staff administrator access to YOUR\u00a0network. System Manager is the DataMIS managers tool, it keeps people out of THEIR database, including IT staff. I\u2019ve found this has been really useful with new IT staff coming from the \u201creal\u201d world and they have found the clear what you do and don\u2019t do has helped keep them out of trouble. You do get the odd, why can\u2019t I get a [SCCM](http:\/\/technet.microsoft.com\/en-gb\/systemcenter\/) package, but when you point out that would require either [Capita](http:\/\/www.capita-sims.co.uk\/) forcing schools to buy more [Microsoft](http:\/\/www.microsoft.com\/en-gb\/) licenses or them\u00a0reading more [Capita](http:\/\/www.capita-sims.co.uk\/) documentation, they tend to go quiet.\n\nNow I think the issue is the MIS support people\u00a0are trying to push [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus), when it should be the IT\u00a0support people. If you look at the problems people are having with [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus), they are IT problems, firewall and DNS mainly. Which MIS support staff don\u2019t resolve. IT support staff do.\u00a0If you\u2019re now saying, but we don\u2019t have any IT support people, it\u2019s all third parties. What would happen if something, non-MIS related was required to be pushed out? What I\u2019d do is organise a third party to support it, get the community together and issue training. So, find someone who has deployed [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus)\u00a0successfully and get them to do some training sessions for those pesky IT support teams. The cost of even getting even a [Capita trainer](http:\/\/www.capita-sims.co.uk\/support-and-services\/site-training-and-consultancy) in at \u00a3\u00a3\u00a3, booking a venue could be offset by charging fees to delegates and to be honest, it isn\u2019t that much when you compare it to even 1 day of failed [SIMS](http:\/\/www.capita-sims.co.uk\/) upgradesdeployments. Costs can be cut by using a central school as the venue, by using a non-Capita trainer, by joining forces with other local support teams or even going completely digital. Support forums like [EduGeek](http:\/\/www.edugeek.net\/) are a excellent way for the community to support itself with very little effort. I would also not be fussy by who attends, if they support one of your schools, offer them the training. Don\u2019t get caught up in the fact their going to resell your knowledge. Think bigger picture.\n\nSo, do I think their will be much progress? Do I think [Capita](http:\/\/www.capita-sims.co.uk\/) will stick with their Autumn 2014 is the last [SOLUS2](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus) release?\n\nWell\u00a0I also noticed they still had the following documents on the [SupportNet](http:\/\/support.capitaes.co.uk\/) homepage as sticky items:\n\n- **Technical Guide \u2013 Network Impact of SIMS**\n- **Technical Guide \u2013 Optimising SIMS .net startup speed**\n- **Technical Guide \u2013 Remote Working with SIMS**\n\nSound pretty useful, till you look at the dates, 06 April 2005, 08 April 2005 and 11th June 2004 respectively.\n\nTake the first one, **Network Impact of SIMS** \u2013 to quote a bit of it:\n\n> Unfortunately, minimum hardware specifications are set to rise as we cease support for Windows 98.\n> \n> Realistically Windows 2000 and Windows XP we would recommend a minimum of 256MB.\n\n<div class=\"page\" title=\"Page 8\"><div class=\"layoutArea\"><div class=\"column\">I\u2019m sorry, didn\u2019t [Microsoft](http:\/\/www.microsoft.com\/en-gb\/) and even [Capita](http:\/\/www.capita-sims.co.uk\/) just drop support for Windows XP? Why haven\u2019t they updated a document that is important enough to warrant being displayed on their support portal? In over **9** years?!?\n\nLooking at\u00a0**Optimising SIMS .net startup speed**, why are worrying about turning the antivirus off certain directories? Aren\u2019t our computers these days powerful enough to handle it? Surely it\u2019ll be a good idea if we\u2019re **not** using [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus)\u00a0and giving everyone and their dog\u00a0access to a protected folder location \u2013 Program Files. Why are we worrying about SIMSload, it\u2019s does nothing once the [SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus)\u00a0agent gets installed. Why would anyone compress the drive nowadays?\n\nRemotely accessing [SIMS .net](http:\/\/www.capita-sims.co.uk\/) is a hot topic \u2013 the general concession is to use RemoteApp (Terminal Services). But the \u201cofficial\u201d [Capita](http:\/\/www.capita-sims.co.uk\/) response is the\u00a0**Remote Working with SIMS** document\u2026 which says to use a VPN. I\u2019m not a fan of this idea.\u00a0[FMS](http:\/\/web.archive.org\/web\/20151114110121\/http:\/\/www.capita-sims.co.uk:80\/our-products\/sims-financial-management-system-fms-primary-schools-and-academies), the [Capita SIMS finance package](http:\/\/web.archive.org\/web\/20151114110121\/http:\/\/www.capita-sims.co.uk:80\/our-products\/sims-financial-management-system-fms-primary-schools-and-academies), for starts doesn\u2019t work well over a VPN, it\u2019s not a speed issue, I\u2019ve got 50MBs and that\u2019s the lowest package I could get, it\u2019s a latency issue. SQL doesn\u2019t like latency. If you think of that 50MBs as the number of lanes and the latency as the speed what the cars are traveling. [SIMS .net](http:\/\/www.capita-sims.co.uk\/) isn\u2019t immune either, it just more modern, so it copes better.\n\nI\u2019m sorry, but SIMS8, the next generation of [SIMS](http:\/\/www.capita-sims.co.uk\/) which is rumoured to be in the \u201ccloud\u201d, can\u2019t come fast enough for me to wash away all this silly technical problems. It\u2019s ridiculous that things aren\u2019t further along. Take the file sets for the School Census, I can see 4 file sets that came out in May, it\u2019s still a manual import.\u00a0[SOLUS3](http:\/\/www.capita-sims.co.uk\/support-and-services\/solus)\u00a0should be deploying file sets. Automatically. The biggest strength of SIMS is the community, it\u2019s also the biggest problem. Viva la revolution!\n\n<\/div><\/div><\/div>[![Cloud revolution](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/cloud-rev.png?resize=300%2C177)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/cloud-rev1.png?ssl=1)\n\n\n","html":"<p>I haven&#8217;t really been on <a href=\"http:\/\/support.capitaes.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SupportNet<\/a>, <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita SIMS<\/a> support portal, regularly since changing roles about 20 months ago, the only time I pop on nowadays is to find something when I&#8217;m helping out my old team during busyhard times (you never really escape at my work). On this occasion I stopped by the forum and one thing jumped out at me. The lack of progress. Now I appreciate I&#8217;m about to unload both barrels into my foot, but I think it needs to be said.<\/p>\n<p>The same issues exist today that exists when I was dealing with <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a>\u00a0on daily bases over 20 months ago. That&#8217;s nearly 2 years. There are still people who aren&#8217;t using <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a> &#8211; you know that free tool <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> created to ease the woes of upgrades and deployments. Despite a large number of users already using it and all the major bugs being resolve. More worrying, <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> has even issued <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS2<\/a> with it&#8217;s marching orders. It&#8217;s not a question of if, but when. The last release will be Autumn 2014 unless they are forced to push it back. Again.<\/p>\n<p>I don&#8217;t think pushing it back is the answer. Pushing the date back is like putting a plaster over a gunshot wound. OK, it might help stop the bleeding, but it&#8217;s not the answer. Now I accept my approach of nagging my boss until he allowed me get on top of <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a> whilst <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> was throwing major development time at it so I can make sure it works for our\u00a0schools might not be possible for everyone. In fact it&#8217;s impossible, there aren&#8217;t enough developers to go around. But something has epically failed. Why, why, why hasn&#8217;t someone gone. Right, this needs to happen. It&#8217;s not going to go away. We have these problems:<\/p>\n<ul>\n<li><a href=\"http:\/\/www.capita-sims.co.uk\/our-products\/sims-discover-primary-schools-and-academies\" target=\"_blank\" rel=\"nofollow\">SIMS Discover<\/a> needs <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a>\u00a0&#8211; Sorry, you don&#8217;t install SIMS manually why? So why is installing Discover manually an option?<\/li>\n<li><a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a>\u00a0needs MORE access rights to installupgrade &#8211; switching UAC off is just plain stupid<\/li>\n<li>Upgrades are just a pain<\/li>\n<\/ul>\n<p>We need to resolve. Lets get <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a> setup.<\/p>\n<p>Now if your one of the support teams I&#8217;m attacking, before you start defending yourselves. Step back. Being busy\u00a0isn&#8217;t an valid excuse. If you weren&#8217;t busy, you&#8217;ll be at the job centre. Someone, either yourself or your boss should be reviewing whats happening. Regularly. If your trying to do workarounds, you&#8217;re never going to have time to implement a fix. See what your doing is a putting a plaster on a gunshot wound and stop, get to the hospital. I know smaller support teams this will be a lot harder, especially when schools are\u00a0doing their own thing, but I think this actually makes it easier.<\/p>\n<p><a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a> is a bit of a different beast. The way I explain <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a> to new IT staff is,\u00a0<a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a>\u00a0is your tool. It&#8217;s a IT technician&#8217;s tool. This tool will manage <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS\u00a0.net<\/a>\u00a0across your network &#8211; it also keeps <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a> at a safe distance so you don&#8217;t enter the mists of MIS land. At the same time it keeps the MIS manager away from any sort of Windows permissions &#8211; you&#8217;re not giving any non-IT staff administrator access to YOUR\u00a0network. System Manager is the DataMIS managers tool, it keeps people out of THEIR database, including IT staff. I&#8217;ve found this has been really useful with new IT staff coming from the &#8220;real&#8221; world and they have found the clear what you do and don&#8217;t do has helped keep them out of trouble. You do get the odd, why can&#8217;t I get a <a href=\"http:\/\/technet.microsoft.com\/en-gb\/systemcenter\/\" target=\"_blank\" rel=\"nofollow\">SCCM<\/a> package, but when you point out that would require either <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> forcing schools to buy more <a href=\"http:\/\/www.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Microsoft<\/a> licenses or them\u00a0reading more <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> documentation, they tend to go quiet.<\/p>\n<p>Now I think the issue is the MIS support people\u00a0are trying to push <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a>, when it should be the IT\u00a0support people. If you look at the problems people are having with <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a>, they are IT problems, firewall and DNS mainly. Which MIS support staff don&#8217;t resolve. IT support staff do.\u00a0If you&#8217;re now saying, but we don&#8217;t have any IT support people, it&#8217;s all third parties. What would happen if something, non-MIS related was required to be pushed out? What I&#8217;d do is organise a third party to support it, get the community together and issue training. So, find someone who has deployed <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a>\u00a0successfully and get them to do some training sessions for those pesky IT support teams. The cost of even getting even a <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/site-training-and-consultancy\" target=\"_blank\" rel=\"nofollow\">Capita trainer<\/a> in at \u00a3\u00a3\u00a3, booking a venue could be offset by charging fees to delegates and to be honest, it isn&#8217;t that much when you compare it to even 1 day of failed <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS<\/a> upgradesdeployments. Costs can be cut by using a central school as the venue, by using a non-Capita trainer, by joining forces with other local support teams or even going completely digital. Support forums like <a href=\"http:\/\/www.edugeek.net\/\" target=\"_blank\" rel=\"nofollow\">EduGeek<\/a> are a excellent way for the community to support itself with very little effort. I would also not be fussy by who attends, if they support one of your schools, offer them the training. Don&#8217;t get caught up in the fact their going to resell your knowledge. Think bigger picture.<\/p>\n<p>So, do I think their will be much progress? Do I think <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> will stick with their Autumn 2014 is the last <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS2<\/a> release?<\/p>\n<p>Well\u00a0I also noticed they still had the following documents on the <a href=\"http:\/\/support.capitaes.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SupportNet<\/a> homepage as sticky items:<\/p>\n<ul>\n<li><strong>Technical Guide &#8211; Network Impact of SIMS<\/strong><\/li>\n<li><strong>Technical Guide &#8211; Optimising SIMS .net startup speed<\/strong><\/li>\n<li><strong>Technical Guide &#8211; Remote Working with SIMS<\/strong><\/li>\n<\/ul>\n<p>Sound pretty useful, till you look at the dates, 06 April 2005, 08 April 2005 and 11th June 2004 respectively.<\/p>\n<p>Take the first one, <strong>Network Impact of SIMS<\/strong> &#8211; to quote a bit of it:<\/p>\n<blockquote><p>Unfortunately, minimum hardware specifications are set to rise as we cease support for Windows 98.<\/p>\n<p>Realistically Windows 2000 and Windows XP we would recommend a minimum of 256MB.<\/p><\/blockquote>\n<div class=\"page\" title=\"Page 8\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p>I&#8217;m sorry, didn&#8217;t <a href=\"http:\/\/www.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Microsoft<\/a> and even <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> just drop support for Windows XP? Why haven&#8217;t they updated a document that is important enough to warrant being displayed on their support portal? In over <strong>9<\/strong> years?!?<\/p>\n<p>Looking at\u00a0<strong>Optimising SIMS .net startup speed<\/strong>, why are worrying about turning the antivirus off certain directories? Aren&#8217;t our computers these days powerful enough to handle it? Surely it&#8217;ll be a good idea if we&#8217;re <strong>not<\/strong> using <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a>\u00a0and giving everyone and their dog\u00a0access to a protected folder location &#8211; Program Files. Why are we worrying about SIMSload, it&#8217;s does nothing once the <a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a>\u00a0agent gets installed. Why would anyone compress the drive nowadays?<\/p>\n<p>Remotely accessing <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a> is a hot topic &#8211; the general concession is to use RemoteApp (Terminal Services). But the &#8220;official&#8221; <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Capita<\/a> response is the\u00a0<strong>Remote Working with SIMS<\/strong> document&#8230; which says to use a VPN. I&#8217;m not a fan of this idea.\u00a0<a href=\"http:\/\/web.archive.org\/web\/20151114110121\/http:\/\/www.capita-sims.co.uk:80\/our-products\/sims-financial-management-system-fms-primary-schools-and-academies\" target=\"_blank\" rel=\"nofollow\">FMS<\/a>, the <a href=\"http:\/\/web.archive.org\/web\/20151114110121\/http:\/\/www.capita-sims.co.uk:80\/our-products\/sims-financial-management-system-fms-primary-schools-and-academies\" target=\"_blank\" rel=\"nofollow\">Capita SIMS finance package<\/a>, for starts doesn&#8217;t work well over a VPN, it&#8217;s not a speed issue, I&#8217;ve got 50MBs and that&#8217;s the lowest package I could get, it&#8217;s a latency issue. SQL doesn&#8217;t like latency. If you think of that 50MBs as the number of lanes and the latency as the speed what the cars are traveling. <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a> isn&#8217;t immune either, it just more modern, so it copes better.<\/p>\n<p>I&#8217;m sorry, but SIMS8, the next generation of <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS<\/a> which is rumoured to be in the &#8220;cloud&#8221;, can&#8217;t come fast enough for me to wash away all this silly technical problems. It&#8217;s ridiculous that things aren&#8217;t further along. Take the file sets for the School Census, I can see 4 file sets that came out in May, it&#8217;s still a manual import.\u00a0<a href=\"http:\/\/www.capita-sims.co.uk\/support-and-services\/solus\" target=\"_blank\" rel=\"nofollow\">SOLUS3<\/a>\u00a0should be deploying file sets. Automatically. The biggest strength of SIMS is the community, it&#8217;s also the biggest problem. Viva la revolution!<\/p>\n<\/div>\n<\/div>\n<\/div>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/cloud-rev1.png?ssl=1\"><img class=\"size-full wp-image-89 aligncenter\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/05\/cloud-rev.png?resize=300%2C177\" alt=\"Cloud revolution\" data-recalc-dims=\"1\" \/><\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 27 May 2014 23:39:37 +0000","created_by":1,"updated_at":"Sat, 19 Nov 2016 17:41:13 +0000","updated_by":1,"published_at":"Tue, 27 May 2014 23:39:37 +0000","published_by":1},{"id":106,"title":"(no title)","slug":"temp-slug-6","markdown":"\n\u00a0\n\n\u00a0\n\nhttp:\/\/www.jinx.com\/p\/battlefield_4_blood_womens_tee.html?catid=&preview=1&s=battlefield\n\nhttp:\/\/www.jinx.com\/p\/portal_2_undeserved_compliments_womens_tee.html?catid=&preview=1&s=portal2\n\n\n","html":"<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p>http:\/\/www.jinx.com\/p\/battlefield_4_blood_womens_tee.html?catid=&#038;preview=1&#038;s=battlefield<\/p>\n<p>http:\/\/www.jinx.com\/p\/portal_2_undeserved_compliments_womens_tee.html?catid=&#038;preview=1&#038;s=portal2<\/p>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 23 Jun 2014 22:46:25 +0000","created_by":1,"updated_at":"Mon, 23 Jun 2014 22:46:25 +0000","updated_by":1,"published_at":"","published_by":1},{"id":114,"title":"SIMS Bulk Import","slug":"temp-slug-7","markdown":"","html":"","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 23 Jun 2014 22:50:28 +0000","created_by":1,"updated_at":"Mon, 23 Jun 2014 22:50:28 +0000","updated_by":1,"published_at":"","published_by":1},{"id":116,"title":"SOLUS2, will you not just die already!","slug":"solus2-will-you-not-just-die-already","markdown":"\nWell it appears Capita has announced SOLUS2 death day\n\n\u00a0\n\n[![s2_end_twitter](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/s2_end_twitter.png?resize=562%2C166)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/s2_end_twitter1.png?ssl=1)\n\n\u00a0\n\nThat\u2019s assuming they don\u2019t put it back. Again.\n\nThis is bad news. Let me explain why.\n\nI\u2019m using Chrome, it\u2019s updated itself I don\u2019t know how many times. If I go and check, all I know or care about is that it is indeed up-to-date, so at some point, it\u2019s updated itself and its worked.\n\nIf I look at my antivirus I can see it\u2019s updated 3 times today alone. Again, this is all in the background without me doing anything.\n\nNow compare this with SIMS and SOLUS2. I wonder how many hours I\u2019ve wasted supporting schools doing SOLUS2 upgrades in my past life. I dread to think.\n\nBefore you start waiving the MSI flag, let stop and have a look at the outstanding CR logged on SupportNet today (24\/06\/2014) for the past year. [Extract here](http:\/\/matt40k.uk\/wp-content\/uploads\/2014\/06\/Capita-SIMS-Outstanding-CRs1.xlsx).\n\n> # **1,057**\n\n1,057,outstanding change request. All requested by end-users. All with positive votes.\n\n<span style=\"line-height: 1.5;\">1,057.\u00a0<\/span><span style=\"line-height: 1.5;\">Wow.\u00a0<\/span><span style=\"line-height: 1.5;\">I dread to think how many have gone unlogged or is older then a year!!<\/span>\n\nCapita clearly can\u2019t roll them up into a major build. How many re-releases have you seen? Add the fact\u00a0it doesn\u2019t even seem to be making a dent in CR mountain and you can see why Capita wants to be Agile like the [other](http:\/\/www.bromcom.com\/)\u00a0[MIS](http:\/\/www.scholarpack.com\/) [suppliers](http:\/\/www.arbor-education.com\/).\n\nNot sure I fancy pushing out 1,057 updates\u2026 per school\u2026\n\n\n","html":"<p>Well it appears Capita has announced SOLUS2 death day<\/p>\n<p>&nbsp;<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/s2_end_twitter1.png?ssl=1\"><img class=\"alignnone size-full wp-image-117\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/s2_end_twitter.png?resize=562%2C166\" alt=\"s2_end_twitter\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>&nbsp;<\/p>\n<p>That&#8217;s assuming they don&#8217;t put it back. Again.<\/p>\n<p>This is bad news. Let me explain why.<\/p>\n<p>I&#8217;m using Chrome, it&#8217;s updated itself I don&#8217;t know how many times. If I go and check, all I know or care about is that it is indeed up-to-date, so at some point, it&#8217;s updated itself and its worked.<\/p>\n<p>If I look at my antivirus I can see it&#8217;s updated 3 times today alone. Again, this is all in the background without me doing anything.<\/p>\n<p>Now compare this with SIMS and SOLUS2. I wonder how many hours I&#8217;ve wasted supporting schools doing SOLUS2 upgrades in my past life. I dread to think.<\/p>\n<p>Before you start waiving the MSI flag, let stop and have a look at the outstanding CR logged on SupportNet today (24\/06\/2014) for the past year. <a href=\"http:\/\/matt40k.uk\/wp-content\/uploads\/2014\/06\/Capita-SIMS-Outstanding-CRs1.xlsx\">Extract here<\/a>.<\/p>\n<blockquote>\n<h1><strong>1,057<\/strong><\/h1>\n<\/blockquote>\n<p>1,057,outstanding change request. All requested by end-users. All with positive votes.<\/p>\n<p><span style=\"line-height: 1.5;\">1,057.\u00a0<\/span><span style=\"line-height: 1.5;\">Wow.\u00a0<\/span><span style=\"line-height: 1.5;\">I dread to think how many have gone unlogged or is older then a year!!<\/span><\/p>\n<p>Capita clearly can&#8217;t roll them up into a major build. How many re-releases have you seen? Add the fact\u00a0it doesn&#8217;t even seem to be making a dent in CR mountain and you can see why Capita wants to be Agile like the <a href=\"http:\/\/www.bromcom.com\/\" target=\"_blank\" rel=\"nofollow\">other<\/a>\u00a0<a href=\"http:\/\/www.scholarpack.com\/\" target=\"_blank\" rel=\"nofollow\">MIS<\/a> <a href=\"http:\/\/www.arbor-education.com\/\" target=\"_blank\" rel=\"nofollow\">suppliers<\/a>.<\/p>\n<p>Not sure I fancy pushing out 1,057 updates&#8230; per school&#8230;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 24 Jun 2014 20:06:34 +0000","created_by":1,"updated_at":"Wed, 22 Jul 2015 13:03:46 +0000","updated_by":1,"published_at":"Tue, 24 Jun 2014 20:06:34 +0000","published_by":1},{"id":123,"title":"How not to write a newsletter","slug":"how-not-to-write-a-newsletter","markdown":"\nI received NameCheap newsletter today full of annoying holes (at least for me), needless to say I hit the unsubscribe button shortly after.\n\n[![namecheap1](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/namecheap1.png?resize=631%2C286)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/namecheap1.png?ssl=1)\n\n\u00a0\n\nFirst mistake \u2013 mark your calendars. Did they not check their calendar before sending it? The June 10 was 2 weeks ago!\n\n$1, one dollar!! You\u2019re trying to promote .UK, use the local currency, using \u00a3 (GBP)!\n\n\u00a0\n\n[![namecheap2](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/namecheap2.png?resize=634%2C401)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/namecheap2.png?ssl=1)\n\n\u00a0\n\nFinal mistake I notice (I didn\u2019t look very hard to be honest) was the \u201cSCHOOLSOUT\u201d code. Sorry,\u00a0that\u2019s not till next month. Perhaps someone should buy NameCheap a calendar.\n\n\n","html":"<p>I received NameCheap newsletter today full of annoying holes (at least for me), needless to say I hit the unsubscribe button shortly after.<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/namecheap1.png?ssl=1\"><img class=\"alignnone size-full wp-image-124\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/namecheap1.png?resize=631%2C286\" alt=\"namecheap1\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>&nbsp;<\/p>\n<p>First mistake &#8211; mark your calendars. Did they not check their calendar before sending it? The June 10 was 2 weeks ago!<\/p>\n<p>$1, one dollar!! You&#8217;re trying to promote .UK, use the local currency, using \u00a3 (GBP)!<\/p>\n<p>&nbsp;<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/namecheap2.png?ssl=1\"><img class=\"alignnone size-full wp-image-125\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/06\/namecheap2.png?resize=634%2C401\" alt=\"namecheap2\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>&nbsp;<\/p>\n<p>Final mistake I notice (I didn&#8217;t look very hard to be honest) was the &#8220;SCHOOLSOUT&#8221; code. Sorry,\u00a0that&#8217;s not till next month. Perhaps someone should buy NameCheap a calendar.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 24 Jun 2014 20:41:04 +0000","created_by":1,"updated_at":"Wed, 22 Jul 2015 13:03:35 +0000","updated_by":1,"published_at":"Tue, 24 Jun 2014 20:41:04 +0000","published_by":1},{"id":129,"title":"Why Microsoft Business Intelligence is on my radar","slug":"why-microsoft-business-intelligence-is-on-my-radar","markdown":"\nIn my day job I\u2019ve been looking at SQL Server 2012 recently (I know SQL Server 2014 out before you say anything!), I\u2019ve had a developer license for a while but unfortunately other priorities have\u00a0been consuming my time and I\u2019ve only managed to get a dev server build, SQL 2012 installed and not much else up till a few days ago.\n\nOur current Business Intelligence platform is using SQL Server 2008 (not R2) for the database backend and SQL Server Integration Services (SSIS) BIDS for the ETL. We use IBM Cognos Business Intelligence for the presentation layer, which we upgraded to 10.2.1 at the being of the year from 8.4.1, after a massive sprint with a mix of in house and a third party company. In total we created over 100 reports in about 6 months between us! Half of them being created by us\u00a0in house staff \u2013 which was\u00a02 full-time report writers (me being one) and the odd bit of time\u00a0from the 2 report writers when it got a bit hairy. It was nice upgrading to 10.2.1, other then waiting for Fix Pack 2 to resolve the Tomcat memory leak, as allowed me to sink my teeth into the technical side which is my background \u2013 techy. Beyond the techy side of it it was\u00a0a big team effort to get some of the reports re-written as the method we used to do the drill-downhierarchy was \u201cfixed\u201d in 10.2.1 so it stopped working and after battling for days with\u00a0ancestors we just re-did it. It did give us really good in-depth knowledge of the reports the third party had written which has helped us supporting them going forward and also helped us improve our techniques\u00a0and knowledge \u2013 we\u2019re always re-factoring our work to bring about improvements!\n\nA few weeks ago, we had to novate our Cognos license, turns out, at the last minute I might add, we couldn\u2019t do it. IBM wouldn\u2019t allow it. So we had to relicense. IBM had just hit our list of suppliers we don\u2019t like.\u00a0Bad news, big bill, good news, all our licenses now had Query Studio licenses \u2013 ie they can run ad-hoc queries. Bad news, our models are really designed for our static reports and our staff aren\u2019t all trained in Query Studio. Starting to see why we\u2019re looking at other BI tools?\n\nSo, I basically started looking at\u00a0Microsoft BI because\u2026\n\n- I had a developer license for SQL 2012 \u2013 cost, less then \u00a320, which allowed me to build and demo anything I created. IE I\u2019m not spend thousands on a tool that I maybe able to use without expensive training\n- Our data warehouse is SQL Server\n- We had just signed a Microsoft Enterprise Agreement\n- Our staff know Excel \u2013 everything ends up in Excel data wise\n\n\u00a0\n\n\u00a0\n\n\n","html":"<p>In my day job I&#8217;ve been looking at SQL Server 2012 recently (I know SQL Server 2014 out before you say anything!), I&#8217;ve had a developer license for a while but unfortunately other priorities have\u00a0been consuming my time and I&#8217;ve only managed to get a dev server build, SQL 2012 installed and not much else up till a few days ago.<\/p>\n<p>Our current Business Intelligence platform is using SQL Server 2008 (not R2) for the database backend and SQL Server Integration Services (SSIS)  BIDS for the ETL. We use IBM Cognos Business Intelligence for the presentation layer, which we upgraded to 10.2.1 at the being of the year from 8.4.1, after a massive sprint with a mix of in house and a third party company. In total we created over 100 reports in about 6 months between us! Half of them being created by us\u00a0in house staff &#8211; which was\u00a02 full-time report writers (me being one) and the odd bit of time\u00a0from the 2 report writers when it got a bit hairy. It was nice upgrading to 10.2.1, other then waiting for Fix Pack 2 to resolve the Tomcat memory leak, as allowed me to sink my teeth into the technical side which is my background &#8211; techy. Beyond the techy side of it it was\u00a0a big team effort to get some of the reports re-written as the method we used to do the drill-downhierarchy was &#8220;fixed&#8221; in 10.2.1 so it stopped working and after battling for days with\u00a0ancestors we just re-did it. It did give us really good in-depth knowledge of the reports the third party had written which has helped us supporting them going forward and also helped us improve our techniques\u00a0and knowledge &#8211; we&#8217;re always re-factoring our work to bring about improvements!<\/p>\n<p>A few weeks ago, we had to novate our Cognos license, turns out, at the last minute I might add, we couldn&#8217;t do it. IBM wouldn&#8217;t allow it. So we had to relicense. IBM had just hit our list of suppliers we don&#8217;t like.\u00a0Bad news, big bill, good news, all our licenses now had Query Studio licenses &#8211; ie they can run ad-hoc queries. Bad news, our models are really designed for our static reports and our staff aren&#8217;t all trained in Query Studio. Starting to see why we&#8217;re looking at other BI tools?<\/p>\n<p>So, I basically started looking at\u00a0Microsoft BI because&#8230;<\/p>\n<ul>\n<li>I had a developer license for SQL 2012 &#8211; cost, less then \u00a320, which allowed me to build and demo anything I created. IE I&#8217;m not spend thousands on a tool that I maybe able to use without expensive training<\/li>\n<li>Our data warehouse is SQL Server<\/li>\n<li>We had just signed a Microsoft Enterprise Agreement<\/li>\n<li>Our staff know Excel &#8211; everything ends up in Excel data wise<\/li>\n<\/ul>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Thu, 03 Jul 2014 23:11:40 +0000","created_by":1,"updated_at":"Thu, 03 Jul 2014 23:11:40 +0000","updated_by":1,"published_at":"Thu, 03 Jul 2014 23:11:40 +0000","published_by":1},{"id":132,"title":"Primary Interop Assemblies","slug":"temp-slug-11","markdown":"\n\u00a0\n\n\u00a0\n\nhttp:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=18346\n\nhttp:\/\/www.microsoft.com\/en-gb\/download\/details.aspx?id=10\n\n\n","html":"<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p>http:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=18346<\/p>\n<p>http:\/\/www.microsoft.com\/en-gb\/download\/details.aspx?id=10<\/p>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 05 Jul 2014 00:35:43 +0000","created_by":1,"updated_at":"Sat, 05 Jul 2014 00:35:43 +0000","updated_by":1,"published_at":"","published_by":1},{"id":134,"title":"Created new user is disabled","slug":"created-new-user-is-disabled","markdown":"\nI\u2019ve created a new SQL user along with a new role\u00a0in our warehouse db project using Visual Studio 2012.\n\n> CREATE LOGIN [newuser] WITHPASSWORD='{{ RANDOM PASSWORD }}\u2019,DEFAULT_DATABASE=[Database]  \n>  GO\n> \n> CREATE USER [newuser] FORLOGIN [newuser] WITHDEFAULT_SCHEMA=[dbo]\n> \n> GO\n> \n> ALTER ROLE [newrole] ADD MEMBER [newuser]\n> \n> GO\n\n\u00a0\n\nProblem is, the user is disabled. When you do it manually via SQL Management Studio, it\u2019s enabled and working. Manually enabling the account doesn\u2019t allow it connect either. A quick Google revealed:\n\n[http:\/\/www.sqlhammer.com\/blog\/creating-logins-and-users-why-i-cant-connect\/](http:\/\/www.sqlhammer.com\/blog\/creating-logins-and-users-why-i-cant-connect\/)\n\nBingo. Appears I need to add the following to the end of the script:\n\n> \u00a0GRANT CONNECT TO [newuser]\n\n\n","html":"<p>I&#8217;ve created a new SQL user along with a new role\u00a0in our warehouse db project using Visual Studio 2012.<\/p>\n<blockquote><p>CREATE LOGIN [newuser] WITHPASSWORD='{{ RANDOM PASSWORD }}&#8217;,DEFAULT_DATABASE=[Database]<br \/>\nGO<\/p>\n<p>CREATE USER [newuser] FORLOGIN [newuser] WITHDEFAULT_SCHEMA=[dbo]<\/p>\n<p>GO<\/p>\n<p>ALTER ROLE [newrole] ADD MEMBER [newuser]<\/p>\n<p>GO<\/p><\/blockquote>\n<p>&nbsp;<\/p>\n<p>Problem is, the user is disabled. When you do it manually via SQL Management Studio, it&#8217;s enabled and working. Manually enabling the account doesn&#8217;t allow it connect either. A quick Google revealed:<\/p>\n<p><a href=\"http:\/\/www.sqlhammer.com\/blog\/creating-logins-and-users-why-i-cant-connect\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/www.sqlhammer.com\/blog\/creating-logins-and-users-why-i-cant-connect\/<\/a><\/p>\n<p>Bingo. Appears I need to add the following to the end of the script:<\/p>\n<blockquote><p>\u00a0GRANT CONNECT TO [newuser]<\/p><\/blockquote>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 14 Jul 2014 11:41:18 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:03:53 +0000","updated_by":1,"published_at":"Mon, 14 Jul 2014 11:41:18 +0000","published_by":1},{"id":112,"title":"Tron","slug":"tron","markdown":"\nFound this little gem \u2013 appears they actually made those really cool interfaces they used in Tron Legacy:\u00a0[http:\/\/www.robscanlon.com\/encom-boardroom\/](http:\/\/www.robscanlon.com\/encom-boardroom\/ \"This external link will open in a new window\")\n\n\n","html":"<p>Found this little gem &#8211; appears they actually made those really cool interfaces they used in Tron Legacy:\u00a0<a style=\"color: purple;\" title=\"This external link will open in a new window\" href=\"http:\/\/www.robscanlon.com\/encom-boardroom\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/www.robscanlon.com\/encom-boardroom\/<\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 14 Jul 2014 11:46:36 +0000","created_by":1,"updated_at":"Fri, 10 Jun 2016 21:07:23 +0000","updated_by":1,"published_at":"Mon, 14 Jul 2014 11:46:36 +0000","published_by":1},{"id":110,"title":"What SOLUS 3.7 should of looked like","slug":"temp-slug-14","markdown":"\nSo Capita have released version 3.7 of SOLUS, below is the release info published by Capita.\n\n> **SOLUS 3.7 release information**\u00a0\n> \n> <div>**SOLUS3.7 release**<\/div><div>The forthcoming SOLUS3.7 update will be released on Friday the 20th\u00a0of June. It will contain the following new features and improvements.<\/div><div><\/div><div>- <span style=\"font-family: Georgia, 'Bitstream Charter', serif; font-style: italic;\">a complete re-design of the SOLUS3 User Interface making it easier to use and quicker to perform key tasks.<\/span>\n> - <span style=\"font-family: Georgia, 'Bitstream Charter', serif; font-style: italic;\">the ability to issue application fixes to SIMS workstations. This will help reduce the need to apply whole platform re-releases in the case of a critical fix in the front end being identified in a release.<\/span>\n> \n> <\/div><div>**NOTE:**<\/div><div>The new deployment service user interface will require .NET framework 4.5 or above on the deployment server (only).<\/div><div><\/div><div>As part of the SOLUS3.7 update it will download the .NET framework 4.5.0 update and apply it to the Deployment Server. This .NET framework update has been set to not automatically reboot.<\/div>\n\n<div><\/div>\n","html":"<p>So Capita have released version 3.7 of SOLUS, below is the release info published by Capita.<\/p>\n<blockquote \n<p> <strong>SOLUS 3.7 release information<\/strong><\/p>\n<p>&nbsp;<\/p>\n<div><strong>SOLUS3.7 release<\/strong><\/div>\n<div>The forthcoming SOLUS3.7 update will be released on Friday the 20th\u00a0of June. It will contain the following new features and improvements.<\/div>\n<div><\/div>\n<div>\n<ul>\n<li><span style=\"font-family: Georgia, 'Bitstream Charter', serif; font-style: italic;\">a complete re-design of the SOLUS3 User Interface making it easier to use and quicker to perform key tasks.<\/span><\/li>\n<li><span style=\"font-family: Georgia, 'Bitstream Charter', serif; font-style: italic;\">the ability to issue application fixes to SIMS workstations. This will help reduce the need to apply whole platform re-releases in the case of a critical fix in the front end being identified in a release.<\/span><\/li>\n<\/ul>\n<\/div>\n<div><strong>NOTE:<\/strong><\/div>\n<div>The new deployment service user interface will require .NET framework 4.5 or above on the deployment server (only).<\/div>\n<div><\/div>\n<div>As part of the SOLUS3.7 update it will download the .NET framework 4.5.0 update and apply it to the Deployment Server. This .NET framework update has been set to not automatically reboot.<\/div>\n<\/blockquote>\n<div><\/div>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 14 Jul 2014 11:48:22 +0000","created_by":1,"updated_at":"Mon, 14 Jul 2014 11:48:22 +0000","updated_by":1,"published_at":"","published_by":1},{"id":108,"title":"Clear Visual Studio recent projects","slug":"clear-visual-studio-recent-projects","markdown":"\nAnother little gem, clearing out those pesky recent projects from your menu on Visual Studio 2012. Fire up RegEdit\u00a0and navigate to:\n\n- Files: HKCU\\SOFTWARE\\Microsoft\\Visual Studio\\11.0\\FileMRUList\\\n- Proj: HKCU\\SOFTWARE\\Microsoft\\Visual Studio\\11.0\\ProjectMRUList\\\n\nUsual disclaimer  \n[http:\/\/nathondalton.wordpress.com\/2011\/10\/13\/clear-visual-studio-recent-project-and-files\/](http:\/\/nathondalton.wordpress.com\/2011\/10\/13\/clear-visual-studio-recent-project-and-files\/ \"This external link will open in a new window\")\n\n\n","html":"<p>Another little gem, clearing out those pesky recent projects from your menu on Visual Studio 2012. Fire up RegEdit\u00a0and navigate to:<\/p>\n<ul>\n<li>Files: HKCU\\SOFTWARE\\Microsoft\\Visual Studio\\11.0\\FileMRUList\\<\/li>\n<li>Proj: HKCU\\SOFTWARE\\Microsoft\\Visual Studio\\11.0\\ProjectMRUList\\<\/li>\n<\/ul>\n<p>Usual disclaimer<br \/>\n<a style=\"color: purple;\" title=\"This external link will open in a new window\" href=\"http:\/\/nathondalton.wordpress.com\/2011\/10\/13\/clear-visual-studio-recent-project-and-files\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/nathondalton.wordpress.com\/2011\/10\/13\/clear-visual-studio-recent-project-and-files\/<\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 14 Jul 2014 11:55:43 +0000","created_by":1,"updated_at":"Sat, 20 Jun 2015 20:24:34 +0000","updated_by":1,"published_at":"Mon, 14 Jul 2014 11:55:43 +0000","published_by":1},{"id":151,"title":"The term 'Invoke-WebRequest' is not recognized","slug":"the-term-invoke-webrequest-is-not-recognized","markdown":"\nI\u2019ve currently been working on a PowerShell script to build a virtual server using [DigitalOcean](https:\/\/www.digitalocean.com\/) excellent [RESTful API](https:\/\/developers.digitalocean.com\/). So far this has gone extremely well and I have been\u00a0impressed with both PowerShell and [DigitalOcean\u2019s](https:\/\/www.digitalocean.com\/) [API](https:\/\/developers.digitalocean.com\/). Today however I tried running on another machine (an important part of development) only to find it doesn\u2019t work. The first error that appears is:\n\n> The term \u2018Invoke-WebRequest\u2019 is not recognized as the name of a cmdlet, function, script file, or operable progr  \n>  am. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.  \n>  At line:1 char:18  \n>  + Invoke-WebRequest <<<<  \n>  + CategoryInfo\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 : ObjectNotFound: (Invoke-WebRequest:String) [], CommandNotFoundException  \n>  + FullyQualifiedErrorId : CommandNotFoundException\n\nIn simple terms it\u2019s saying it can\u2019t find the\u00a0<span style=\"font-style: italic;\">\u2018Invoke-WebRequest\u2019 cmdlet. This should be a built-in cmdlet in PowerShell, so off I went to TechNet to find the details of the cmdlet \u2013\u00a0<\/span>\n\n[http:\/\/technet.microsoft.com\/en-us\/library\/hh849901.aspx](http:\/\/technet.microsoft.com\/en-us\/library\/hh849901.aspx)\n\nThe key bit of information was this line:\n\n> <span style=\"color: #2a2a2a;\">This cmdlet was introduced in Windows PowerShell 3.0.<\/span>\n\nThe other way is at the top of such documents on TechNet it defaults to the most recent version of the, in this case, cmdlet and next to it gives you the option select a older version, clicking it reveals previous versions and does indeed confirm the above statement that it was not present in any version of PowerShell prior to 3.0.\n\n<figure class=\"wp-caption aligncenter\" id=\"attachment_155\" style=\"width: 654px\">[![TechNet](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/07\/invoke-webrequest.png?resize=654%2C394)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/08\/invoke-webrequest1.png?ssl=1)<figcaption class=\"wp-caption-text\">TechNet<\/figcaption><\/figure>Next question, is PowerShell 4.0 installed? Well for Windows 8.1 and Windows Server 2012 R2 it\u2019s built-in, you can check by running (in PowerShell)\n\n> `$PSVersionTable.PSVersion`\n\nsure enough, the other machine (which is Windows 7 Enterprise x64) returns\n\n> Major\u00a0 Minor\u00a0 Build\u00a0 Revision  \n>  \u2014\u2013\u00a0 \u2014\u2013\u00a0 \u2014\u2013\u00a0 \u2014\u2014\u2013  \n>  2\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0 -1\u00a0\u00a0\u00a0\u00a0 -1\n\nFor help installing PowerShell 4.0 go to:\u00a0[http:\/\/social.technet.microsoft.com\/wiki\/contents\/articles\/21016.how-to-install-windows-powershell-4-0.aspx](http:\/\/social.technet.microsoft.com\/wiki\/contents\/articles\/21016.how-to-install-windows-powershell-4-0.aspx)\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\n","html":"<p>I&#8217;ve currently been working on a PowerShell script to build a virtual server using <a href=\"https:\/\/www.digitalocean.com\/\" target=\"_blank\" rel=\"nofollow\">DigitalOcean<\/a> excellent <a href=\"https:\/\/developers.digitalocean.com\/\" target=\"_blank\" rel=\"nofollow\">RESTful API<\/a>. So far this has gone extremely well and I have been\u00a0impressed with both PowerShell and <a href=\"https:\/\/www.digitalocean.com\/\" target=\"_blank\" rel=\"nofollow\">DigitalOcean&#8217;s<\/a> <a href=\"https:\/\/developers.digitalocean.com\/\" target=\"_blank\" rel=\"nofollow\">API<\/a>. Today however I tried running on another machine (an important part of development) only to find it doesn&#8217;t work. The first error that appears is:<\/p>\n<blockquote><p>The term &#8216;Invoke-WebRequest&#8217; is not recognized as the name of a cmdlet, function, script file, or operable progr<br \/>\nam. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.<br \/>\nAt line:1 char:18<br \/>\n+ Invoke-WebRequest &lt;&lt;&lt;&lt;<br \/>\n+ CategoryInfo\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 : ObjectNotFound: (Invoke-WebRequest:String) [], CommandNotFoundException<br \/>\n+ FullyQualifiedErrorId : CommandNotFoundException<\/p><\/blockquote>\n<p>In simple terms it&#8217;s saying it can&#8217;t find the\u00a0<span style=\"font-style: italic;\">&#8216;Invoke-WebRequest&#8217; cmdlet. This should be a built-in cmdlet in PowerShell, so off I went to TechNet to find the details of the cmdlet &#8211;\u00a0<\/span><\/p>\n<p><a href=\"http:\/\/technet.microsoft.com\/en-us\/library\/hh849901.aspx\" target=\"_blank\" rel=\"nofollow\">http:\/\/technet.microsoft.com\/en-us\/library\/hh849901.aspx<\/a><\/p>\n<p>The key bit of information was this line:<\/p>\n<blockquote><p><span style=\"color: #2a2a2a;\">This cmdlet was introduced in Windows PowerShell 3.0.<\/span><\/p><\/blockquote>\n<p>The other way is at the top of such documents on TechNet it defaults to the most recent version of the, in this case, cmdlet and next to it gives you the option select a older version, clicking it reveals previous versions and does indeed confirm the above statement that it was not present in any version of PowerShell prior to 3.0.<\/p>\n<figure id=\"attachment_155\" style=\"width: 654px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/08\/invoke-webrequest1.png?ssl=1\"><img class=\"wp-image-155 size-full\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/07\/invoke-webrequest.png?resize=654%2C394\" alt=\"TechNet\" data-recalc-dims=\"1\" \/><\/a><figcaption class=\"wp-caption-text\">TechNet<\/figcaption><\/figure>\n<p>Next question, is PowerShell 4.0 installed? Well for Windows 8.1 and Windows Server 2012 R2 it&#8217;s built-in, you can check by running (in PowerShell)<\/p>\n<blockquote>\n<pre><code>$PSVersionTable.PSVersion<\/code><\/pre>\n<\/blockquote>\n<p>sure enough, the other machine (which is Windows 7 Enterprise x64) returns<\/p>\n<blockquote><p>Major\u00a0 Minor\u00a0 Build\u00a0 Revision<br \/>\n&#8212;&#8211;\u00a0 &#8212;&#8211;\u00a0 &#8212;&#8211;\u00a0 &#8212;&#8212;&#8211;<br \/>\n2\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0 -1\u00a0\u00a0\u00a0\u00a0 -1<\/p><\/blockquote>\n<p>For help installing PowerShell 4.0 go to:\u00a0<a href=\"http:\/\/social.technet.microsoft.com\/wiki\/contents\/articles\/21016.how-to-install-windows-powershell-4-0.aspx\" target=\"_blank\" rel=\"nofollow\">http:\/\/social.technet.microsoft.com\/wiki\/contents\/articles\/21016.how-to-install-windows-powershell-4-0.aspx<\/a><\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 23 Jul 2014 22:02:05 +0000","created_by":1,"updated_at":"Wed, 22 Jul 2015 13:03:09 +0000","updated_by":1,"published_at":"Wed, 23 Jul 2014 22:02:05 +0000","published_by":1},{"id":161,"title":"SQLCambs","slug":"sqlcambs","markdown":"\nWell my day is finally coming to an end, my bed is calling me after a long day. If I had thought about it more I would have packed a few cans of Pepsi Max and probability took a half day at work, as it was I spent my lunch break by coming home and taking my son to the park*, then heading off to Cambridge after work for mine and my colleagues first\u00a0<span style=\"color: #3b3b3b;\">[Cambridgeshire SQL Server User Group](http:\/\/sqlcambs.blogspot.co.uk\/). I thought I\u2019d write a blog post about the event whilst everything is still fresh in my head and my dinner is still\u00a0going down.<\/span>\n\nFirst up, the venue, [Redgate\u2019s](http:\/\/www.red-gate.com\/) office in the Cambridge Business Park (also the same business park that\u00a0[Mythic-Beasts](http:\/\/www.mythic-beasts.com\/) has a data centre in) was fantastic. You really did get the feeling they practice what they preach and they really have embraced the agile culture. It\u00a0really is visible in their environment \u2013 I have to\u00a0admit the floor to ceiling room divider whiteboard did (sadly) give me a bit of envy and I was thinking if I could get away with turning the cupboards at work into a giant whiteboard.\n\nThe\u00a0[Cambridgeshire SQL Server User Group](http:\/\/sqlcambs.blogspot.co.uk\/)\u00a0is ran by\u00a0[Mark Broadbent](https:\/\/twitter.com\/retracement)\u00a0who I assume is doing these events as part of some\u00a0Microsoft-y requirement\u00a0of mentoring. Whatever his reasons, it\u2019s great his doing it. This especially rang true in the second half of the event when [Alex](https:\/\/twitter.com\/_AlexYates_) from\u00a0[Redgate](http:\/\/www.red-gate.com\/)\u00a0started\u00a0taking about the importance of\u00a0[Redgate](http:\/\/www.red-gate.com\/)\u00a0database version control software. To [Alex](https:\/\/twitter.com\/_AlexYates_) credit, he did do a good job showing\u00a0[Redgate](http:\/\/www.red-gate.com\/)\u00a0products whilst at the same time not feeling like we just entered a\u00a0sales pitch meeting and we\u2019re going spend the next 6 months getting spammed with sales calls. I really appreciate when people put these types of events together, the low pressure, honest events where you can see the product but then not have your phone ring every 5 mins asking when the orders going to arrive. It also gives a chance to see how other people in different areas are having the same problems as well as\u00a0get some honest feedback about products and companies from real end users \u2013 ie not managers who will spend 20 mins talking about how great it is despite never using or having any real knowledge about it.\n\nThe first session was by\u00a0[Dave Ballantyne](https:\/\/twitter.com\/davebally) on statistics, a subject, if I\u2019m being honest, doesn\u2019t particularly feel me with much excitement. My colleague on the other hand, they are the difference between a quiet day or a day with a number of managers hovering over your desk ask why everything is so slow. Despite my lack of excitement and my colleague previous \u00a0attempts to explain it to me, I did feel I left, after a 1 hr session I might add, having a better understanding. I should at least have a clue why I\u2019m having problems later on and where to start looking. Don\u2019t get me wrong, I\u2019m not going to go looking at it until it happens!\n\nThe second and final session was by\u00a0[Alex Yates](https:\/\/twitter.com\/_AlexYates_) who works at\u00a0[Redgate](http:\/\/www.red-gate.com\/)\u00a0on \u201cBuilding an automated database deployment pipeline\u201d. In short, automating how you get the new stuff into production. One of my bug bears is how we deploy. It\u2019s manual. I won\u2019t go into detail, I\u2019ll leave that for another post, this was basically the sales pitch of the day which I suspect\u00a0might of been the cost of the free venue\u2026 food\u2026 drinks\u2026 books\u2026. lanyards. Still the message\u00a0was a important one and it needs to be heard. DevOps is the future. And Redgate is your friendly company who will help you get there.\n\nSo, would I go again? Yes. Would I recommend it? Totally. Amazing what can come from putting \u201ccambridgeshire\u201d and \u201csql\u201d into twitter\u2019s search box will lead you too \ud83d\ude42\n\n\u00a0\n\n* I main issue I have with evening events is childcare, my girlfriend works evenings so I normally playing Lego whilst these sorts of events go on, \u00a0luckily (well actually\u00a0unluckily) she broke her ankle and is signed off work for 6 weeks with her leg in a cast \u2013 so I now have childcare in the evenings for the next, well now 5, weeks. I just had to get my son out the house which involved a late long lunch and a trip to the park.\n\n\n","html":"<p>Well my day is finally coming to an end, my bed is calling me after a long day. If I had thought about it more I would have packed a few cans of Pepsi Max and probability took a half day at work, as it was I spent my lunch break by coming home and taking my son to the park*, then heading off to Cambridge after work for mine and my colleagues first\u00a0<span style=\"color: #3b3b3b;\"><a href=\"http:\/\/sqlcambs.blogspot.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Cambridgeshire SQL Server User Group<\/a>. I thought I&#8217;d write a blog post about the event whilst everything is still fresh in my head and my dinner is still\u00a0going down.<\/span><\/p>\n<p>First up, the venue, <a href=\"http:\/\/www.red-gate.com\/\" target=\"_blank\" rel=\"nofollow\">Redgate&#8217;s<\/a> office in the Cambridge Business Park (also the same business park that\u00a0<a href=\"http:\/\/www.mythic-beasts.com\/\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a> has a data centre in) was fantastic. You really did get the feeling they practice what they preach and they really have embraced the agile culture. It\u00a0really is visible in their environment &#8211; I have to\u00a0admit the floor to ceiling room divider  whiteboard did (sadly) give me a bit of envy and I was thinking if I could get away with turning the cupboards at work into a giant whiteboard.<\/p>\n<p>The\u00a0<a href=\"http:\/\/sqlcambs.blogspot.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Cambridgeshire SQL Server User Group<\/a>\u00a0is ran by\u00a0<a href=\"https:\/\/twitter.com\/retracement\" target=\"_blank\" rel=\"nofollow\">Mark Broadbent<\/a>\u00a0who I assume is doing these events as part of some\u00a0Microsoft-y requirement\u00a0of mentoring. Whatever his reasons, it&#8217;s great his doing it. This especially rang true in the second half of the event when <a href=\"https:\/\/twitter.com\/_AlexYates_\" target=\"_blank\" rel=\"nofollow\">Alex<\/a> from\u00a0<a href=\"http:\/\/www.red-gate.com\/\" target=\"_blank\" rel=\"nofollow\">Redgate<\/a>\u00a0started\u00a0taking about the importance of\u00a0<a href=\"http:\/\/www.red-gate.com\/\" target=\"_blank\" rel=\"nofollow\">Redgate<\/a>\u00a0database version control software. To <a href=\"https:\/\/twitter.com\/_AlexYates_\" target=\"_blank\" rel=\"nofollow\">Alex<\/a> credit, he did do a good job showing\u00a0<a href=\"http:\/\/www.red-gate.com\/\" target=\"_blank\" rel=\"nofollow\">Redgate<\/a>\u00a0products whilst at the same time not feeling like we just entered a\u00a0sales pitch meeting and we&#8217;re going spend the next 6 months getting spammed with sales calls. I really appreciate when people put these types of events together, the low pressure, honest events where you can see the product but then not have your phone ring every 5 mins asking when the orders going to arrive. It also gives a chance to see how other people in different areas are having the same problems as well as\u00a0get some honest feedback about products and companies from real end users &#8211; ie not managers who will spend 20 mins talking about how great it is despite never using or having any real knowledge about it.<\/p>\n<p>The first session was by\u00a0<a href=\"https:\/\/twitter.com\/davebally\" target=\"_blank\" rel=\"nofollow\">Dave Ballantyne<\/a> on statistics, a subject, if I&#8217;m being honest, doesn&#8217;t particularly feel me with much excitement. My colleague on the other hand, they are the difference between a quiet day or a day with a number of managers hovering over your desk ask why everything is so slow. Despite my lack of excitement and my colleague previous \u00a0attempts to explain it to me, I did feel I left, after a 1 hr session I might add, having a better understanding. I should at least have a clue why I&#8217;m having problems later on and where to start looking. Don&#8217;t get me wrong, I&#8217;m not going to go looking at it until it happens!<\/p>\n<p>The second and final session was by\u00a0<a href=\"https:\/\/twitter.com\/_AlexYates_\" target=\"_blank\" rel=\"nofollow\">Alex Yates<\/a> who works at\u00a0<a href=\"http:\/\/www.red-gate.com\/\" target=\"_blank\" rel=\"nofollow\">Redgate<\/a>\u00a0on &#8220;Building an automated database deployment pipeline&#8221;. In short, automating how you get the new stuff into production. One of my bug bears is how we deploy. It&#8217;s manual. I won&#8217;t go into detail, I&#8217;ll leave that for another post, this was basically the sales pitch of the day which I suspect\u00a0might of been the cost of the free venue&#8230; food&#8230; drinks&#8230; books&#8230;. lanyards. Still the message\u00a0was a important one and it needs to be heard. DevOps is the future. And Redgate is your friendly company who will help you get there.<\/p>\n<p>So, would I go again? Yes. Would I recommend it? Totally. Amazing what can come from putting &#8220;cambridgeshire&#8221; and &#8220;sql&#8221; into twitter&#8217;s search box will lead you too \ud83d\ude42<\/p>\n<p>&nbsp;<\/p>\n<p>* I main issue I have with evening events is childcare, my girlfriend works evenings so I normally playing Lego whilst these sorts of events go on, \u00a0luckily (well actually\u00a0unluckily) she broke her ankle and is signed off work for 6 weeks with her leg in a cast &#8211; so I now have childcare in the evenings for the next, well now 5, weeks. I just had to get my son out the house which involved a late long lunch and a trip to the park.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 01 Aug 2014 00:25:43 +0000","created_by":1,"updated_at":"Fri, 01 Aug 2014 00:25:43 +0000","updated_by":1,"published_at":"Fri, 01 Aug 2014 00:25:43 +0000","published_by":1},{"id":185,"title":"PowerShell, DigitalOcean and WordPress","slug":"powershell_digitalocean_wordpress","markdown":"\nBack in May (2014) I decided to start up a blog, again. I decided to keep it simple and just get a off the shelf hosting package rather then going to extremes like I normally do \u2013 configuring a VPS or even a Dedi server! I ended up going with [CS New Media](http:\/\/www.csnewmedia.co.uk) \u2013 it was just their lite Linux package which\u00a0I signed up for 3 months. I was tempted to stick with what I know and go with [Mythic-Beasts](https:\/\/www.mythic-beasts.com\/) like I normally but I like to tinker and try new things so I went with\u00a0[CS New Media](http:\/\/www.csnewmedia.co.uk)\u00a0after a failed attempt to spend my dosh with [NameCheap](https:\/\/www.namecheap.com\/) \u2013 when it came to entering my card details, it just failed to connect to \u201ctheir\u201d backend and their response was, well it works for me, try another browser \u2013 by the time I phoned them I had already tried different browsers, internet connections, computers so at that point I just walked away.\n\nAnyway fast forward two months and I was getting ichy to move away from\u00a0[CS New Media](http:\/\/www.csnewmedia.co.uk)\u00a0\u2013 nothing wrong with them, a bit of downtime, but nothing major and it was all stupid-o-clock, performance was ok, nothing special and support \u2013 well I never used it so, can\u2019t comment. Using [Plesk](http:\/\/sp.parallels.com\/products\/plesk\/)\u00a0was a blast from the past \u2013 that was the first web control panel I ever used, so it was nice to see how it\u2019s improved.\n\nProblem was, where do I go, well [Mythic-Beasts had fitted SSDs into their web servers](http:\/\/blog.mythic-beasts.com\/2013\/11\/07\/sphinx-aka-triggers-broom\/) since I\u2019ve hosted with them, tempting. Then [DigitalOcean](https:\/\/www.digitalocean.com\/) did it. They announced a new data centre. [In London](https:\/\/www.digitalocean.com\/company\/blog\/introducing-our-london-region\/). [With IPv6](https:\/\/www.digitalocean.com\/company\/blog\/announcing-ipv6-support-in-singapore\/). And they have that sexy [API](https:\/\/developers.digitalocean.com\/). Ooo and I have credit with them for some reason or other, happy days. I decided to take it slow and script the whole process \u2013 I\u2019ve been playing with [PowerShell ](https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell)lately, so [I created a PowerShell script ](https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell)that [creates the DNS records](https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell), [builds the droplet](https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell). I\u2019ve even managed to get it to convert the Putty public SSH key into OpenSSH format so [DigitalOcean](https:\/\/www.digitalocean.com\/) will accept it and I can use SSH keys to connect to the server. I was planning on scripting the build\u00a0process of installing the LEMP stack \u2013 but I lost interest to be honest and [enough ](https:\/\/www.linode.com\/stackscripts) [already exist](https:\/\/rtcamp.com\/easyengine\/).\n\nNet result, it\u2019s got my [PowerShell ](https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell)knowledge up \u2013 all the codes in my [GitHub repository](https:\/\/github.com\/matt40k). One of the off-shot projects of the project was a PowerShell function to generate secure passwords, the idea was my [DigitalOcean PowerShell](https:\/\/github.com\/matt40k\/PowerShell-GenSecurePass) script would generate passwords for your newly created droplet \u2013 MySQL root password for example, store it as say CSV on your local machine and only pass the password as an argument\u00a0to the stack install script over SSH\u00a0\u2013 so it wouldn\u2019t get stored on the remote server discs.\n\n\n","html":"<p>Back in May (2014) I decided to start up a blog, again. I decided to keep it simple and just get a off the shelf hosting package rather then going to extremes like I normally do &#8211; configuring a VPS or even a Dedi server! I ended up going with <a href=\"http:\/\/www.csnewmedia.co.uk\" target=\"_blank\" rel=\"nofollow\">CS New Media<\/a> &#8211; it was just their lite Linux package which\u00a0I signed up for 3 months. I was tempted to stick with what I know and go with <a href=\"https:\/\/www.mythic-beasts.com\/\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a> like I normally but I like to tinker and try new things so I went with\u00a0<a href=\"http:\/\/www.csnewmedia.co.uk\" target=\"_blank\" rel=\"nofollow\">CS New Media<\/a>\u00a0after a failed attempt to spend my dosh with <a href=\"https:\/\/www.namecheap.com\/\" target=\"_blank\" rel=\"nofollow\">NameCheap<\/a> &#8211; when it came to entering my card details, it just failed to connect to &#8220;their&#8221; backend and their response was, well it works for me, try another browser &#8211; by the time I phoned them I had already tried different browsers, internet connections, computers so at that point I just walked away.<\/p>\n<p>Anyway fast forward two months and I was getting ichy to move away from\u00a0<a href=\"http:\/\/www.csnewmedia.co.uk\" target=\"_blank\" rel=\"nofollow\">CS New Media<\/a>\u00a0&#8211; nothing wrong with them, a bit of downtime, but nothing major and it was all stupid-o-clock, performance was ok, nothing special and support &#8211; well I never used it so, can&#8217;t comment. Using <a href=\"http:\/\/sp.parallels.com\/products\/plesk\/\" target=\"_blank\" rel=\"nofollow\">Plesk<\/a>\u00a0was a blast from the past &#8211; that was the first web control panel I ever used, so it was nice to see how it&#8217;s improved.<\/p>\n<p>Problem was, where do I go, well <a href=\"http:\/\/blog.mythic-beasts.com\/2013\/11\/07\/sphinx-aka-triggers-broom\/\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts had fitted SSDs into their web servers<\/a> since I&#8217;ve hosted with them, tempting. Then <a href=\"https:\/\/www.digitalocean.com\/\" target=\"_blank\" rel=\"nofollow\">DigitalOcean<\/a> did it. They announced a new data centre. <a href=\"https:\/\/www.digitalocean.com\/company\/blog\/introducing-our-london-region\/\" target=\"_blank\" rel=\"nofollow\">In London<\/a>. <a href=\"https:\/\/www.digitalocean.com\/company\/blog\/announcing-ipv6-support-in-singapore\/\" target=\"_blank\" rel=\"nofollow\">With IPv6<\/a>. And they have that sexy <a href=\"https:\/\/developers.digitalocean.com\/\" target=\"_blank\" rel=\"nofollow\">API<\/a>. Ooo and I have credit with them for some reason or other, happy days. I decided to take it slow and script the whole process &#8211; I&#8217;ve been playing with <a href=\"https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell\" target=\"_blank\" rel=\"nofollow\">PowerShell <\/a>lately, so <a href=\"https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell\" target=\"_blank\" rel=\"nofollow\">I created a PowerShell script <\/a>that <a href=\"https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell\" target=\"_blank\" rel=\"nofollow\">creates the DNS records<\/a>, <a href=\"https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell\" target=\"_blank\" rel=\"nofollow\">builds the droplet<\/a>. I&#8217;ve even managed to get it to convert the Putty public SSH key into OpenSSH format so <a href=\"https:\/\/www.digitalocean.com\/\" target=\"_blank\" rel=\"nofollow\">DigitalOcean<\/a> will accept it and I can use SSH keys to connect to the server. I was planning on scripting the build\u00a0process of installing the LEMP stack &#8211; but I lost interest to be honest and <a href=\"https:\/\/www.linode.com\/stackscripts\" target=\"_blank\" rel=\"nofollow\">enough <\/a><a href=\"https:\/\/rtcamp.com\/easyengine\/\" target=\"_blank\" rel=\"nofollow\">already exist<\/a>.<\/p>\n<p>Net result, it&#8217;s got my <a href=\"https:\/\/github.com\/matt40k\/DigitalOcean-PowerShell\" target=\"_blank\" rel=\"nofollow\">PowerShell <\/a>knowledge up &#8211; all the codes in my <a href=\"https:\/\/github.com\/matt40k\" target=\"_blank\" rel=\"nofollow\">GitHub repository<\/a>. One of the off-shot projects of the project was a PowerShell function to generate secure passwords, the idea was my <a href=\"https:\/\/github.com\/matt40k\/PowerShell-GenSecurePass\" target=\"_blank\" rel=\"nofollow\">DigitalOcean PowerShell<\/a> script would generate passwords for your newly created droplet &#8211; MySQL root password for example, store it as say CSV on your local machine and only pass the password as an argument\u00a0to the stack install script over SSH\u00a0&#8211; so it wouldn&#8217;t get stored on the remote server discs.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 10 Aug 2014 01:21:22 +0000","created_by":1,"updated_at":"Sun, 10 Aug 2014 01:21:22 +0000","updated_by":1,"published_at":"Sun, 10 Aug 2014 01:21:22 +0000","published_by":1},{"id":189,"title":"BI for IT operations","slug":"bi-for-it-operations","markdown":"\nI always find it funny when IT departments talk about BI for their company and they don\u2019t actually have a BI solution in place for themselves. Surely you should\u00a0practice what you preach?\n\nSo why do IT departments need BI. Well lets look at\u00a0[Rosetta@home](http:\/\/boinc.bakerlab.org\/).\n\n> <span class=\"news_date\">Jul 30, 2014<\/span>  \n> <span class=\"news_content\">We are aware of significant network slow-down between the subnet upon which our servers sit and the Internet beyond the UW campus. We are working with the UW\u2019s Network Operations team to pinpoint the cause. We apologize for the frustration caused. -KEL<\/span>\n\nDoesn\u2019t sound good does it. Almost like they\u2019ve been hacked or suffering a DDOS.\n\n> <span class=\"news_date\">Aug 05, 2014<\/span>  \n> <span class=\"news_content\">**Slowdown Update:**\u00a0As it turns out, the slow-down experienced during the last week of July was the result of a very large surge in users joining the project through a new campaign by\u00a0[http:\/\/charityengine.com](http:\/\/charityengine.com\/). As the servers were behaving properly \u2013 just overwhelmed \u2013 and DK was on a well-deserved holiday, it was difficult for the rest of us to pin-point the cause. You can see the recent surge\u00a0[here](http:\/\/boincstats.com\/en\/charts\/14\/project\/perDay\/user\/total\/chart.png).  \n>  We are looking at changing\/expanding our webserver frontend to be more resilient to surges like this in the future. Yet again, we apologize for the frustration\u00a0<\/span>caused. -KEL\n\n6 days later they twig. Using the third party stats site \u2013[BoincStats.com](http:\/\/boincstats.com\/)\u00a0they get a bit of\u00a0[visual analysis](http:\/\/boincstats.com\/en\/charts\/14\/project\/perDay\/user\/total\/chart.png). They\u2019ve seen massive new user growth. Having a cloud based solution is only half the solution, knowing when to scale up and when to scale down is the other half of the problem.\n\n\n","html":"<p>I always find it funny when IT departments talk about BI for their company and they don&#8217;t actually have a BI solution in place for themselves. Surely you should\u00a0practice what you preach?<\/p>\n<p>So why do IT departments need BI. Well lets look at\u00a0<a href=\"http:\/\/boinc.bakerlab.org\/\" target=\"_blank\" rel=\"nofollow\">Rosetta@home<\/a>.<\/p>\n<blockquote><p><span class=\"news_date\">Jul 30, 2014<\/span><br \/>\n<span class=\"news_content\">We are aware of significant network slow-down between the subnet upon which our servers sit and the Internet beyond the UW campus. We are working with the UW&#8217;s Network Operations team to pinpoint the cause. We apologize for the frustration caused. -KEL<\/span><\/p><\/blockquote>\n<p>Doesn&#8217;t sound good does it. Almost like they&#8217;ve been hacked or suffering a DDOS.<\/p>\n<blockquote><p><span class=\"news_date\">Aug 05, 2014<\/span><br \/>\n<span class=\"news_content\"><b>Slowdown Update:<\/b>\u00a0As it turns out, the slow-down experienced during the last week of July was the result of a very large surge in users joining the project through a new campaign by\u00a0<a style=\"color: blue;\" href=\"http:\/\/charityengine.com\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/charityengine.com<\/a>. As the servers were behaving properly &#8211; just overwhelmed &#8211; and DK was on a well-deserved holiday, it was difficult for the rest of us to pin-point the cause. You can see the recent surge\u00a0<a style=\"color: blue;\" href=\"http:\/\/boincstats.com\/en\/charts\/14\/project\/perDay\/user\/total\/chart.png\" target=\"_blank\" rel=\"nofollow\">here<\/a>.<br \/>\nWe are looking at changing\/expanding our webserver frontend to be more resilient to surges like this in the future. Yet again, we apologize for the frustration\u00a0<\/span>caused. -KEL<\/p><\/blockquote>\n<p>6 days later they twig. Using the third party stats site &#8211;<a href=\"http:\/\/boincstats.com\/\" target=\"_blank\" rel=\"nofollow\">BoincStats.com<\/a>\u00a0they get a bit of\u00a0<a href=\"http:\/\/boincstats.com\/en\/charts\/14\/project\/perDay\/user\/total\/chart.png\" target=\"_blank\" rel=\"nofollow\">visual analysis<\/a>. They&#8217;ve seen massive new user growth. Having a cloud based solution is only half the solution, knowing when to scale up and when to scale down is the other half of the problem.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 17 Aug 2014 21:20:08 +0000","created_by":1,"updated_at":"Sun, 17 Aug 2014 21:20:08 +0000","updated_by":1,"published_at":"Sun, 17 Aug 2014 21:20:08 +0000","published_by":1},{"id":191,"title":"Living in a IPv6 world","slug":"living-in-a-ipv6-world","markdown":"\nI\u2019ve finally gotten round to setting up the [VDS](https:\/\/www.mythic-beasts.com\/servers\/virtual) [Mythic-Beasts](https:\/\/www.mythic-beasts.com) have kindly donated to host the API backend for one of my open-source projects. A few nights ago I enabled IPv6 and today when I went to run apt-get update it just hung saying:\n\n> 0% [Connecting to gb.archive.ubuntu.com (2a01:450:10:1::10)]\n\nAs they had previously worked, I suspect it\u2019s IPv6 problem, quick google and\u2026\n\n[http:\/\/askubuntu.com\/questions\/272796\/connecting-to-archive-ubuntu-com-takes-too-long](http:\/\/askubuntu.com\/questions\/272796\/connecting-to-archive-ubuntu-com-takes-too-long)\n\n> I solved this on 12.10 by editing\u00a0**\/etc\/gai.conf**\u00a0and uncommenting the line:\n> \n> ```\n> <code style=\"color: #222222;\">\n> #\n> #    For sites which prefer IPv4 connections change the last line to\n> #\n> precedence ::ffff:0:0\/96 100\n> ```\n\nBingo.\n\n\n","html":"<p>I&#8217;ve finally gotten round to setting up the <a href=\"https:\/\/www.mythic-beasts.com\/servers\/virtual\" target=\"_blank\" rel=\"nofollow\">VDS<\/a> <a href=\"https:\/\/www.mythic-beasts.com\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a> have kindly donated to host the API backend for one of my open-source projects. A few nights ago I enabled IPv6 and today when I went to run apt-get update it just hung saying:<\/p>\n<blockquote><p>0% [Connecting to gb.archive.ubuntu.com (2a01:450:10:1::10)]<\/p><\/blockquote>\n<p>As they had previously worked, I suspect it&#8217;s IPv6 problem, quick google and&#8230;<\/p>\n<p><a href=\"http:\/\/askubuntu.com\/questions\/272796\/connecting-to-archive-ubuntu-com-takes-too-long\" target=\"_blank\" rel=\"nofollow\">http:\/\/askubuntu.com\/questions\/272796\/connecting-to-archive-ubuntu-com-takes-too-long<\/a><\/p>\n<blockquote>\n<p style=\"color: #333333;\">I solved this on 12.10 by editing\u00a0<strong>\/etc\/gai.conf<\/strong>\u00a0and uncommenting the line:<\/p>\n<pre style=\"color: #333333;\"><code style=\"color: #222222;\">\n#\n#    For sites which prefer IPv4 connections change the last line to\n#\nprecedence ::ffff:0:0\/96 100\n<\/code><\/pre>\n<\/blockquote>\n<p>Bingo.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Thu, 21 Aug 2014 22:12:29 +0000","created_by":1,"updated_at":"Thu, 21 Aug 2014 22:12:29 +0000","updated_by":1,"published_at":"Thu, 21 Aug 2014 22:12:29 +0000","published_by":1},{"id":201,"title":"SIMS Bulk Import","slug":"sims-bulk-import","markdown":"\n\n## Overview\n\nIf your in the UK, the chances are your local school is using [SIMS .net](http:\/\/www.capita-sims.co.uk\/). [Just checkout the stats on their site](http:\/\/web.archive.org\/web\/20150909213728\/http:\/\/www.capita-sims.co.uk\/facts-and-figures). 22,000 schools taking\u00a0<span style=\"color: #57585a;\">2,500,000 children\u2019s attendance, every day. That\u2019s impressive.<\/span>\n\nSo what is SIMS .net? Well its a MIS system, but what is a MIS system? In the simplest terms its a database that holds the\u00a0school records, for both students\u00a0and staff. \u00a0So it makes sense that you are going to want to interface with it as it\u2019s your at your core when it comes to data sources.\n\nNow extracting data is pretty straightforward. Capita have created a custom reporting engine that allows simple report creation that can then be scheduled and produce exports of data. The problem is getting data back into SIMS .net. Take for example identity management, it\u2019s easy enough to export a list of students, then write a PowerShell script to generate user accounts, but wouldn\u2019t it be good to get that username added back into your core data source? Or what about adding in new students home email addresses and telephone numbers? Well it isn\u2019t that straightforward to bulk import.\u00a0Although Capita provide a API it isn\u2019t as straightforward and certainly isn\u2019t as friendly as a\u00a0RESTful web service and certainly requires a programming background to understand it which rules out many schools being able to use it.\n\nBack in May 2012 I was working on a SIMS support desk doing technical support and one of our customers asked if he could bulk import email addresses back into SIMS .net. This resulted in me asking Capita for documentation regarding the API which they provided, at no cost, along with a few snippets of example code. I then spent the following nights\u00a0coding away at home to what has become SIMS Bulk Import.\n\n\n## About\n\nSo what are\u00a0SIMS Bulk Import features\n\n- It\u2019s free \u2013 Thank you [Phil Neal](https:\/\/twitter.com\/phil_neal) for waiving the licensing costs \ud83d\ude42\n- It uses the SIMS .net Business Objects\u00a0(no large Capita charges\u00a0for corrupting your SIMS .net database!)\n- Imports from CSV, Excel spreadsheets and XML files\n- Matches the file fields with SIMS .net fields\n\n\n## The future\n\nI\u2019ve since moved away from SIMS support and I\u2019ve been trying to find a suitable new home for SIMS Bulk Import. Whether that\u2019ll be Capita writing a replacement, or someone else taking up the project it isn\u2019t clear. For now I\u2019ll continue to support it. But to as part of this I\u2019ve moved the source over to [GitHub](https:\/\/github.com\/SIMSBulkImport), the releases will still be via [CodePlex](http:\/\/simsbulkimport.uk\/). \u00a0I\u2019ve also created a separate organisation on\u00a0[GitHub](https:\/\/github.com\/SIMSBulkImport),\u00a0[SIMSBulkImport](https:\/\/github.com\/SIMSBulkImport), which effectively \u201cowns\u201d the code. I fork the code from \u00a0[SIMSBulkImport](https:\/\/github.com\/SIMSBulkImport)\u00a0into [my personal repository](https:\/\/github.com\/matt40k), and do a pull request to merge the\u00a0code back into the main\u00a0[SIMSBulkImport](https:\/\/github.com\/SIMSBulkImport)\u00a0repository. This will help should the \u201cowner\u201d of SIMS Bulk Import change in the future.\n\nI\u2019ve also created a number of sub-projects \u2013 the SIMS interface library will be moved from [Unfuddle](https:\/\/unfuddle.com\/)\u00a0onto [GitHub](https:\/\/github.com\/SIMSBulkImport), also the installer element will become a separate repository. I\u2019m looking at setting up [TeamCity](http:\/\/www.jetbrains.com\/teamcity\/) to automate the build process so building and creating releases is a lot more streamlined and less time consuming. Also a simple web site setup giving easy advise for getting started.\n\nAnother change is a web API \u2013 this allows checking for newer versions and secure uploading of log files to the developers (OK, me). [Mythic-Beasts](https:\/\/www.mythic-beasts.com\/) have kindly donated a server hosted in Cambridge, UK to host this. This written in [PHP](http:\/\/www.php.net\/)\u00a0using the [Laravel](http:\/\/laravel.com\/) framework, I\u2019ve started writing it based on some of [Bobby Allen](http:\/\/bobbyallen.me\/)\u00a0original code.\n\nGoing forward I would like some (official) recommendation from schools and support teams, ideally I\u2019d like to put together some sort of list or program detailing where you can get support from, for example:\n\nYour Local SIMS Team supports SIMS Bulk Import!\n\nYour Local SIMS Team is a SIMS Bulk Import silver partner!\n\nIt\u2019s just difficult making a business case to people when your product is free. The main reason I want to do this is I\u2019m find the odd problem where someone need to remote in, this is difficult without some sort of support agreement and T and Cs \u2013 most of the problems are actual SIMS problems\u00a0like\u00a0the SIMS client hasn\u2019t be installed correctly which their SIMS support team could resolve. I appreciate working in the dark isn\u2019t easy and you can\u2019t know about every SIMS third party product, so your going to get a element of\u00a0from pillar to post. Ideally I need a main backer to act as data controller with regards to the log files, at the moment I\u2019m investigating if I could get around it by limiting the data it could spit out but that\u2019s going to limit the usefulness of the logs. It\u2019ll also been good to get the program [digitally signed](http:\/\/en.wikipedia.org\/wiki\/Digital_signature).\n\nIf anyone is willing to help out feel free to drop me a email \u2013 matt [at] matt40k [dot] uk\n\n\n","html":"<h2>Overview<\/h2>\n<p>If your in the UK, the chances are your local school is using <a href=\"http:\/\/www.capita-sims.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS .net<\/a>. <a href=\"http:\/\/web.archive.org\/web\/20150909213728\/http:\/\/www.capita-sims.co.uk\/facts-and-figures\" target=\"_blank\" rel=\"nofollow\">Just checkout the stats on their site<\/a>. 22,000 schools taking\u00a0<span style=\"color: #57585a;\">2,500,000 children&#8217;s attendance, every day. That&#8217;s impressive.<\/span><\/p>\n<p>So what is SIMS .net? Well its a MIS system, but what is a MIS system? In the simplest terms its a database that holds the\u00a0school records, for both students\u00a0and staff. \u00a0So it makes sense that you are going to want to interface with it as it&#8217;s your at your core when it comes to data sources.<\/p>\n<p>Now extracting data is pretty straightforward. Capita have created a custom reporting engine that allows simple report creation that can then be scheduled and produce exports of data. The problem is getting data back into SIMS .net. Take for example identity management, it&#8217;s easy enough to export a list of students, then write a PowerShell script to generate user accounts, but wouldn&#8217;t it be good to get that username added back into your core data source? Or what about adding in new students home email addresses and telephone numbers? Well it isn&#8217;t that straightforward to bulk import.\u00a0Although Capita provide a API it isn&#8217;t as straightforward and certainly isn&#8217;t as friendly as a\u00a0RESTful web service and certainly requires a programming background to understand it which rules out many schools being able to use it.<\/p>\n<p>Back in May 2012 I was working on a SIMS support desk doing technical support and one of our customers asked if he could bulk import email addresses back into SIMS .net. This resulted in me asking Capita for documentation regarding the API which they provided, at no cost, along with a few snippets of example code. I then spent the following nights\u00a0coding away at home to what has become SIMS Bulk Import.<\/p>\n<h2>About<\/h2>\n<p>So what are\u00a0SIMS Bulk Import features<\/p>\n<ul>\n<li>It&#8217;s free &#8211; Thank you <a href=\"https:\/\/twitter.com\/phil_neal\" target=\"_blank\" rel=\"nofollow\">Phil Neal<\/a> for waiving the licensing costs \ud83d\ude42<\/li>\n<li>It uses the SIMS .net Business Objects\u00a0(no large Capita charges\u00a0for corrupting your SIMS .net database!)<\/li>\n<li>Imports from CSV, Excel spreadsheets and XML files<\/li>\n<li>Matches the file fields with SIMS .net fields<\/li>\n<\/ul>\n<h2>The future<\/h2>\n<p>I&#8217;ve since moved away from SIMS support and I&#8217;ve been trying to find a suitable new home for SIMS Bulk Import. Whether that&#8217;ll be Capita writing a replacement, or someone else taking up the project it isn&#8217;t clear. For now I&#8217;ll continue to support it. But to as part of this I&#8217;ve moved the source over to <a href=\"https:\/\/github.com\/SIMSBulkImport\" target=\"_blank\" rel=\"nofollow\">GitHub<\/a>, the releases will still be via <a href=\"http:\/\/simsbulkimport.uk\/\" target=\"_blank\" rel=\"nofollow\">CodePlex<\/a>. \u00a0I&#8217;ve also created a separate organisation on\u00a0<a href=\"https:\/\/github.com\/SIMSBulkImport\" target=\"_blank\" rel=\"nofollow\">GitHub<\/a>,\u00a0<a href=\"https:\/\/github.com\/SIMSBulkImport\" target=\"_blank\" rel=\"nofollow\">SIMSBulkImport<\/a>, which effectively &#8220;owns&#8221; the code. I fork the code from \u00a0<a href=\"https:\/\/github.com\/SIMSBulkImport\" target=\"_blank\" rel=\"nofollow\">SIMSBulkImport<\/a>\u00a0into <a href=\"https:\/\/github.com\/matt40k\" target=\"_blank\" rel=\"nofollow\">my personal repository<\/a>, and do a pull request to merge the\u00a0code back into the main\u00a0<a href=\"https:\/\/github.com\/SIMSBulkImport\" target=\"_blank\" rel=\"nofollow\">SIMSBulkImport<\/a>\u00a0repository. This will help should the &#8220;owner&#8221; of SIMS Bulk Import change in the future.<\/p>\n<p>I&#8217;ve also created a number of sub-projects &#8211; the SIMS interface library will be moved from <a href=\"https:\/\/unfuddle.com\/\" target=\"_blank\" rel=\"nofollow\">Unfuddle<\/a>\u00a0onto <a href=\"https:\/\/github.com\/SIMSBulkImport\" target=\"_blank\" rel=\"nofollow\">GitHub<\/a>, also the installer element will become a separate repository. I&#8217;m looking at setting up <a href=\"http:\/\/www.jetbrains.com\/teamcity\/\" target=\"_blank\" rel=\"nofollow\">TeamCity<\/a> to automate the build process so building and creating releases is a lot more streamlined and less time consuming. Also a simple web site setup giving easy advise for getting started.<\/p>\n<p>Another change is a web API &#8211; this allows checking for newer versions and secure uploading of log files to the developers (OK, me). <a href=\"https:\/\/www.mythic-beasts.com\/\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a> have kindly donated a server hosted in Cambridge, UK to host this. This written in <a href=\"http:\/\/www.php.net\/\" target=\"_blank\" rel=\"nofollow\">PHP<\/a>\u00a0using the <a href=\"http:\/\/laravel.com\/\" target=\"_blank\" rel=\"nofollow\">Laravel<\/a> framework, I&#8217;ve started writing it based on some of <a href=\"http:\/\/bobbyallen.me\/\" target=\"_blank\" rel=\"nofollow\">Bobby Allen<\/a>\u00a0original code.<\/p>\n<p>Going forward I would like some (official) recommendation from schools and support teams, ideally I&#8217;d like to put together some sort of list or program detailing where you can get support from, for example:<\/p>\n<p style=\"padding-left: 30px;\">Your Local SIMS Team supports SIMS Bulk Import!<\/p>\n<p style=\"padding-left: 30px;\">Your Local SIMS Team is a SIMS Bulk Import silver partner!<\/p>\n<p>It&#8217;s just difficult making a business case to people when your product is free. The main reason I want to do this is I&#8217;m find the odd problem where someone need to remote in, this is difficult without some sort of support agreement and T and Cs &#8211; most of the problems are actual SIMS problems\u00a0like\u00a0the SIMS client hasn&#8217;t be installed correctly which their SIMS support team could resolve. I appreciate working in the dark isn&#8217;t easy and you can&#8217;t know about every SIMS third party product, so your going to get a element of\u00a0from pillar to post. Ideally I need a main backer to act as data controller with regards to the log files, at the moment I&#8217;m investigating if I could get around it by limiting the data it could spit out but that&#8217;s going to limit the usefulness of the logs. It&#8217;ll also been good to get the program <a href=\"http:\/\/en.wikipedia.org\/wiki\/Digital_signature\" target=\"_blank\" rel=\"nofollow\">digitally signed<\/a>.<\/p>\n<p>If anyone is willing to help out feel free to drop me a email &#8211; matt [at] matt40k [dot] uk<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 03 Sep 2014 21:58:27 +0000","created_by":1,"updated_at":"Sun, 16 Oct 2016 22:50:00 +0000","updated_by":1,"published_at":"Wed, 03 Sep 2014 21:58:27 +0000","published_by":1},{"id":207,"title":"WIX installer why you no MSBUILD no more?","slug":"wix-installer-why-you-no-msbuild-no-more","markdown":"\nLast night I chopped up my WIX installer project \u2013 I basically split the actual installer parts into one file \u2013 CoreMsi.wxs, the versions into a variable file \u2013\u00a0Version.wxi and the file list into a separate fragment file\u00a0\u2013\u00a0SimsBulkImport.wxs. This worked.\n\nGreat I thought, simple PowerShell script to generate the file list, I can even grab the main repository complied bin as a artifact dependency \u2013 got to love TeamCity.\n\nProblem was, it fails to build.\n\n> *error CNDL0104: Not a valid source file; detail: \u2018.\u2019, hexadecimal value 0x00, is an invalid character. Line 2, position 1.*\n\nbit of trial and error later I figured it out. It was my old friend Mr Encoding. After adding\n\n> <span class=\"n\">-Encoding<\/span><span class=\"s2\">\u201cUTF8\u201d\u00a0<\/span>\n\nto the end of the Out-File and it builds again.\n\n\n","html":"<p>Last night I chopped up my WIX installer project &#8211; I basically split the actual installer parts into one file &#8211; CoreMsi.wxs, the versions into a variable file &#8211;\u00a0Version.wxi and the file list into a separate fragment file\u00a0&#8211;\u00a0SimsBulkImport.wxs. This worked.<\/p>\n<p>Great I thought, simple PowerShell script to generate the file list, I can even grab the main repository complied bin as a artifact dependency &#8211; got to love TeamCity.<\/p>\n<p>Problem was, it fails to build.<\/p>\n<blockquote><p><i class=\"mark error_msg  status_err\">error CNDL0104: Not a valid source file; detail: &#8216;.&#8217;, hexadecimal value 0x00, is an invalid character. Line 2, position 1.<\/i><\/p><\/blockquote>\n<p>bit of trial and error later I figured it out. It was my old friend Mr Encoding. After adding<\/p>\n<blockquote><p><span class=\"n\">-Encoding<\/span> <span class=\"s2\">&#8220;UTF8&#8221;\u00a0<\/span><\/p><\/blockquote>\n<p>to the end of the Out-File and it builds again.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 15 Sep 2014 21:13:36 +0000","created_by":1,"updated_at":"Mon, 15 Sep 2014 21:13:36 +0000","updated_by":1,"published_at":"Mon, 15 Sep 2014 21:13:36 +0000","published_by":1},{"id":210,"title":"TeamCity AssemblyInfo Patcher not working","slug":"teamcity-assemblyinfo-patcher-not-working","markdown":"\nTonight I was trying to get [TeamCity](http:\/\/www.jetbrains.com\/teamcity\/) to auto-update the version number for my [SIMS Bulk Import](http:\/\/simsbulkimport.uk\/) application, however the simple [AssemblyInfo Patcher](http:\/\/confluence.jetbrains.com\/display\/TCD65\/AssemblyInfo+Patcher) just failed to work. No errors. Nothing.\n\nThen I read the manual, again\u2026\n\n> Note that this feature will work only for \u201cstandard\u201d projects, i.e. created by means of the Visual Studio wizard, so that all the AssemblyInfo files and content have a standard location.\n\nSo I created a new package which placed the\u00a0AssemblyInfo.cs into the Properties folder, mine was in the main directory, moved it into the subfolder and bang, it works. Awesome.\n\n\u00a0\n\n\n","html":"<p>Tonight I was trying to get <a href=\"http:\/\/www.jetbrains.com\/teamcity\/\" target=\"_blank\" rel=\"nofollow\">TeamCity<\/a> to auto-update the version number for my <a href=\"http:\/\/simsbulkimport.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS Bulk Import<\/a> application, however the simple <a href=\"http:\/\/confluence.jetbrains.com\/display\/TCD65\/AssemblyInfo+Patcher\" target=\"_blank\" rel=\"nofollow\">AssemblyInfo Patcher<\/a> just failed to work. No errors. Nothing.<\/p>\n<p>Then I read the manual, again&#8230;<\/p>\n<blockquote><p>Note that this feature will work only for &#8220;standard&#8221; projects, i.e. created by means of the Visual Studio wizard, so that all the AssemblyInfo files and content have a standard location.<\/p><\/blockquote>\n<p>So I created a new package which placed the\u00a0AssemblyInfo.cs into the Properties folder, mine was in the main directory, moved it into the subfolder and bang, it works. Awesome.<\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 20 Sep 2014 01:16:33 +0000","created_by":1,"updated_at":"Wed, 19 Aug 2015 15:53:32 +0000","updated_by":1,"published_at":"Sat, 20 Sep 2014 01:16:33 +0000","published_by":1},{"id":216,"title":"Slow progress","slug":"slow-progress","markdown":"\nI\u2019m currently getting bogged down with other projects and unfortunately my final sprint of [SIMS Bulk Import](https:\/\/simsbulkimport.uk\/) has grind to a halt. On the plus side I managed to swash a few more bugs last month, get a\u00a0code signing certificate. This will mean all future releases will be signed as coming from me which is great news, it adds a layer of\u00a0confidence that the code you run is unaltered by a third party. I\u2019ve also started reviewing my other projects, ensure that the code on the public repository is up-to-date, I\u2019ve also switched over to Git and copied them all over to [GitHub](https:\/\/github.com\/matt40k?tab=repositories). At bit more on that later.\n\nPart of the updated process was to use a Continuous Integration server \u2013 specifically [TeamCity](https:\/\/www.jetbrains.com\/teamcity\/). Simply put, these allowed the builds to occur on a dedicated box which made the whole process quicker and easier \u2013 it also added\u00a0confidence as it ensured that everything\u00a0required\u00a0was commit in the repository. The only downside to this is the cost \u2013 although renting a VPS from OVH is cheap, it still isn\u2019t cost effective due to the limited amount of time I actually use it, I\u2019m therefore looking at moving it to Azure as you only pay for provisioned resources and your can de-provision servers and only pay for the storage. Alas this means more messing about setting up servers.\n\n\n","html":"<p>I&#8217;m currently getting bogged down with other projects and unfortunately my final sprint of <a href=\"https:\/\/simsbulkimport.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS Bulk Import<\/a> has grind to a halt. On the plus side I managed to swash a few more bugs last month, get a\u00a0code signing certificate. This will mean all future releases will be signed as coming from me which is great news, it adds a layer of\u00a0confidence that the code you run is unaltered by a third party. I&#8217;ve also started reviewing my other projects, ensure that the code on the public repository is up-to-date, I&#8217;ve also switched over to Git and copied them all over to <a href=\"https:\/\/github.com\/matt40k?tab=repositories\" target=\"_blank\" rel=\"nofollow\">GitHub<\/a>. At bit more on that later.<\/p>\n<p>Part of the updated process was to use a Continuous Integration server &#8211; specifically <a href=\"https:\/\/www.jetbrains.com\/teamcity\/\" target=\"_blank\" rel=\"nofollow\">TeamCity<\/a>. Simply put, these allowed the builds to occur on a dedicated box which made the whole process quicker and easier &#8211; it also added\u00a0confidence as it ensured that everything\u00a0required\u00a0was commit in the repository. The only downside to this is the cost &#8211; although renting a VPS from OVH is cheap, it still isn&#8217;t cost effective due to the limited amount of time I actually use it, I&#8217;m therefore looking at moving it to Azure as you only pay for provisioned resources and your can de-provision servers and only pay for the storage. Alas this means more messing about setting up servers.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 10 Nov 2014 22:34:33 +0000","created_by":1,"updated_at":"Wed, 19 Aug 2015 15:53:24 +0000","updated_by":1,"published_at":"Mon, 10 Nov 2014 22:34:33 +0000","published_by":1},{"id":232,"title":"Are you ready for IPv6?","slug":"are-you-ready-for-ipv6","markdown":"\nFor a long while now it has been known that IPv4 will run out of available publicly assignable IP addresses. IPv4 address are 32 bits wide and quite simply can\u2019t cope with the demand of the modern world \u2013 despite NAT\u2019ing. IPv6 looks to resolve this by have not only more digits, but also using hexadecimal.\n\nFor example, an IPv4 address looks like this\n\n> 192 . 168 . 0 . 1\n\n4 parts each running from 0 \u2013 255.\n\nNow lets look at Facebook IPv6 record:\n\n> 2a03 : 2880 : 2110 : df07 : face : b00c : 0 : 1\n\nNow that\u2019s 8 blocks, each one being 4 hexadecimals \u2013 so that\u2019s 0 \u2013 9 then a \u2013 f (so 16), so that\u2019s 16 x 16 x 16 x 16 \u2013 so 65,536 in a block vs IPv4 255, and there are 8 blocks\u2026 that\u2019s 128 bits, starting to see how massive the IPv6 range is?\n\nBecause of the massive IP range, you in effect get to bypass the IPv4 tax \u2013 in fact [Mythic-Beasts](https:\/\/www.mythic-beasts.com) has already started [offering IPv6 only servers](https:\/\/www.mythic-beasts.com\/servers\/virtual) without the IPv4 tax. That\u2019s not the only thing, NAT becomes obsolete which means gaming on the XBOX One becomes faster as you don\u2019t have to setup port forwarding and put extra load on your router \u2013 also new Microsoft devices (Windows PCs and XBOX One) have a preference for IPv6 over IPv4, this could be because IPv6 has cleaner routing? IPv6\u00a0has been designed for the future,\u00a0security has been account for and isn\u2019t just tacked\u00a0on.\n\nWhen is IPv6 coming out? Well, it\u2019s actually out, and it\u2019s been out for a long while. RIPE, who are responsible for issuing IP addresses (both IPv4 and IPv6) in Europe has been doing it since 1999 and\u00a0World IPv6 Day was back in 2011.\n\nSo, are you IPv6 ready?\n\n<span style=\"line-height: 1.5;\">You can check if your ISP has setup IPv6 so you can access those IPv6 servers from your computer by going to:\u00a0[http:\/\/test-ipv6.com\/](http:\/\/test-ipv6.com\/)<\/span>\n\nAnd you can check if your website is IPv6 ready by going to:\u00a0[https:\/\/www.mythic-beasts.com\/ipv6\/health-check](https:\/\/www.mythic-beasts.com\/ipv6\/health-check)\n\nI\u2019m guessing the answer is no.\n\nThankfully, you\u2019re not alone, but it\u2019s something to think about, especially\u00a0as all the major ISP in the UK are gearing up \u2013\u00a0[http:\/\/blog.mythic-beasts.com\/2014\/10\/22\/ipv6-support-in-the-uk\/](http:\/\/blog.mythic-beasts.com\/2014\/10\/22\/ipv6-support-in-the-uk\/)\u00a0and\u00a0[http:\/\/www.ipv6.org.uk\/2014\/11\/20\/ipv6-council-meeting-oct2014\/](http:\/\/www.ipv6.org.uk\/2014\/11\/20\/ipv6-council-meeting-oct2014\/)\n\n\n","html":"<p>For a long while now it has been known that IPv4 will run out of available publicly assignable IP addresses. IPv4 address are 32 bits wide and quite simply can&#8217;t cope with the demand of the modern world &#8211; despite NAT&#8217;ing. IPv6 looks to resolve this by have not only more digits, but also using hexadecimal.<\/p>\n<p>For example, an IPv4 address looks like this<\/p>\n<blockquote><p>192 . 168 . 0 . 1<\/p><\/blockquote>\n<p>4 parts each running from 0 &#8211; 255.<\/p>\n<p>Now lets look at Facebook IPv6 record:<\/p>\n<blockquote><p>2a03 : 2880 : 2110 : df07 : face : b00c : 0 : 1<\/p><\/blockquote>\n<p>Now that&#8217;s 8 blocks, each one being 4 hexadecimals &#8211; so that&#8217;s 0 &#8211; 9 then a &#8211; f (so 16), so that&#8217;s 16 x 16 x 16 x 16 &#8211; so 65,536 in a block vs IPv4 255, and there are 8 blocks&#8230; that&#8217;s 128 bits, starting to see how massive the IPv6 range is?<\/p>\n<p>Because of the massive IP range, you in effect get to bypass the IPv4 tax &#8211; in fact <a href=\"https:\/\/www.mythic-beasts.com\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a> has already started <a href=\"https:\/\/www.mythic-beasts.com\/servers\/virtual\" target=\"_blank\" rel=\"nofollow\">offering IPv6 only servers<\/a> without the IPv4 tax. That&#8217;s not the only thing, NAT becomes obsolete which means gaming on the XBOX One becomes faster as you don&#8217;t have to setup port forwarding and put extra load on your router &#8211; also new Microsoft devices (Windows PCs and XBOX One) have a preference for IPv6 over IPv4, this could be because IPv6 has cleaner routing? IPv6\u00a0has been designed for the future,\u00a0security has been account for and isn&#8217;t just tacked\u00a0on.<\/p>\n<p>When is IPv6 coming out? Well, it&#8217;s actually out, and it&#8217;s been out for a long while. RIPE, who are responsible for issuing IP addresses (both IPv4 and IPv6) in Europe has been doing it since 1999 and\u00a0World IPv6 Day was back in 2011.<\/p>\n<p>So, are you IPv6 ready?<\/p>\n<p><span style=\"line-height: 1.5;\">You can check if your ISP has setup IPv6 so you can access those IPv6 servers from your computer by going to:\u00a0<a href=\"http:\/\/test-ipv6.com\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/test-ipv6.com\/<\/a><\/span><\/p>\n<p>And you can check if your website is IPv6 ready by going to:\u00a0<a href=\"https:\/\/www.mythic-beasts.com\/ipv6\/health-check\" target=\"_blank\" rel=\"nofollow\">https:\/\/www.mythic-beasts.com\/ipv6\/health-check<\/a><\/p>\n<p>I&#8217;m guessing the answer is no.<\/p>\n<p>Thankfully, you&#8217;re not alone, but it&#8217;s something to think about, especially\u00a0as all the major ISP in the UK are gearing up &#8211;\u00a0<a href=\"http:\/\/blog.mythic-beasts.com\/2014\/10\/22\/ipv6-support-in-the-uk\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/blog.mythic-beasts.com\/2014\/10\/22\/ipv6-support-in-the-uk\/<\/a>\u00a0and\u00a0<a href=\"http:\/\/www.ipv6.org.uk\/2014\/11\/20\/ipv6-council-meeting-oct2014\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/www.ipv6.org.uk\/2014\/11\/20\/ipv6-council-meeting-oct2014\/<\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 03 Dec 2014 22:16:26 +0000","created_by":1,"updated_at":"Fri, 10 Jun 2016 21:07:21 +0000","updated_by":1,"published_at":"Wed, 03 Dec 2014 22:16:26 +0000","published_by":1},{"id":238,"title":"Technical Analysis on Schools websites in England","slug":"technical-analysis-on-schools-websites-in-england","markdown":"\nSo in my [last blog post](http:\/\/matt40k.uk\/2014\/12\/are-you-ready-for-ipv6\/) I asked, [are you ready for IPv6](http:\/\/matt40k.uk\/2014\/12\/are-you-ready-for-ipv6\/)? The post came about when I was looking at Schools MIS data, which [Graham](http:\/\/eduwarenetwork.com\/mis_market_statistics\/), [Joshua](http:\/\/bringmoredata.blogspot.co.uk\/2014\/11\/mis-market-moves-sims-still-dominate.html) and [myself](http:\/\/matt40k.uk\/) have being look at to see who are the big movers and shakers in the Schools administration software (MIS) arena. Data is collected by what software suppliers a school uses to submit the School Census (in England)\u00a0which is requested under the Freedom of Information (FOI) from [Department of Education(DfE)](https:\/\/www.gov.uk\/government\/organisations\/department-for-education) (saving having to FOI every individual school). In order to enhance this data I was joining the data onto the general schools data that can be extract from [EduBase](http:\/\/www.education.gov.uk\/edubase\/home.xhtml). Looking at the data I notice that the website addresses listed in the extract was of extremely poor quality.\u00a0A number even had email addresses listed!\n\nThis got me thinking, are schools ready for IPv6? If Sky are running out of IPv4 addresses and offer IPv6 only connections at a lower price, how many parents are going to jump on the deal only to find out they can\u2019t access their child\u2019s school website later on. After a bit of scripting and a support call to [Mythic-Beasts](https:\/\/www.mythic-beasts.com\/) to enable a response in JSON that I could automate, I had the results. It wasn\u2019t good.\n\nStill, no-ones ready for IPv6 are they, sure they\u2019ll be ready in time. Won\u2019t they?\n\n> We can only judge the future from what we have suffered in the past\n> \n> Themistocles ,\u00a0*300: Rise of an Empire*\n\nTo this effect, I\u2019ve gathered data to look at:\n\n- &#154;Domain registration correctness\n- &#154;Content management systems\n- &#154;Document type definition\n- &#154;Raw HTML homepage size\n- &#154;Google Analytics\n- &#154;IPv6 readiness\n\nAt the moment I\u2019m still creating the presentation detailing my findings, but you can download the raw data from: [https:\/\/github.com\/matt40k\/SchoolsWebsites-England](https:\/\/github.com\/matt40k\/SchoolsWebsites-England)\n\n\n","html":"<p>So in my <a href=\"http:\/\/matt40k.uk\/2014\/12\/are-you-ready-for-ipv6\/\">last blog post<\/a> I asked, <a href=\"http:\/\/matt40k.uk\/2014\/12\/are-you-ready-for-ipv6\/\">are you ready for IPv6<\/a>? The post came about when I was looking at Schools MIS data, which <a href=\"http:\/\/eduwarenetwork.com\/mis_market_statistics\/\" target=\"_blank\" rel=\"nofollow\">Graham<\/a>, <a href=\"http:\/\/bringmoredata.blogspot.co.uk\/2014\/11\/mis-market-moves-sims-still-dominate.html\" target=\"_blank\" rel=\"nofollow\">Joshua<\/a> and <a href=\"http:\/\/matt40k.uk\/\">myself<\/a> have being look at to see who are the big movers and shakers in the Schools administration software (MIS) arena. Data is collected by what software suppliers a school uses to submit the School Census (in England)\u00a0which is requested under the Freedom of Information (FOI) from <a href=\"https:\/\/www.gov.uk\/government\/organisations\/department-for-education\" target=\"_blank\" rel=\"nofollow\">Department of Education(DfE)<\/a> (saving having to FOI every individual school). In order to enhance this data I was joining the data onto the general schools data that can be extract from <a href=\"http:\/\/www.education.gov.uk\/edubase\/home.xhtml\" target=\"_blank\" rel=\"nofollow\">EduBase<\/a>. Looking at the data I notice that the website addresses listed in the extract was of extremely poor quality.\u00a0A number even had email addresses listed!<\/p>\n<p>This got me thinking, are schools ready for IPv6? If Sky are running out of IPv4 addresses and offer IPv6 only connections at a lower price, how many parents are going to jump on the deal only to find out they can&#8217;t access their child&#8217;s school website later on. After a bit of scripting and a support call to <a href=\"https:\/\/www.mythic-beasts.com\/\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a> to enable a response in JSON that I could automate, I had the results. It wasn&#8217;t good.<\/p>\n<p>Still, no-ones ready for IPv6 are they, sure they&#8217;ll be ready in time. Won&#8217;t they?<\/p>\n<blockquote><p>We can only judge the future from what we have suffered in the past<\/p>\n<p style=\"text-align: right;\">Themistocles ,\u00a0<em>300: Rise of an Empire<\/em><\/p>\n<\/blockquote>\n<p style=\"text-align: left;\">To this effect, I&#8217;ve gathered data to look at:<\/p>\n<ul>\n<li>\u009aDomain registration correctness<\/li>\n<li>\u009aContent management systems<\/li>\n<li>\u009aDocument type definition<\/li>\n<li>\u009aRaw HTML homepage size<\/li>\n<li>\u009aGoogle Analytics<\/li>\n<li>\u009aIPv6 readiness<\/li>\n<\/ul>\n<p>At the moment I&#8217;m still creating the presentation detailing my findings, but you can download the raw data from: <a href=\"https:\/\/github.com\/matt40k\/SchoolsWebsites-England\" target=\"_blank\" rel=\"nofollow\">https:\/\/github.com\/matt40k\/SchoolsWebsites-England<\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 05 Dec 2014 10:31:31 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:16:37 +0000","updated_by":1,"published_at":"Fri, 05 Dec 2014 10:31:31 +0000","published_by":1},{"id":241,"title":"4th Anniversary of contributing to Rosetta@Home","slug":"4th-anniversary-of-contributing-to-rosettahome","markdown":"\nTomorrow, Sunday the 7th December 2014, I will be celebrating 4 years of contributing wasted CPU cycles to the excellent [Rosetta@Home ](http:\/\/boinc.bakerlab.org\/)project.\n\n[![rosetta_at_home_logo](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/12\/rosetta_at_home_logo.gif?resize=297%2C100)](http:\/\/boinc.bakerlab.org\/)\n\n[Rosetta@home](http:\/\/boinc.bakerlab.org\/)\u00a0project is\u00a0determining the 3-dimensional shapes of proteins through research, that may ultimately lead to finding cures for some major human diseases such as [HIV, Malaria, Cancer, and Alzheimer\u2019s](http:\/\/boinc.bakerlab.org\/rosetta\/rah_medical_relevance.php). The project is lead by [Dr David Baker ](http:\/\/boinc.bakerlab.org\/rah_welcome.php)at the [Univerity of Washington](https:\/\/www.washington.edu\/).\n\nYou can [find out more ](http:\/\/boinc.bakerlab.org\/rah_welcome.php)about the [Rosetta@Home](http:\/\/boinc.bakerlab.org\/) project on their website \u2013 [http:\/\/boinc.bakerlab.org\/](http:\/\/boinc.bakerlab.org\/).\n\nNot only will this be my 4th year contributing, I have also surpased the\n\n\n# 1,000,000\n\n[![certificat](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/12\/certificat.png?resize=700%2C506)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/12\/certificat1.png?ssl=1)\n\n[credits mark](http:\/\/boincstats.com\/en\/stats\/14\/user\/detail\/404524). I think in part this is because of my new i5 CPU I got for my birthday this year.\n\n[![Bimw0KOCIAA0mmX](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/12\/Bimw0KOCIAA0mmX.png?resize=599%2C465)](https:\/\/twitter.com\/dabsdotcom\/status\/444092168698089472)\n\n\u00a0\n\n\n","html":"<p>Tomorrow, Sunday the 7th December 2014, I will be celebrating 4 years of contributing wasted CPU cycles to the excellent <a href=\"http:\/\/boinc.bakerlab.org\/\" target=\"_blank\" rel=\"nofollow\">Rosetta@Home <\/a>project.<\/p>\n<p><a href=\"http:\/\/boinc.bakerlab.org\/\" target=\"_blank\" rel=\"nofollow\"><img class=\"size-full wp-image-243 aligncenter\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/12\/rosetta_at_home_logo.gif?resize=297%2C100\" alt=\"rosetta_at_home_logo\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p><a href=\"http:\/\/boinc.bakerlab.org\/\" target=\"_blank\" rel=\"nofollow\">Rosetta@home<\/a>\u00a0project is\u00a0determining the 3-dimensional shapes of proteins through research, that may ultimately lead to finding cures for some major human diseases such as <a href=\"http:\/\/boinc.bakerlab.org\/rosetta\/rah_medical_relevance.php\" target=\"_blank\" rel=\"nofollow\">HIV, Malaria, Cancer, and Alzheimer&#8217;s<\/a>. The project is lead by <a href=\"http:\/\/boinc.bakerlab.org\/rah_welcome.php\" target=\"_blank\" rel=\"nofollow\">Dr David Baker <\/a>at the <a href=\"https:\/\/www.washington.edu\/\" target=\"_blank\" rel=\"nofollow\">Univerity of Washington<\/a>.<\/p>\n<p>You can <a href=\"http:\/\/boinc.bakerlab.org\/rah_welcome.php\" target=\"_blank\" rel=\"nofollow\">find out more <\/a>about the <a href=\"http:\/\/boinc.bakerlab.org\/\" target=\"_blank\" rel=\"nofollow\">Rosetta@Home<\/a> project on their website &#8211; <a href=\"http:\/\/boinc.bakerlab.org\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/boinc.bakerlab.org\/<\/a>.<\/p>\n<p>Not only will this be my 4th year contributing, I have also surpased the<\/p>\n<h1 style=\"text-align: center;\">1,000,000<\/h1>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/12\/certificat1.png?ssl=1\"><img class=\"size-full wp-image-247 aligncenter\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/12\/certificat.png?resize=700%2C506\" alt=\"certificat\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p><a href=\"http:\/\/boincstats.com\/en\/stats\/14\/user\/detail\/404524\" target=\"_blank\" rel=\"nofollow\">credits mark<\/a>. I think in part this is because of my new i5 CPU I got for my birthday this year.<\/p>\n<p><a href=\"https:\/\/twitter.com\/dabsdotcom\/status\/444092168698089472\" target=\"_blank\" rel=\"nofollow\"><img class=\"alignnone size-full wp-image-244 aligncenter\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2014\/12\/Bimw0KOCIAA0mmX.png?resize=599%2C465\" alt=\"Bimw0KOCIAA0mmX\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 06 Dec 2014 21:56:28 +0000","created_by":1,"updated_at":"Fri, 10 Jun 2016 21:07:20 +0000","updated_by":1,"published_at":"Sat, 06 Dec 2014 21:56:28 +0000","published_by":1},{"id":252,"title":"Local Government to go Academy","slug":"local-government-to-go-academy","markdown":"\nIt appears the Local Government is looking to follow in schools\u00a0footsteps and do an \u201cAcademy\u201d \u2013 cutting the red tape and be given more control and freedom.\n\n<iframe allowfullscreen=\"\" frameborder=\"0\" height=\"394\" src=\"https:\/\/www.youtube.com\/embed\/09SLw1rAUpo?feature=oembed\" width=\"700\"><\/iframe>\n\n\n","html":"<p>It appears the Local Government is looking to follow in schools\u00a0footsteps and do an &#8220;Academy&#8221; &#8211; cutting the red tape and be given more control and freedom.<\/p>\n<p><iframe width=\"700\" height=\"394\" src=\"https:\/\/www.youtube.com\/embed\/09SLw1rAUpo?feature=oembed\" frameborder=\"0\" allowfullscreen><\/iframe><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 17 Dec 2014 00:45:40 +0000","created_by":1,"updated_at":"Fri, 10 Jun 2016 21:07:16 +0000","updated_by":1,"published_at":"Wed, 17 Dec 2014 00:45:40 +0000","published_by":1},{"id":263,"title":"Keyboard mapping [SQL 2014]","slug":"keyboard-mapping-sql-2014","markdown":"\nI\u2019ve been working on SQL Server 2014 lately and one of the annoying problems I\u2019ve stumbled across using SSMS is that F5 no longer means execute the SQL query, it now means Debug. Which brings up an annoying popup (least for me) about configuring my Windows Firewall.\n\nThis can be changed\u00a0in SSMS by going\u00a0**Tools** > **Customize\u2026** > **Keyboard\u2026**\n\nThe default is:\n\n`Debug.Start (F5 (Global))`\n\nAnd the traditional\u00a0is:\n\n`View.Refresh`\n\nYou can also do it by setting it to\u00a0Visual Studio 2010 Compatible\n\n\n","html":"<p>I&#8217;ve been working on SQL Server 2014 lately and one of the annoying problems I&#8217;ve stumbled across using SSMS is that F5 no longer means execute the SQL query, it now means Debug. Which brings up an annoying popup (least for me) about configuring my Windows Firewall.<\/p>\n<p>This can be changed\u00a0in SSMS by going\u00a0<strong>Tools<\/strong> &gt; <strong>Customize&#8230;<\/strong> &gt; <strong>Keyboard&#8230;<\/strong><\/p>\n<p>The default is:<\/p>\n<p><code>Debug.Start (F5 (Global))<\/code><\/p>\n<p>And the traditional\u00a0is:<\/p>\n<p><code>View.Refresh<\/code><\/p>\n<p>You can also do it by setting it to\u00a0Visual Studio 2010 Compatible<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 30 Dec 2014 00:20:11 +0000","created_by":1,"updated_at":"Tue, 30 Dec 2014 00:20:11 +0000","updated_by":1,"published_at":"Tue, 30 Dec 2014 00:20:11 +0000","published_by":1},{"id":347,"title":"Version Control","slug":"version-control","markdown":"\nI\u2019ve been thinking lately about the adoption of version control. One of the common fears of using version control is that its permanent. All mistakes are visible and are in fact, highlight.\u00a0Originals are updated with new commits which detail only the\u00a0change and a nice comment. There is no hiding mistakes. The thing is\n\n\n## *Mistakes are what make us human.*\n\nEveryone makes mistakes, we need to accept that fact. In doing so we can move forward faster.\n\n\n","html":"<p>I&#8217;ve been thinking lately about the adoption of version control. One of the common fears of using version control is that its permanent. All mistakes are visible and are in fact, highlight.\u00a0Originals are updated with new commits which detail only the\u00a0change and a nice comment. There is no hiding mistakes. The thing is<\/p>\n<h2><em>Mistakes are what make us human.<\/em><\/h2>\n<p>Everyone makes mistakes, we need to accept that fact. In doing so we can move forward faster.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 19 May 2015 23:03:26 +0000","created_by":1,"updated_at":"Tue, 19 May 2015 23:05:19 +0000","updated_by":1,"published_at":"Tue, 19 May 2015 23:03:26 +0000","published_by":1},{"id":351,"title":"Toshiba R50-B-12Q","slug":"toshiba-r50-b-12q","markdown":"\nUPDATE: [I\u2019ve detailed the Toshiba default build a bit here](https:\/\/matt40k.uk\/2015\/05\/toshiba-laptop-update\/)\n\nAt the beginning of the month I order a new laptop, for the past few weeks I\u2019ve been wanting something more mobile then my desktop, at first I was toying with the idea of selling my desktop and picking up a new [Surface](http:\/\/www.microsoft.com\/surface\/en-gb). The new Surface 3 which starts at \u00a3419 seemed like a good idea what with its sexy full hd touchscreen, however when you scratch the surface (ha ha) it doesn\u2019t look so go\n\n- Atom processor\n- 2GB RAM\n- 64GB storage\n\nNot really something beefy enough to be a main computer, add the fact my Blu-ray player is SATA and currently housed in my desktop means I\u2019d need to buy either a caddy or get a whole new external drive.\u00a0 So I\u2019m now looking at \u00a3700 for a half decent laptop, to get something to match my desktop, I\u2019m looking at around \u00a31200. So as you might have guessed. I ruled that out.\n\nI end up looking at cheap laptops, ideally I was after something that was upgradable \u2013 I had a spare solid state drive and I wanted to be able to upgrade the RAM later if needed. Ideally I would like a Full HD (1920 x 1280) screen, unfortunately no-one seems to\u00a0pack a nice screen\u00a0on a cheap\u00a0laptop, unless you want a Chromebook like [Toshiba Chromebook 2](http:\/\/www.toshiba.co.uk\/laptops\/chromebook\/chromebook-2\/).\u00a0In the end it came down to the [Lenovo ThinkPad E555](http:\/\/shop.lenovo.com\/gb\/en\/laptops\/thinkpad\/edge-series\/e555\/) and the [Toshiba Satellite Pro R50-B-12Q](http:\/\/www.toshiba.co.uk\/laptops\/satellite-pro\/r50-b\/satellite-pro-r50-b-12q\/). In the end I let cost decide, the Lenovo was \u00a350 more expensive (after the \u00a350 cash back), so I went for the Toshiba. The Toshiba was just under \u00a3200 from [Dabs](http:\/\/www.dabs.com\/). I also ordered a 4GB stick of RAM (Crucial part code: CT51264BF160BJ, Dabs quick: <span class=\"qlinks\">[8PQFWS00](https:\/\/www.dabs.com\/products\/crucial-4gb-ddr3-1600-mt-s--pc3-12800--8PQF.html)).<\/span>  \n[![WP_20150509_002](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150509_002-1024x575.jpg?fit=660%2C371&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150509_002.jpg?ssl=1)\n\nThe laptop came with a Windows 8.1 Pro license, which is about \u00a3100 for a OEM license. It comes with Windows 7 Pro installed and pretty clean build. There was a annoying bits, like a unregistered evaluation copy of WinZip and some annoying favourite websites but nothing as bad as what Lenovo has been installing by default. All the drivers appears to have been loaded via Windows Updates, I then created a installable USB pen drive as there is a no DVD drive on the laptop. You can [<u><span style=\"color: #0066cc;\">download the Windows 8.1 installation media direct from Microsoft for free<\/span><\/u>](http:\/\/windows.microsoft.com\/en-us\/windows-8\/create-reset-refresh-media). Once you\u2019ve download it, it will turn a USB pen drive into installation media.\n\nOpening the laptop was simple, they are standard cross screws. This particular model doesn\u2019t have a optical drive.\n\n[![WP_20150510_001](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_001-1024x575.jpg?fit=660%2C371&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_001.jpg?ssl=1)\n\nI\u2019ve removed the hdd, I could buy a caddy to use the empty optical drive space, but I\u2019m not a fan of the old traditional spindle hdd, so it had to go, plus I might add a optical drive later. Its nice to had options.\n\n[![WP_20150510_002](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_002-1024x575.jpg?fit=660%2C371&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_002.jpg?ssl=1)\n\nThe hdd wasn\u2019t actually screwed in place. Its just wedged in, I guess they call this shock absorbing technology. Seems to work pretty well.\n\nOne thing I will say is to be careful re-assembling it. I stupidly over tighten the screws and now have a few bumps under the keyboard.\n\n\n","html":"<p>UPDATE: <a href=\"https:\/\/matt40k.uk\/2015\/05\/toshiba-laptop-update\/\">I&#8217;ve detailed the Toshiba default build a bit here<\/a><\/p>\n<p>At the beginning of the month I order a new laptop, for the past few weeks I&#8217;ve been wanting something more mobile then my desktop, at first I was toying with the idea of selling my desktop and picking up a new <a href=\"http:\/\/www.microsoft.com\/surface\/en-gb\" target=\"_blank\" rel=\"nofollow\">Surface<\/a>. The new Surface 3 which starts at \u00a3419 seemed like a good idea what with its sexy full hd touchscreen, however when you scratch the surface (ha ha) it doesn&#8217;t look so go<\/p>\n<ul>\n<li>Atom processor<\/li>\n<li>2GB RAM<\/li>\n<li>64GB storage<\/li>\n<\/ul>\n<p>Not really something beefy enough to be a main computer, add the fact my Blu-ray player is SATA and currently housed in my desktop means I&#8217;d need to buy either a caddy or get a whole new external drive.\u00a0 So I&#8217;m now looking at \u00a3700 for a half decent laptop, to get something to match my desktop, I&#8217;m looking at around \u00a31200. So as you might have guessed. I ruled that out.<\/p>\n<p>I end up looking at cheap laptops, ideally I was after something that was upgradable &#8211; I had a spare solid state drive and I wanted to be able to upgrade the RAM later if needed. Ideally I would like a Full HD (1920 x 1280) screen, unfortunately no-one seems to\u00a0pack a nice screen\u00a0on a cheap\u00a0laptop, unless you want a Chromebook like <a href=\"http:\/\/www.toshiba.co.uk\/laptops\/chromebook\/chromebook-2\/\" target=\"_blank\" rel=\"nofollow\">Toshiba Chromebook 2<\/a>.\u00a0In the end it came down to the <a href=\"http:\/\/shop.lenovo.com\/gb\/en\/laptops\/thinkpad\/edge-series\/e555\/\" target=\"_blank\" rel=\"nofollow\">Lenovo ThinkPad E555<\/a> and the <a href=\"http:\/\/www.toshiba.co.uk\/laptops\/satellite-pro\/r50-b\/satellite-pro-r50-b-12q\/\" target=\"_blank\" rel=\"nofollow\">Toshiba Satellite Pro R50-B-12Q<\/a>. In the end I let cost decide, the Lenovo was \u00a350 more expensive (after the \u00a350 cash back), so I went for the Toshiba. The Toshiba was just under \u00a3200 from <a href=\"http:\/\/www.dabs.com\/\" target=\"_blank\" rel=\"nofollow\">Dabs<\/a>. I also ordered a 4GB stick of RAM (Crucial part code: CT51264BF160BJ, Dabs quick: <span class=\"qlinks\"><a href=\"https:\/\/www.dabs.com\/products\/crucial-4gb-ddr3-1600-mt-s--pc3-12800--8PQF.html\" target=\"_blank\" rel=\"nofollow\">8PQFWS00<\/a>).<\/span><br \/>\n<a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150509_002.jpg?ssl=1\"><img class=\"aligncenter wp-image-352 size-large\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150509_002-1024x575.jpg?fit=660%2C371&#038;ssl=1\" alt=\"WP_20150509_002\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150509_002.jpg?resize=1024%2C575&amp;ssl=1 1024w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150509_002.jpg?resize=300%2C168&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150509_002.jpg?w=1277&amp;ssl=1 1277w\" sizes=\"(max-width: 660px) 100vw, 660px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>The laptop came with a Windows 8.1 Pro license, which is about \u00a3100 for a OEM license. It comes with Windows 7 Pro installed and pretty clean build. There was a annoying bits, like a unregistered evaluation copy of WinZip and some annoying favourite websites but nothing as bad as what Lenovo has been installing by default. All the drivers appears to have been loaded via Windows Updates, I then created a installable USB pen drive as there is a no DVD drive on the laptop. You can <a href=\"http:\/\/windows.microsoft.com\/en-us\/windows-8\/create-reset-refresh-media\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">download the Windows 8.1 installation media direct from Microsoft for free<\/span><\/u><\/a>. Once you&#8217;ve download it, it will turn a USB pen drive into installation media.<\/p>\n<p>Opening the laptop was simple, they are standard cross screws. This particular model doesn&#8217;t have a optical drive.<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_001.jpg?ssl=1\"><img class=\"aligncenter wp-image-353 size-large\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_001-1024x575.jpg?fit=660%2C371&#038;ssl=1\" alt=\"WP_20150510_001\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_001.jpg?resize=1024%2C575&amp;ssl=1 1024w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_001.jpg?resize=300%2C168&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_001.jpg?w=1277&amp;ssl=1 1277w\" sizes=\"(max-width: 660px) 100vw, 660px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>I&#8217;ve removed the hdd, I could buy a caddy to use the empty optical drive space, but I&#8217;m not a fan of the old traditional spindle hdd, so it had to go, plus I might add a optical drive later. Its nice to had options.<\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_002.jpg?ssl=1\"><img class=\"aligncenter wp-image-354 size-large\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_002-1024x575.jpg?fit=660%2C371&#038;ssl=1\" alt=\"WP_20150510_002\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_002.jpg?resize=1024%2C575&amp;ssl=1 1024w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_002.jpg?resize=300%2C168&amp;ssl=1 300w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/WP_20150510_002.jpg?w=1277&amp;ssl=1 1277w\" sizes=\"(max-width: 660px) 100vw, 660px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>The hdd wasn&#8217;t actually screwed in place. Its just wedged in, I guess they call this shock absorbing technology. Seems to work pretty well.<\/p>\n<p>One thing I will say is to be careful re-assembling it. I stupidly over tighten the screws and now have a few bumps under the keyboard.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 25 May 2015 20:51:53 +0000","created_by":1,"updated_at":"Sun, 31 May 2015 08:43:00 +0000","updated_by":1,"published_at":"Mon, 25 May 2015 20:51:53 +0000","published_by":1},{"id":359,"title":"Technical debt","slug":"technical-debt","markdown":"\nI was talking to a colleague about one of our suppliers and the progress they were making\u00a0on a new product they were developing. He was surprised to hear how little progress they appear to have made, they had previously been making huge steps in very little time with very few developers, especially surprising when they have been scaling up the development team over the past few months. I explained they are burning some of the technical debt they have collected whilst they still can. This of course then led to me explaining what I meant by using a common product, which then later prompted this tweet (which irony Capita hit the\u00a0favourite button on)\n\n> Explaining technical debt to schools is extremely easy thanks to [@CapitaSIMS](https:\/\/twitter.com\/CapitaSIMS) :p\n> \n> \u2014 Matt Smith (@matt40k) [May 26, 2015](https:\/\/twitter.com\/matt40k\/status\/603139277191544832)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\nFor secondary schools who use SIMS .net \u2013 which is most schools in the UK \u2013 this can be simply be explained by Nova-T. Nova-T6 is a perfect example. Technically, it should be written in C#\/.NET, however, there is a no business case, so it\u2019s still a Delphi program. From a end-user perspective if they re-wrote it, they would gain nothing. Personally however, this still doesn\u2019t mean it should be ruled out. It\u2019s easier to maintain C# code when you have a small army of C# developers vs only a hand full of aging Delphi coders.\u00a0Not to mention the advantage of C# over Delphi. The longer Capita leaves it, the more the interest costs them. Just look at some of the technical problems SIMS customers have had, it can all be tracked back to that technical debt. That debt that Capita needs to pay before the interest becomes to high.\n\n\n","html":"<p>I was talking to a colleague about one of our suppliers and the progress they were making\u00a0on a new product they were developing. He was surprised to hear how little progress they appear to have made, they had previously been making huge steps in very little time with very few developers, especially surprising when they have been scaling up the development team over the past few months. I explained they are burning some of the technical debt they have collected whilst they still can. This of course then led to me explaining what I meant by using a common product, which then later prompted this tweet (which irony Capita hit the\u00a0favourite button on)<\/p>\n<blockquote class=\"twitter-tweet\" width=\"550\">\n<p lang=\"en\" dir=\"ltr\">Explaining technical debt to schools is extremely easy thanks to <a href=\"https:\/\/twitter.com\/CapitaSIMS\" target=\"_blank\" rel=\"nofollow\">@CapitaSIMS<\/a> :p<\/p>\n<p>&mdash; Matt Smith (@matt40k) <a href=\"https:\/\/twitter.com\/matt40k\/status\/603139277191544832\" target=\"_blank\" rel=\"nofollow\">May 26, 2015<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>For secondary schools who use SIMS .net &#8211; which is most schools in the UK &#8211; this can be simply be explained by Nova-T. Nova-T6 is a perfect example. Technically, it should be written in C#\/.NET, however, there is a no business case, so it&#8217;s still a Delphi program. From a end-user perspective if they re-wrote it, they would gain nothing. Personally however, this still doesn&#8217;t mean it should be ruled out. It&#8217;s easier to maintain C# code when you have a small army of C# developers vs only a hand full of aging Delphi coders.\u00a0Not to mention the advantage of C# over Delphi. The longer Capita leaves it, the more the interest costs them. Just look at some of the technical problems SIMS customers have had, it can all be tracked back to that technical debt. That debt that Capita needs to pay before the interest becomes to high.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 26 May 2015 21:39:05 +0000","created_by":1,"updated_at":"Tue, 26 May 2015 21:39:05 +0000","updated_by":1,"published_at":"Tue, 26 May 2015 21:39:05 +0000","published_by":1},{"id":367,"title":"Toshiba laptop update","slug":"toshiba-laptop-update","markdown":"\nJust an update to [my previous post about the Toshiba Laptop](https:\/\/matt40k.uk\/2015\/05\/toshiba-r50-b-12q\/), I\u2019ve been thinking about reinstalling the Toshiba laptop with Ubuntu, but before I do that, I want a backup. Luckily, I still have the original 500GB hdd spare, I just need a USB caddy. Luckily my local Curry\u2019s had a USB3.0 one ([PNY SSD and 2.5\u2033 Hard Drive Enclosure and Upgrade Kit](http:\/\/www.currys.co.uk\/gbuk\/computing\/ipad-tablets-and-ereaders\/tablets\/tablet-accessories\/pny-ssd-and-2-5-hard-drive-enclosure-and-upgrade-kit-22082146-pdt.html)), before anyone comments about how I could of got one cheaper off eBay, just remember, I was able to get it same day and it included Acronis.\n\nBefore I swapped the HDD out for a SSD, I ran[ a simple PowerShell script to get a list of installed applications](https:\/\/gist.github.com\/matt40k\/afb3623292dbd62151cd), you can see the list [here](https:\/\/gist.github.com\/matt40k\/6b688214e7b8b117df3d).\n\n<figure class=\"wp-caption aligncenter\" id=\"attachment_370\" style=\"width: 660px\">[![Desktop](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/Desktop-1024x576.png?fit=660%2C371&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/Desktop.png?ssl=1)<figcaption class=\"wp-caption-text\">Desktop<\/figcaption><\/figure><figure class=\"wp-caption aligncenter\" id=\"attachment_369\" style=\"width: 660px\">[![IE](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/IE-1024x576.png?fit=660%2C371&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/IE.png?ssl=1)<figcaption class=\"wp-caption-text\">Internet Explorer (Homepage)<\/figcaption><\/figure><figure class=\"wp-caption aligncenter\" id=\"attachment_368\" style=\"width: 660px\">[![hdd](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/hdd-1024x576.png?fit=660%2C371&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/hdd.png?ssl=1)<figcaption class=\"wp-caption-text\">HDD Warning<\/figcaption><\/figure>One of the problems with traditional HDD is the fact they have moving parts, if your moving your laptop around and you bang it, it can get damage, Toshiba have implemented a safely feature where when movement is detected it moved the HDD file header to a safe position. It make sound a little bit extreme, but when your talking about a disc that spins at over 4000 RPM and is wafer thin, you kinda get why they\u2019ve add the feature. Personally, SSD is a better fix. No moving parts \ud83d\ude42\n\n\n","html":"<p>Just an update to <a href=\"https:\/\/matt40k.uk\/2015\/05\/toshiba-r50-b-12q\/\">my previous post about the Toshiba Laptop<\/a>, I&#8217;ve been thinking about reinstalling the Toshiba laptop with Ubuntu, but before I do that, I want a backup. Luckily, I still have the original 500GB hdd spare, I just need a USB caddy. Luckily my local Curry&#8217;s had a USB3.0 one (<a href=\"http:\/\/www.currys.co.uk\/gbuk\/computing\/ipad-tablets-and-ereaders\/tablets\/tablet-accessories\/pny-ssd-and-2-5-hard-drive-enclosure-and-upgrade-kit-22082146-pdt.html\" target=\"_blank\" rel=\"nofollow\">PNY SSD and 2.5&#8243; Hard Drive Enclosure and Upgrade Kit<\/a>), before anyone comments about how I could of got one cheaper off eBay, just remember, I was able to get it same day and it included Acronis.<\/p>\n<p>Before I swapped the HDD out for a SSD, I ran<a href=\"https:\/\/gist.github.com\/matt40k\/afb3623292dbd62151cd\" target=\"_blank\" rel=\"nofollow\"> a simple PowerShell script to get a list of installed applications<\/a>, you can see the list <a href=\"https:\/\/gist.github.com\/matt40k\/6b688214e7b8b117df3d\" target=\"_blank\" rel=\"nofollow\">here<\/a>.<\/p>\n<figure id=\"attachment_370\" style=\"width: 660px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/Desktop.png?ssl=1\"><img class=\"wp-image-370 size-large\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/Desktop-1024x576.png?fit=660%2C371&#038;ssl=1\" alt=\"Desktop\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/Desktop.png?resize=1024%2C576&amp;ssl=1 1024w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/Desktop.png?resize=300%2C169&amp;ssl=1 300w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/Desktop.png?w=1366&amp;ssl=1 1366w\" sizes=\"(max-width: 660px) 100vw, 660px\" data-recalc-dims=\"1\" \/><\/a><figcaption class=\"wp-caption-text\">Desktop<\/figcaption><\/figure>\n<figure id=\"attachment_369\" style=\"width: 660px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/IE.png?ssl=1\"><img class=\"wp-image-369 size-large\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/IE-1024x576.png?fit=660%2C371&#038;ssl=1\" alt=\"IE\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/IE.png?resize=1024%2C576&amp;ssl=1 1024w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/IE.png?resize=300%2C169&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/IE.png?w=1366&amp;ssl=1 1366w\" sizes=\"(max-width: 660px) 100vw, 660px\" data-recalc-dims=\"1\" \/><\/a><figcaption class=\"wp-caption-text\">Internet Explorer (Homepage)<\/figcaption><\/figure>\n<figure id=\"attachment_368\" style=\"width: 660px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/hdd.png?ssl=1\"><img class=\"wp-image-368 size-large\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/hdd-1024x576.png?fit=660%2C371&#038;ssl=1\" alt=\"hdd\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/hdd.png?resize=1024%2C576&amp;ssl=1 1024w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/hdd.png?resize=300%2C169&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/05\/hdd.png?w=1366&amp;ssl=1 1366w\" sizes=\"(max-width: 660px) 100vw, 660px\" data-recalc-dims=\"1\" \/><\/a><figcaption class=\"wp-caption-text\">HDD Warning<\/figcaption><\/figure>\n<p>One of the problems with traditional HDD is the fact they have moving parts, if your moving your laptop around and you bang it, it can get damage, Toshiba have implemented a safely feature where when movement is detected it moved the HDD file header to a safe position. It make sound a little bit extreme, but when your talking about a disc that spins at over 4000 RPM and is wafer thin, you kinda get why they&#8217;ve add the feature. Personally, SSD is a better fix. No moving parts \ud83d\ude42<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 31 May 2015 08:40:58 +0000","created_by":1,"updated_at":"Sun, 31 May 2015 08:40:58 +0000","updated_by":1,"published_at":"Sun, 31 May 2015 08:40:58 +0000","published_by":1},{"id":374,"title":"Parking fines issued in Ipswich","slug":"parking-fines-issued-in-ipswich","markdown":"\n<iframe allowfullscreen=\"\" frameborder=\"0\" height=\"360\" mozallowfullscreen=\"\" src=\"https:\/\/player.vimeo.com\/video\/130773925\" title=\"Parking Tickets Issued\" webkitallowfullscreen=\"\" width=\"640\"><\/iframe>\n\nI\u00a0made the\u00a0above video using Microsoft Excel using data\u00a0from a FOI request to [Ipswich Borough Council](https:\/\/www.ipswich.gov.uk\/) about the number of Parking fines issued since 2010.\n\n\n","html":"<p><iframe src=\"https:\/\/player.vimeo.com\/video\/130773925\" width=\"640\" height=\"360\" frameborder=\"0\" title=\"Parking Tickets Issued\" webkitallowfullscreen mozallowfullscreen allowfullscreen><\/iframe><\/p>\n<p>I\u00a0made the\u00a0above video using Microsoft Excel using data\u00a0from a FOI request to <a href=\"https:\/\/www.ipswich.gov.uk\/\" target=\"_blank\" rel=\"nofollow\">Ipswich Borough Council<\/a> about the number of Parking fines issued since 2010.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 16 Jun 2015 20:52:51 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:15:17 +0000","updated_by":1,"published_at":"Tue, 16 Jun 2015 20:52:51 +0000","published_by":1},{"id":378,"title":"New Azure features","slug":"new-azure-features","markdown":"\nTwo new [Azure](http:\/\/azure.microsoft.com\/en-gb) features have caught my eye\u00a0\u2013 the first is [Logic App](http:\/\/azure.microsoft.com\/en-gb\/services\/app-service\/logic\/). In a nutshell this is workflow. You have connectors and you can add triggers and actions. So you could have a trigger on your HR system that when a new employee starts, it creates a user account then sends a welcome message to the existing staff informing them of the new starters.\n\nThe other is [Data Catalog](http:\/\/azure.microsoft.com\/en-gb\/services\/data-catalog\/), this basically allows you to generate meta data about your data sources. Effectively this becomes\u00a0your documentation, your point of reference when it comes data. This looks to solve a very real problem\u00a0large enterprises have. Too much data, silo away.\n\n\n","html":"<p>Two new <a href=\"http:\/\/azure.microsoft.com\/en-gb\" target=\"_blank\" rel=\"nofollow\">Azure<\/a> features have caught my eye\u00a0&#8211; the first is <a href=\"http:\/\/azure.microsoft.com\/en-gb\/services\/app-service\/logic\/\" target=\"_blank\" rel=\"nofollow\">Logic App<\/a>. In a nutshell this is workflow. You have connectors and you can add triggers and actions. So you could have a trigger on your HR system that when a new employee starts, it creates a user account then sends a welcome message to the existing staff informing them of the new starters.<\/p>\n<p>The other is <a href=\"http:\/\/azure.microsoft.com\/en-gb\/services\/data-catalog\/\" target=\"_blank\" rel=\"nofollow\">Data Catalog<\/a>, this basically allows you to generate meta data about your data sources. Effectively this becomes\u00a0your documentation, your point of reference when it comes data. This looks to solve a very real problem\u00a0large enterprises have. Too much data, silo away.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Thu, 16 Jul 2015 21:43:05 +0000","created_by":1,"updated_at":"Thu, 16 Jul 2015 21:43:05 +0000","updated_by":1,"published_at":"Thu, 16 Jul 2015 21:43:05 +0000","published_by":1},{"id":380,"title":"Swollen Business Objects database","slug":"swollen-business-objects-database","markdown":"\nOur new HR system uses SAP Business Objects for transactional reporting, as this was setup by our HR supplier we haven\u2019t really got involved with it beyond writing a few custom reports, turns out we\u2019ve written quite a few, so much so that the Business Objects CMS database has swollen to over 30 GBs. This, as you might have guessed, is causing a few performance problems. After a discussion with the supplier, we found out it was storing all the reports, even the ad-hoc one-off reports and we should have set a parameter to limit it.\n\nAfter limiting it, the database still didn\u2019t reduce the database size. A quick [Google found someone saying that it is because it can\u2019t handle over 1 million rows of old reports](http:\/\/bukhantsov.org\/2012\/05\/removing-the-failed-instances-manually-from-the-database\/), which makes sense, running a SQL command that would delete over 30gb of data would have insane log file grow as well as massive performance problems.\n\nThe steps to resolve this, on MS-SQL, was to:\n\n1. Stop the Business Objects services on the app tier\n2. Ensure you have a backup of the database\n3. Set the recovery model to simple if it isn\u2019t already\n4. Copy out all the required rows\n<script src=\"https:\/\/gist.github.com\/matt40k\/7ce305248bd9497f6b46.js\"><\/script>\n\n6. Truncate the table\n7. Re-insert the required\u00a0rows back into the table\n8. Check everything looks ok, deal with the fact the database is now tiny\n9. Create another backup\n10. Start the app tier backup\n\n\n","html":"<p>Our new HR system uses SAP Business Objects for transactional reporting, as this was setup by our HR supplier we haven&#8217;t really got involved with it beyond writing a few custom reports, turns out we&#8217;ve written quite a few, so much so that the Business Objects CMS database has swollen to over 30 GBs. This, as you might have guessed, is causing a few performance problems. After a discussion with the supplier, we found out it was storing all the reports, even the ad-hoc one-off reports and we should have set a parameter to limit it.<\/p>\n<p>After limiting it, the database still didn&#8217;t reduce the database size. A quick <a href=\"http:\/\/bukhantsov.org\/2012\/05\/removing-the-failed-instances-manually-from-the-database\/\" target=\"_blank\" rel=\"nofollow\">Google found someone saying that it is because it can&#8217;t handle over 1 million rows of old reports<\/a>, which makes sense, running a SQL command that would delete over 30gb of data would have insane log file grow as well as massive performance problems.<\/p>\n<p>The steps to resolve this, on MS-SQL, was to:<\/p>\n<ol>\n<li>Stop the Business Objects services on the app tier<\/li>\n<li>Ensure you have a backup of the database<\/li>\n<li>Set the recovery model to simple if it isn&#8217;t already<\/li>\n<li>Copy out all the required rows<\/li>\n<p><script src=\"https:\/\/gist.github.com\/matt40k\/7ce305248bd9497f6b46.js\"><\/script><\/p>\n<li>Truncate the table<\/li>\n<li>Re-insert the required\u00a0rows back into the table<\/li>\n<li>Check everything looks ok, deal with the fact the database is now tiny<\/li>\n<li>Create another backup<\/li>\n<li>Start the app tier backup<\/li>\n<\/ol>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 19 Jul 2015 19:58:50 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:14:56 +0000","updated_by":1,"published_at":"Sun, 19 Jul 2015 19:58:50 +0000","published_by":1},{"id":337,"title":"Moved backup locations","slug":"moved-backup-locations","markdown":"\nIt appears IBM has moved the Cognos backup folder location from:  \n C:\\Program Files\\ibm\\cognos\\c10_64\\bkp  \n To:  \n C:\\Program Files\\ibm\\cognos\\c10_64\\uninstall\n\n\n","html":"<p>It appears IBM has moved the Cognos backup folder location from:<br \/>\nC:\\Program Files\\ibm\\cognos\\c10_64\\bkp<br \/>\nTo:<br \/>\nC:\\Program Files\\ibm\\cognos\\c10_64\\uninstall<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 22 Jul 2015 12:47:20 +0000","created_by":1,"updated_at":"Wed, 22 Jul 2015 12:47:20 +0000","updated_by":1,"published_at":"Wed, 22 Jul 2015 12:47:20 +0000","published_by":1},{"id":388,"title":"Failed RavenDB backup","slug":"failed-ravendb-backup","markdown":"\nI had a rather odd error with [OctopusDeploy ](http:\/\/octopusdeploy.com\/)where the [RavenDB](http:\/\/ravendb.net\/) backups were failing. Turns out the problem was because I had assigned 1 IPv4 address to [OctopusDeploy ](http:\/\/octopusdeploy.com\/)and another IPv4 address for [TeamCity](https:\/\/www.jetbrains.com\/teamcity\/). Oddly the RavenDB backup routine\u00a0referenced the localhost address \u2013 127.0.0.1, it appeared to be hardcode with no option other then changing port. This was especially weird as the\u00a0[OctopusDeploy ](http:\/\/octopusdeploy.com\/)service,\u00a0was able to access it fine.\u00a0To resolve \u2013 at least long enough to get a backup to migrate to v3 which uses [SQL Server](http:\/\/www.microsoft.com\/en-gb\/server-cloud\/products\/sql-server\/) \u2013 was to setup a port proxy so accessing TCP port 10931\u00a0on the local loopback would resolve to the same port but on a the actual public IPv4\n\nTo do this run Command Prompt as Administrator (right-click, Run As Administrator) then type\n\n> netsh  \n>  interface portproxy  \n>  add v4tov4 listenaddress=127.0.0.1 listenport=10931 connectaddress={{your ip}} connectport=10931\n\nRemember to replace {{your ip}} with the actual IP address\n\n\n","html":"<p>I had a rather odd error with <a href=\"http:\/\/octopusdeploy.com\/\" target=\"_blank\" rel=\"nofollow\">OctopusDeploy <\/a>where the <a href=\"http:\/\/ravendb.net\/\" target=\"_blank\" rel=\"nofollow\">RavenDB<\/a> backups were failing. Turns out the problem was because I had assigned 1 IPv4 address to <a href=\"http:\/\/octopusdeploy.com\/\" target=\"_blank\" rel=\"nofollow\">OctopusDeploy <\/a>and another IPv4 address for <a href=\"https:\/\/www.jetbrains.com\/teamcity\/\" target=\"_blank\" rel=\"nofollow\">TeamCity<\/a>. Oddly the RavenDB backup routine\u00a0referenced the localhost address &#8211; 127.0.0.1, it appeared to be hardcode with no option other then changing port. This was especially weird as the\u00a0<a href=\"http:\/\/octopusdeploy.com\/\" target=\"_blank\" rel=\"nofollow\">OctopusDeploy <\/a>service,\u00a0was able to access it fine.\u00a0To resolve &#8211; at least long enough to get a backup to migrate to v3 which uses <a href=\"http:\/\/www.microsoft.com\/en-gb\/server-cloud\/products\/sql-server\/\" target=\"_blank\" rel=\"nofollow\">SQL Server<\/a> &#8211; was to setup a port proxy so accessing TCP port 10931\u00a0on the local loopback would resolve to the same port but on a the actual public IPv4<\/p>\n<p>To do this run Command Prompt as Administrator (right-click, Run As Administrator) then type<\/p>\n<blockquote><p>netsh<br \/>\ninterface portproxy<br \/>\nadd v4tov4 listenaddress=127.0.0.1 listenport=10931 connectaddress={{your ip}} connectport=10931<\/p><\/blockquote>\n<p>Remember to replace {{your ip}} with the actual IP address<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 22 Jul 2015 12:55:55 +0000","created_by":1,"updated_at":"Wed, 22 Jul 2015 12:56:28 +0000","updated_by":1,"published_at":"Wed, 22 Jul 2015 12:55:55 +0000","published_by":1},{"id":417,"title":"Small world","slug":"small-world","markdown":"\nSo I\u2019ve been following a few folks on Twitter \u2013 one of them is\u00a0[Tim Mitchell](http:\/\/www.timmitchell.net\/) from the US, he\u00a0[tweeted a link to some resources](https:\/\/twitter.com\/Tim_Mitchell\/status\/638020785429479424)\u00a0he used in a recent [SQL Saturday](http:\/\/www.sqlsaturday.com\/) he presented at.\n\nOne of them is\u00a0[Konesans.com](http:\/\/www.konesans.com\/). Who happen to be based in\u00a0Holbeach, which is really close to my home town of Wisbech. You go all over the world in search of knowledge, only to\u00a0find there\u2019s a guru right on your own doorstep.\n\n\n","html":"<p>So I&#8217;ve been following a few folks on Twitter &#8211; one of them is\u00a0<a href=\"http:\/\/www.timmitchell.net\/\" target=\"_blank\" rel=\"nofollow\">Tim Mitchell<\/a> from the US, he\u00a0<a href=\"https:\/\/twitter.com\/Tim_Mitchell\/status\/638020785429479424\" target=\"_blank\" rel=\"nofollow\">tweeted a link to some resources<\/a>\u00a0he used in a recent <a href=\"http:\/\/www.sqlsaturday.com\/\" target=\"_blank\" rel=\"nofollow\">SQL Saturday<\/a> he presented at.<\/p>\n<p>One of them is\u00a0<a href=\"http:\/\/www.konesans.com\/\" target=\"_blank\" rel=\"nofollow\">Konesans.com<\/a>. Who happen to be based in\u00a0Holbeach, which is really close to my home town of Wisbech. You go all over the world in search of knowledge, only to\u00a0find there&#8217;s a guru right on your own doorstep.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 30 Aug 2015 20:51:12 +0000","created_by":1,"updated_at":"Sun, 30 Aug 2015 20:51:12 +0000","updated_by":1,"published_at":"Sun, 30 Aug 2015 20:51:12 +0000","published_by":1},{"id":419,"title":"Documentation","slug":"documentation","markdown":"\nOne of the problems we have is documentation and how to keep it up-to-date. We tend to deliver a new batch\u00a0of reports as part of a CR (Change Request) then make changes as part of BAU (Business as usual) unless its a particularly complex or time consuming change. The problem is often BAU changes happen rapidly often within a short time frame and\u00a0time isn\u2019t always allocated to updating documentation.\n\nOver time a small, simple change and evolve into a major change and the documentation can significantly drift out-of-sync.\u00a0Documentation is an important part of the communication between developer, analysis and the end-user, without it misunderstanding and confusing can occur and errors and mistakes happen.\n\nWhilst investigating how other are documentation work I rediscovered the much unloved extended property MS_Description. As you might have guess, using the description field to enter, yes, you guessed it, a description of the tables, views, stored procedure and other SQL objects. Speaking of naming \u2013 it\u2019s also important to name things correctly. A table named dbo.Table1 helps no-one. I tend to name any temporary tables MS_TMP \u2013 this then quickly identities me as the owner and the fact it can most likely be destroyed. Any dimensions are prefix with Dim and facts are, yes, you\u2019ve guessed it again \u2013 Fact.\n\nI have a TSQL script that pulls this data into a table on the staging database as part of a SSIS package, this is configured a SQL Job, however it is only execute post-deployment \u2013 we use [TeamCity](https:\/\/www.jetbrains.com\/teamcity\/) to build the project and then [OctopusDeploy](http:\/\/octopusdeploy.com\/) for deploying to the various environments.\n\nAs we move towards using Analysis Services, I needed a way to document the cubes, luckily [Alex Whittles](http:\/\/www.purplefrogsystems.com\/about-us.html) from [Purple Frog](http:\/\/www.purplefrogsystems.com\/)\u00a0has already come up with a solution using the\u00a0Dynamic Management Views (DMVs) and blogged about it \u2013\u00a0[http:\/\/www.purplefrogsystems.com\/blog\/2010\/09\/olap-cube-documentation-in-ssrs-part-1\/](http:\/\/www.purplefrogsystems.com\/blog\/2010\/09\/olap-cube-documentation-in-ssrs-part-1\/).\n\nI have however modified it, I\u2019ve followed the standard ETL process, so I\u2019ve extracted the data from the DMVs into a staging data, like SQL objects, this is only executed post-deployment by a SQL job that is executed by [OctopusDeploy](http:\/\/octopusdeploy.com\/) task. I didn\u2019t like the idea of dynamically querying the data every time and as we use continue integration\\deployment I don\u2019t need to worry about the data being out of data.\n\nAll I have left to really look at is documenting SSIS. Speaking of SSIS, I found [Jamie Thomson post on naming conventions](http:\/\/sqlblog.com\/blogs\/jamie_thomson\/archive\/2012\/01\/29\/suggested-best-practises-and-naming-conventions.aspx) very useful.\n\n\n","html":"<p>One of the problems we have is documentation and how to keep it up-to-date. We tend to deliver a new batch\u00a0of reports as part of a CR (Change Request) then make changes as part of BAU (Business as usual) unless its a particularly complex or time consuming change. The problem is often BAU changes happen rapidly often within a short time frame and\u00a0time isn&#8217;t always allocated to updating documentation.<\/p>\n<p>Over time a small, simple change and evolve into a major change and the documentation can significantly drift out-of-sync.\u00a0Documentation is an important part of the communication between developer, analysis and the end-user, without it misunderstanding and confusing can occur and errors and mistakes happen.<\/p>\n<p>Whilst investigating how other are documentation work I rediscovered the much unloved extended property MS_Description. As you might have guess, using the description field to enter, yes, you guessed it, a description of the tables, views, stored procedure and other SQL objects. Speaking of naming &#8211; it&#8217;s also important to name things correctly. A table named dbo.Table1 helps no-one. I tend to name any temporary tables MS_TMP &#8211; this then quickly identities me as the owner and the fact it can most likely be destroyed. Any dimensions are prefix with Dim and facts are, yes, you&#8217;ve guessed it again &#8211; Fact.<\/p>\n<p>I have a TSQL script that pulls this data into a table on the staging database as part of a SSIS package, this is configured a SQL Job, however it is only execute post-deployment &#8211; we use <a href=\"https:\/\/www.jetbrains.com\/teamcity\/\" target=\"_blank\" rel=\"nofollow\">TeamCity<\/a> to build the project and then <a href=\"http:\/\/octopusdeploy.com\/\" target=\"_blank\" rel=\"nofollow\">OctopusDeploy<\/a> for deploying to the various environments.<\/p>\n<p>As we move towards using Analysis Services, I needed a way to document the cubes, luckily <a href=\"http:\/\/www.purplefrogsystems.com\/about-us.html\" target=\"_blank\" rel=\"nofollow\">Alex Whittles<\/a> from <a href=\"http:\/\/www.purplefrogsystems.com\/\" target=\"_blank\" rel=\"nofollow\">Purple Frog<\/a>\u00a0has already come up with a solution using the\u00a0Dynamic Management Views (DMVs) and blogged about it &#8211;\u00a0<a href=\"http:\/\/www.purplefrogsystems.com\/blog\/2010\/09\/olap-cube-documentation-in-ssrs-part-1\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/www.purplefrogsystems.com\/blog\/2010\/09\/olap-cube-documentation-in-ssrs-part-1\/<\/a>.<\/p>\n<p>I have however modified it, I&#8217;ve followed the standard ETL process, so I&#8217;ve extracted the data from the DMVs into a staging data, like SQL objects, this is only executed post-deployment by a SQL job that is executed by <a href=\"http:\/\/octopusdeploy.com\/\" target=\"_blank\" rel=\"nofollow\">OctopusDeploy<\/a> task. I didn&#8217;t like the idea of dynamically querying the data every time and as we use continue integration\\deployment I don&#8217;t need to worry about the data being out of data.<\/p>\n<p>All I have left to really look at is documenting SSIS. Speaking of SSIS, I found <a href=\"http:\/\/sqlblog.com\/blogs\/jamie_thomson\/archive\/2012\/01\/29\/suggested-best-practises-and-naming-conventions.aspx\" target=\"_blank\" rel=\"nofollow\">Jamie Thomson post on naming conventions<\/a> very useful.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 30 Aug 2015 22:30:14 +0000","created_by":1,"updated_at":"Sun, 30 Aug 2015 22:33:07 +0000","updated_by":1,"published_at":"Sun, 30 Aug 2015 22:30:14 +0000","published_by":1},{"id":424,"title":"SSIS jumping in Visual Studio 2013 \/ SQL Server 2014","slug":"ssis-jumping-in-visual-studio-2013-sql-server-2014","markdown":"\nOne really annoying bug in SSIS when using Visual Studio 2013 \/ SQL Server 2014 is the object jumping, so when you drag an object like a sequence container down the object shoots to the bottom. Thankfully the fix is simple. Close Visual Studio and apply [SQL Server 2014 SP1](https:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=46694) to your machine.\n\n\n","html":"<p>One really annoying bug in SSIS when using Visual Studio 2013 \/ SQL Server 2014 is the object jumping, so when you drag an object like a sequence container down the object shoots to the bottom. Thankfully the fix is simple. Close Visual Studio and apply <a href=\"https:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=46694\" target=\"_blank\" rel=\"nofollow\">SQL Server 2014 SP1<\/a> to your machine.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 01 Sep 2015 12:00:08 +0000","created_by":1,"updated_at":"Wed, 02 Sep 2015 11:17:53 +0000","updated_by":1,"published_at":"Tue, 01 Sep 2015 12:00:08 +0000","published_by":1},{"id":426,"title":"Missing SSIS toolbox in Visual Studio 2013 \/ SQL Server 2014","slug":"missing-ssis-toolbox-in-visual-studio-2013-sql-server-2014","markdown":"\nStupidly today, I accidently closed the SSIS toolbox. After a bit of unsuccessful searching in the Visual Studio menus, I gave up and done the IT norm and Google it \u2013 hoping I wouldn\u2019t have to reinstall.\n\nLuckily I found [James Serra](http:\/\/www.jamesserra.com\/aboutme\/)\u00a0had [already blogged about it](http:\/\/www.jamesserra.com\/archive\/2013\/01\/ssis-2012-empty-toolbox\/),\u00a0the only difference is [Microsoft ](http:\/\/www.microsoft.com\/)has changed the icon, its still in the same place at least\n\n[![ssistoolbox](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/ssistoolbox.png?fit=489%2C106&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/ssistoolbox.png?ssl=1)\n\nSo when is a Visual Studio Toolbox, not a Toolbox? When it\u2019s a SSIS Toolbox.\n\n\n","html":"<p>Stupidly today, I accidently closed the SSIS toolbox. After a bit of unsuccessful searching in the Visual Studio menus, I gave up and done the IT norm and Google it &#8211; hoping I wouldn&#8217;t have to reinstall.<\/p>\n<p>Luckily I found <a href=\"http:\/\/www.jamesserra.com\/aboutme\/\" target=\"_blank\" rel=\"nofollow\">James Serra<\/a>\u00a0had <a href=\"http:\/\/www.jamesserra.com\/archive\/2013\/01\/ssis-2012-empty-toolbox\/\" target=\"_blank\" rel=\"nofollow\">already blogged about it<\/a>,\u00a0the only difference is <a href=\"http:\/\/www.microsoft.com\/\" target=\"_blank\" rel=\"nofollow\">Microsoft <\/a>has changed the icon, its still in the same place at least<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/ssistoolbox.png?ssl=1\"><img class=\"alignnone wp-image-427 size-full\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/ssistoolbox.png?fit=489%2C106&#038;ssl=1\" alt=\"ssistoolbox\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/ssistoolbox.png?w=489&amp;ssl=1 489w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/ssistoolbox.png?resize=300%2C65&amp;ssl=1 300w\" sizes=\"(max-width: 489px) 100vw, 489px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>So when is a Visual Studio Toolbox, not a Toolbox? When it&#8217;s a SSIS Toolbox.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 02 Sep 2015 11:17:09 +0000","created_by":1,"updated_at":"Wed, 02 Sep 2015 11:17:09 +0000","updated_by":1,"published_at":"Wed, 02 Sep 2015 11:17:09 +0000","published_by":1},{"id":461,"title":"Missing Reporting data toolbox in Visual Studio 2013 \/ SQL Server 2014","slug":"missing-reporting-data-toolbox-in-visual-studio-2013","markdown":"\nTodays problem, missing the reporting data toolbox in Visual Studio 2013 \u2013 once again, a different menu options. Open the actual report (.rdl)\n\n**View** > **Report Data**\n\nAlternatively press **Ctrl** + **Alt** + **D**\n\n\n","html":"<p>Todays problem, missing the reporting data toolbox in Visual Studio 2013 \u2013 once again, a different menu options. Open the actual report (.rdl)<\/p>\n<p><strong>View<\/strong> &gt; <strong>Report Data<\/strong><\/p>\n<p>Alternatively press <strong>Ctrl<\/strong> + <strong>Alt<\/strong> + <strong>D<\/strong><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 15 Sep 2015 20:21:16 +0000","created_by":1,"updated_at":"Tue, 15 Sep 2015 20:29:29 +0000","updated_by":1,"published_at":"Tue, 15 Sep 2015 20:21:16 +0000","published_by":1},{"id":464,"title":"Change text direction - Visual Studio 2013 \/ SQL Server 2014","slug":"change-text-direction-visual-studio-2013-sql-server-2014","markdown":"\nI\u2019ve spent a while today trying to change the text direction (orientation) of a header on a SSRS report \u2013 the option was rather oddly placed in Visual Studio \u2013 the option is within the properties (for the text) **Localization** > **Writing Mode** > then change from **Default** to either **Rotate270** or **Vertical**. I was hoping it would be within the Font options. Guess that would be too easy \ud83d\ude09\n\n\n","html":"<p>I&#8217;ve spent a while today trying to change the text direction (orientation) of a header on a SSRS report &#8211; the option was rather oddly placed in Visual Studio &#8211; the option is within the properties (for the text) <strong>Localization<\/strong> &gt; <strong>Writing Mode<\/strong> &gt; then change from <strong>Default<\/strong> to either <strong>Rotate270<\/strong> or <strong>Vertical<\/strong>. I was hoping it would be within the Font options. Guess that would be too easy \ud83d\ude09<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 15 Sep 2015 20:41:06 +0000","created_by":1,"updated_at":"Tue, 15 Sep 2015 20:41:06 +0000","updated_by":1,"published_at":"Tue, 15 Sep 2015 20:41:06 +0000","published_by":1},{"id":443,"title":"SQLSaturday #411 - Cambridge 2015","slug":"sqlsaturday-411-cambridge-2015","markdown":"\n[![](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/COsSZq8WEAAA_qB-300x179.png?fit=300%2C179&ssl=1)](http:\/\/www.sqlsaturday.com\/411\/eventhome.aspx)For a while now I\u2019ve been going to the\u00a0[Cambridgeshire SQL Server User Group](http:\/\/sqlcambs.org.uk\/category\/user-group\/), which I have found really useful especially as we are at moving towards a more self-service model across IT which requires IT to be a bit more cleverer. Beyond the informative speaker talks you get a really good networking opportunity. The group is run by [Mark Broadbent](http:\/\/tenbulls.co.uk\/) ([@retracement](https:\/\/twitter.com\/retracement)) and has recently merged with\u00a0[SharePoint Saturday Cambridge](http:\/\/sqlcambs.org.uk\/). Although Cambridge is about the same time on the train as London. I find Cambridge a nice place to visit, not just because it doesn\u2019t involve me going on the underground.\n\n[![IMG_0234](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0234-150x150.jpg?resize=150%2C150&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0234.jpg?ssl=1) [![IMG_0239](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0239-150x150.jpg?resize=150%2C150&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0239.jpg?ssl=1) [![IMG_0233](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0233-150x150.jpg?resize=150%2C150&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428.jpg?ssl=1)\n\n[![IMG_0232](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428-150x150.jpg?resize=150%2C150&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428.jpg?ssl=1) [![IMG_0237](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0237-e1442175813106-150x150.jpg?resize=150%2C150&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0237-e1442175813106.jpg?ssl=1)\n\nSome how Mark has managed to put together an entire day [SQL Saturday event](http:\/\/www.sqlsaturday.com\/411\/eventhome.aspx) with [two precon days](http:\/\/sqlcambs.org.uk\/preconall\/) \u2013 I swear this guy has gotten hold of [Mary Poppins bag](https:\/\/www.youtube.com\/watch?v=T3-LZx8NF8k). Don\u2019t let the precon name fool you, these are (well were) two full days of very good training. After all, its not every day you get a full-days training with a\u00a0**Microsoft Most Valuable Professional** (**MVP**) or the Data Warehouse Architect at [UNOPS](https:\/\/www.unops.org\/english\/Pages\/Home.aspx), the implementation arm of the UN!\n\nOne of the downsides of attending was having to get up a 5 am \ud83d\ude41\n\nNote to self: Next time, stay in a hotel \u2013 yes [Mark](https:\/\/twitter.com\/retracement), I should have read your [deals on hotels](http:\/\/sqlcambs.org.uk\/sqlsaturday-information-travel\/) (and looked at the back of the guide book for the map)  \n[![IMG_0221](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0221-150x150.jpg?resize=150%2C150&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0221.jpg?ssl=1) [![IMG_0210](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0210-e1442175792339-150x150.jpg?resize=150%2C150&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0210-e1442175792339.jpg?ssl=1) [![IMG_0230](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0230-150x150.jpg?resize=150%2C150&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0230.jpg?ssl=1)\n\n\n## Day 1\n\n\n## ![IMG_0227](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0227-300x225.jpg?fit=300%2C225&ssl=1)\n\nMy first day was with [Penny\u00a0Coventry](http:\/\/www.sharepointdesignerstepbystep.com\/Blog\/default.aspx)\u00a0\u2013 [Automating business processes with SharePoint, Office 365 and Azure](http:\/\/web.archive.org\/web\/20160209211202\/http:\/\/sqlcambs.org.uk\/precon1\/). This was a really good session where I got to see some of the power of [SharePoint](https:\/\/products.office.com\/en-gb\/sharepoint\/collaboration) and cool new\u00a0[Azure ](http:\/\/azure.microsoft.com\/en-gb\/)features\u00a0from the power\u00a0users perspective rather then the overly technical developer perspective. I\u2019ve often found users will shrug off ideas and solutions when explained by a \u201ctechy\u201d as being too \u201ctechnical\u201d \u2013 and to be fair to them, we do get a big excited and go over the config line and into the development world all too often.\n\nThe out-of-the-box just config, no development features in [SharePoint ](https:\/\/products.office.com\/en-gb\/sharepoint\/collaboration)like Workflows are amazing. From a \u201ctechy\u201d point of view, I\u2019m amazed at how easy it is to do something that would be quite complex to create as a bespoke app. It was also good to see how Microsoft are expanding into the cloud, both with [Office 365](https:\/\/products.office.com\/en-gb\/business\/explore-office-365-for-business) and [Azure](http:\/\/azure.microsoft.com\/en-gb\/). I\u2019ve previously only really looked into [Azure ](http:\/\/azure.microsoft.com\/en-gb\/)from the \u201ctechy\u201d side, like [Troy Hunt\u2019s \u201cHave I been pwned?\u201d](http:\/\/www.troyhunt.com\/2015\/08\/how-did-have-i-been-pwned-perform-on.html) site but I hadn\u2019t had a chance to have a look at things like\u00a0[Logic App](http:\/\/azure.microsoft.com\/en-gb\/services\/app-service\/logic). Logic App\u00a0which looks like its another workflow type services where you can drag and drop connections (kinda like SSIS) and do things like pulling tweets from [Twitter ](http:\/\/www.twitter.com\/)into a SharePoint list, or a MS-SQL database or whatever. Again, this is the sort of thing power users can do without IT or a developers. For me this is great news, creating custom connectors in SSIS is a pain, if the power users can get data into a MS-SQL database without me developing anything, great. Makes my like a lot simpler. Combine this with some of the SharePoint features, like Access Web Apps, I can give users access to the static data so they can keep it up-to-date without the manual process without fear of them wrecking it thanks to some (hopefully) clever business logic.\n\nOne last comment about the session, Penny completed the entire thing, including the live demos, using her Office 365\\Azure subscription. I was amazed at this as normally I find Office 365\\Azure professionals always have a \u201cbut\u201d when it comes to them being fully cloud, they always spin up a virtual machine or such. Despite being fully cloud, she knew all the little \u201cthis isn\u2019t on the on-prem version \u2013 yet\u201d or \u201cyou can\u2019t do that in the cloud\u201d or \u201cif you don\u2019t see that option on on-prem you need to..\u201d, as well as latest low down on SharePoint 2016.\n\nOther session going on was\u00a0[A Day with Columnstore Indexes](http:\/\/web.archive.org\/web\/20160210045257\/http:\/\/sqlcambs.org.uk\/precon3\/) with\u00a0[Niko Neugebauer](http:\/\/www.nikoport.com\/). To be honest, I wimped out of going to this one \u2013 I tend to leave the intimate details of indexes to our Senior DBA and just pick up the summary sheet at end and apply the base config and only update it when he says so. Lazy I know, but I can\u2019t learn everything at once!\n\n> Becoming a [#columnstore](https:\/\/twitter.com\/hashtag\/columnstore?src=hash) professional in [@NikoNeugebauer](https:\/\/twitter.com\/NikoNeugebauer) precon at [@sqlsatcambs](https:\/\/twitter.com\/sqlsatcambs) [pic.twitter.com\/HWlPXf8HRN](http:\/\/t.co\/HWlPXf8HRN)\n> \n> \u2014 Zuzana Skrinarova (@zuzskri) [September 10, 2015](https:\/\/twitter.com\/zuzskri\/status\/641921587889983488)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\n\n## Day 2\n\nThe second day was with\u00a0[Rasmus Reinholdt Nielsen](https:\/\/rasmusreinholdt.wordpress.com\/) \u2013\u00a0[Building tomorrows ETL architecture with BIML and MDS today](http:\/\/web.archive.org\/web\/20160210074148\/http:\/\/sqlcambs.org.uk\/precon4\/)\u00a0and was the main reason for me attending, I spend most of my time in SSIS. Despite packing two laptops, I still found myself popping\u00a0out to the shops to pick up a USB mouse as I forgot to pack one. I\u2019ve previously heard about [BIML](http:\/\/www.bimlscript.com\/) and despite being recommended from a lot of folks I just hadn\u2019t had a proper look, the main reason was the resentment towards Microsoft for not providing such a intermediate language \u2013 not that [Scott Currie](http:\/\/www.varigence.com) hasn\u2019t done amazing job, its just it should be merged into core product. Rasmus started with a introduction to C# which covered the basics, which he quickly skipped through as we all ready had a working knowledge of C# and got onto [BIML](http:\/\/www.bimlscript.com\/).\u00a0Before too long\u00a0I had created my [first basic BIML script](https:\/\/gist.github.com\/matt40k\/bb849ecb85ba7af13fe3). He then went onto some of the more complex features of SSIS and then how to achieve the same in a [BIML](http:\/\/www.bimlscript.com\/) script. We then moved onto\u00a0how we use some [BIML](http:\/\/www.bimlscript.com\/) features and those C# skills to auto generate a SSIS package,\u00a0then using\u00a0Master Data Services (MDS) as your meta library to, In short, automated staging.\n\n> And the [#BIML](https:\/\/twitter.com\/hashtag\/BIML?src=hash) precon with [@RasmusReinholdt](https:\/\/twitter.com\/RasmusReinholdt) that I'm doing today at [#sqlsatcambridge](https:\/\/twitter.com\/hashtag\/sqlsatcambridge?src=hash) [pic.twitter.com\/GdBSeCUS4i](http:\/\/t.co\/GdBSeCUS4i)\n> \n> \u2014 Zuzana Skrinarova (@zuzskri) [September 11, 2015](https:\/\/twitter.com\/zuzskri\/status\/642255631324479488)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\nMean while in the other session, they were not only failing over servers\u2026\n\n> Just experienced a real life seamless failover during [@regbac](https:\/\/twitter.com\/regbac) [@retracement](https:\/\/twitter.com\/retracement) session on the topic at [#sqlsatcambridge](https:\/\/twitter.com\/hashtag\/sqlsatcambridge?src=hash) [pic.twitter.com\/5fqI5t8DPe](http:\/\/t.co\/5fqI5t8DPe)\n> \n> \u2014 Kenneth M. Nielsen (@DoktorKermit) [September 11, 2015](https:\/\/twitter.com\/DoktorKermit\/status\/642357856965128193)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\n\n## Day 3\n\nThe actual [SQLSaturday event](http:\/\/www.sqlsaturday.com\/411\/eventhome.aspx) was hosted at the very nice\u00a0[The M\u00f8ller Centre](http:\/\/www.mollercentre.co.uk\/), unfortunately this isn\u2019t as close to the train station as the [Cambridge City Hotel](http:\/\/www.cambridgecityhotel.co.uk\/) the precons were hosted at \u2013 still it does have free parking.\n\n> I can think of worse ways to spend a Saturday \ud83d\ude42 [#sqlsatcambridge](https:\/\/twitter.com\/hashtag\/sqlsatcambridge?src=hash) [#spsatcambridge](https:\/\/twitter.com\/hashtag\/spsatcambridge?src=hash) [pic.twitter.com\/ZcEPHUJcZb](http:\/\/t.co\/ZcEPHUJcZb)\n> \n> \u2014 Obilogic (@obilogic) [September 12, 2015](https:\/\/twitter.com\/obilogic\/status\/642664423778291712)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\nThe day was amazing, the people <del>were<\/del> are friendly \u2013 I managed to go up to a few and ask a few questions which they kindly answered. They even had people handing out free chocolates \ud83d\ude42\n\nBeing a free event, you expect the sponsors to be spamming you with marketing material \u2013 it just didn\u2019t happen, they were all playing it cool and waiting for you to come to them. I did pop over to the [Dell Spotlight ](http:\/\/software.dell.com\/products\/spotlight-on-sql-server-enterprise\/)stand who gave me a demo of some of the cool new features in Spotlight \u2013 something we already own but hadn\u2019t had a chance to upgrade \u2013 needless to say I\u2019ve been poking our DBAs to upgrade since I got back in the office. I also stopped by the [Profisee](http:\/\/www.profisee.com\/) stand, after [<u><span style=\"color: #0066cc;\">Rasmus<\/span><\/u>](https:\/\/rasmusreinholdt.wordpress.com\/)\u00a0training I was starting to look more into [Master Data Services](https:\/\/msdn.microsoft.com\/en-us\/library\/ff487003(v=sql.120).aspx) (MDS) and the word on the street was [<u><span style=\"color: #0066cc;\">Profisee<\/span><\/u>](http:\/\/www.profisee.com\/)\u00a0was the MDS experts. Even after registering for their [free online training](http:\/\/profisee.com\/mdsonlinetraining), I haven\u2019t had a single sales call.\n\nThe [sessions ](https:\/\/sqlcambs.files.wordpress.com\/2015\/09\/sps-sqlsaturday-cambridge-2015-schedule.pdf)were good \u2013 there was a nice range this was partly because they had joined up with the SharePoint group. For me personally this was very good as BI sits in the middle. The biggest problem was which one to pick! I managed to pick up a few tips from [<u><span style=\"color: #0066cc;\">Chris Webb<\/span><\/u>](http:\/\/blog.crossjoin.co.uk\/)\u00a0with my data modelling and MDX which was one of my big ones on my to-do list. I enjoyed [Terry McCann ](http:\/\/www.hyperbi.co.uk\/)session on Reporting on Reporting services, its one of those problem we all have \u2013 we have these reports, but are they actually being used? And he explained his journey on how he\u2019s tried to answered that and some of the problems he came across. Its good that he\u2019s shared his experience, its not a particular sexy problem to solve, in fact its a very unsexy, unrewarding, boring chore that all report writers\u00a0must do and at least now I have a good head start.\n\nOverall I think it was a very worthwhile event. I learnt a lot, my work got some very cheap training, I met a lot of very clever people and had fun doing it all. Can\u2019t wait till the next one \ud83d\ude42\n\nYou can see [Rodney Kidd photos on Flickr](https:\/\/www.flickr.com\/photos\/127113040@N04\/sets\/72157658700726789)\n\n[![DSC_0100_DxO](https:\/\/i1.wp.com\/farm1.staticflickr.com\/588\/21105531374_95cd3680ff_z.jpg?resize=640%2C533&ssl=1)](https:\/\/www.flickr.com\/photos\/127113040@n04\/albums\/72157658700726789 \"SQL Sat Cambrdge 2015 by rodjkidd, on Flickr\")<script async=\"\" charset=\"utf-8\" src=\"https:\/\/embedr.flickr.com\/assets\/client-code.js\"><\/script>\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\n","html":"<p><a href=\"http:\/\/www.sqlsaturday.com\/411\/eventhome.aspx\" target=\"_blank\" rel=\"nofollow\"><img class=\"wp-image-451 size-medium alignright\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/COsSZq8WEAAA_qB-300x179.png?fit=300%2C179&#038;ssl=1\" alt=\"\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/COsSZq8WEAAA_qB.png?resize=300%2C179&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/COsSZq8WEAAA_qB.png?resize=321%2C192&amp;ssl=1 321w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/COsSZq8WEAAA_qB.png?w=333&amp;ssl=1 333w\" sizes=\"(max-width: 300px) 100vw, 300px\" data-recalc-dims=\"1\" \/><\/a>For a while now I&#8217;ve been going to the\u00a0<a href=\"http:\/\/sqlcambs.org.uk\/category\/user-group\/\" target=\"_blank\" rel=\"nofollow\">Cambridgeshire SQL Server User Group<\/a>, which I have found really useful especially as we are at moving towards a more self-service model across IT which requires IT to be a bit more cleverer. Beyond the informative speaker talks you get a really good networking opportunity. The group is run by <a href=\"http:\/\/tenbulls.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Mark Broadbent<\/a> (<a href=\"https:\/\/twitter.com\/retracement\" target=\"_blank\" rel=\"nofollow\">@retracement<\/a>) and has recently merged with\u00a0<a href=\"http:\/\/sqlcambs.org.uk\/\" target=\"_blank\" rel=\"nofollow\">SharePoint Saturday Cambridge<\/a>. Although Cambridge is about the same time on the train as London. I find Cambridge a nice place to visit, not just because it doesn&#8217;t involve me going on the underground.<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0234.jpg?ssl=1\"><img class=\"alignnone wp-image-436 size-thumbnail\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0234-150x150.jpg?resize=150%2C150&#038;ssl=1\" alt=\"IMG_0234\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0234.jpg?resize=150%2C150&amp;ssl=1 150w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0234.jpg?resize=330%2C330&amp;ssl=1 330w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0234.jpg?resize=96%2C96&amp;ssl=1 96w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0234.jpg?resize=1230%2C1230&amp;ssl=1 1230w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0234.jpg?zoom=3&amp;resize=150%2C150&amp;ssl=1 450w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-recalc-dims=\"1\" \/><\/a><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0239.jpg?ssl=1\"><img class=\"alignnone wp-image-438 size-thumbnail\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0239-150x150.jpg?resize=150%2C150&#038;ssl=1\" alt=\"IMG_0239\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0239.jpg?resize=150%2C150&amp;ssl=1 150w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0239.jpg?resize=330%2C330&amp;ssl=1 330w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0239.jpg?resize=96%2C96&amp;ssl=1 96w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0239.jpg?resize=1230%2C1230&amp;ssl=1 1230w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0239.jpg?zoom=3&amp;resize=150%2C150&amp;ssl=1 450w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-recalc-dims=\"1\" \/><\/a><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428.jpg?ssl=1\"><img class=\"alignnone wp-image-435 size-thumbnail\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0233-150x150.jpg?resize=150%2C150&#038;ssl=1\" alt=\"IMG_0233\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0233.jpg?resize=150%2C150&amp;ssl=1 150w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0233.jpg?resize=330%2C330&amp;ssl=1 330w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0233.jpg?resize=96%2C96&amp;ssl=1 96w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0233.jpg?resize=1230%2C1230&amp;ssl=1 1230w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0233.jpg?zoom=3&amp;resize=150%2C150&amp;ssl=1 450w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428.jpg?ssl=1\"><img class=\"alignnone wp-image-434 size-thumbnail\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428-150x150.jpg?resize=150%2C150&#038;ssl=1\" alt=\"IMG_0232\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428.jpg?resize=150%2C150&amp;ssl=1 150w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428.jpg?resize=330%2C330&amp;ssl=1 330w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428.jpg?resize=96%2C96&amp;ssl=1 96w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428.jpg?resize=1230%2C1230&amp;ssl=1 1230w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0232-e1442175835428.jpg?zoom=3&amp;resize=150%2C150&amp;ssl=1 450w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-recalc-dims=\"1\" \/><\/a><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0237-e1442175813106.jpg?ssl=1\"><img class=\"alignnone wp-image-437 size-thumbnail\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0237-e1442175813106-150x150.jpg?resize=150%2C150&#038;ssl=1\" alt=\"IMG_0237\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0237-e1442175813106.jpg?resize=150%2C150&amp;ssl=1 150w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0237-e1442175813106.jpg?resize=330%2C330&amp;ssl=1 330w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0237-e1442175813106.jpg?resize=96%2C96&amp;ssl=1 96w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0237-e1442175813106.jpg?resize=1230%2C1230&amp;ssl=1 1230w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0237-e1442175813106.jpg?zoom=3&amp;resize=150%2C150&amp;ssl=1 450w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>Some how Mark has managed to put together an entire day <a href=\"http:\/\/www.sqlsaturday.com\/411\/eventhome.aspx\" target=\"_blank\" rel=\"nofollow\">SQL Saturday event<\/a> with <a href=\"http:\/\/sqlcambs.org.uk\/preconall\/\" target=\"_blank\" rel=\"nofollow\">two precon days<\/a> &#8211; I swear this guy has gotten hold of <a href=\"https:\/\/www.youtube.com\/watch?v=T3-LZx8NF8k\" target=\"_blank\" rel=\"nofollow\">Mary Poppins bag<\/a>. Don&#8217;t let the precon name fool you, these are (well were) two full days of very good training. After all, its not every day you get a full-days training with a\u00a0<b>Microsoft Most Valuable Professional<\/b> (<b>MVP<\/b>) or the Data Warehouse Architect at <a href=\"https:\/\/www.unops.org\/english\/Pages\/Home.aspx\" target=\"_blank\" rel=\"nofollow\">UNOPS<\/a>, the implementation arm of the UN!<\/p>\n<p>One of the downsides of attending was having to get up a 5 am \ud83d\ude41<\/p>\n<p>Note to self: Next time, stay in a hotel &#8211; yes <a href=\"https:\/\/twitter.com\/retracement\" target=\"_blank\" rel=\"nofollow\">Mark<\/a>, I should have read your <a href=\"http:\/\/sqlcambs.org.uk\/sqlsaturday-information-travel\/\" target=\"_blank\" rel=\"nofollow\">deals on hotels<\/a> (and looked at the back of the guide book for the map)<br \/>\n<a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0221.jpg?ssl=1\"><img class=\"alignnone wp-image-442 size-thumbnail\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0221-150x150.jpg?resize=150%2C150&#038;ssl=1\" alt=\"IMG_0221\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0221.jpg?resize=150%2C150&amp;ssl=1 150w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0221.jpg?resize=330%2C330&amp;ssl=1 330w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0221.jpg?resize=96%2C96&amp;ssl=1 96w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0221.jpg?resize=1230%2C1230&amp;ssl=1 1230w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0221.jpg?zoom=3&amp;resize=150%2C150&amp;ssl=1 450w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-recalc-dims=\"1\" \/><\/a><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0210-e1442175792339.jpg?ssl=1\"><img class=\"alignnone wp-image-441 size-thumbnail\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0210-e1442175792339-150x150.jpg?resize=150%2C150&#038;ssl=1\" alt=\"IMG_0210\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0210-e1442175792339.jpg?resize=150%2C150&amp;ssl=1 150w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0210-e1442175792339.jpg?resize=330%2C330&amp;ssl=1 330w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0210-e1442175792339.jpg?resize=96%2C96&amp;ssl=1 96w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0210-e1442175792339.jpg?resize=1230%2C1230&amp;ssl=1 1230w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0210-e1442175792339.jpg?zoom=3&amp;resize=150%2C150&amp;ssl=1 450w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-recalc-dims=\"1\" \/><\/a><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0230.jpg?ssl=1\"><img class=\"alignnone wp-image-433 size-thumbnail\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0230-150x150.jpg?resize=150%2C150&#038;ssl=1\" alt=\"IMG_0230\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0230.jpg?resize=150%2C150&amp;ssl=1 150w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0230.jpg?resize=330%2C330&amp;ssl=1 330w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0230.jpg?resize=96%2C96&amp;ssl=1 96w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0230.jpg?resize=1230%2C1230&amp;ssl=1 1230w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0230.jpg?zoom=3&amp;resize=150%2C150&amp;ssl=1 450w\" sizes=\"(max-width: 150px) 100vw, 150px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<h2>Day 1<\/h2>\n<h2><img class=\"size-medium wp-image-432 alignright\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0227-300x225.jpg?fit=300%2C225&#038;ssl=1\" alt=\"IMG_0227\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0227.jpg?resize=300%2C225&amp;ssl=1 300w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0227.jpg?resize=1024%2C768&amp;ssl=1 1024w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0227.jpg?resize=648%2C486&amp;ssl=1 648w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0227.jpg?resize=256%2C192&amp;ssl=1 256w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0227.jpg?w=1400&amp;ssl=1 1400w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/09\/IMG_0227.jpg?w=2100&amp;ssl=1 2100w\" sizes=\"(max-width: 300px) 100vw, 300px\" data-recalc-dims=\"1\" \/><\/h2>\n<p>My first day was with <a href=\"http:\/\/www.sharepointdesignerstepbystep.com\/Blog\/default.aspx\" target=\"_blank\" rel=\"nofollow\">Penny\u00a0Coventry<\/a>\u00a0&#8211; <a href=\"http:\/\/web.archive.org\/web\/20160209211202\/http:\/\/sqlcambs.org.uk\/precon1\/\" target=\"_blank\" rel=\"nofollow\">Automating business processes with SharePoint, Office 365 and Azure<\/a>. This was a really good session where I got to see some of the power of <a href=\"https:\/\/products.office.com\/en-gb\/sharepoint\/collaboration\" target=\"_blank\" rel=\"nofollow\">SharePoint<\/a> and cool new\u00a0<a href=\"http:\/\/azure.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Azure <\/a>features\u00a0from the power\u00a0users perspective rather then the overly technical developer perspective. I&#8217;ve often found users will shrug off ideas and solutions when explained by a &#8220;techy&#8221; as being too &#8220;technical&#8221; &#8211; and to be fair to them, we do get a big excited and go over the config line and into the development world all too often.<\/p>\n<p>The out-of-the-box just config, no development features in <a href=\"https:\/\/products.office.com\/en-gb\/sharepoint\/collaboration\" target=\"_blank\" rel=\"nofollow\">SharePoint <\/a>like Workflows are amazing. From a &#8220;techy&#8221; point of view, I&#8217;m amazed at how easy it is to do something that would be quite complex to create as a bespoke app. It was also good to see how Microsoft are expanding into the cloud, both with <a href=\"https:\/\/products.office.com\/en-gb\/business\/explore-office-365-for-business\" target=\"_blank\" rel=\"nofollow\">Office 365<\/a> and <a href=\"http:\/\/azure.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Azure<\/a>. I&#8217;ve previously only really looked into <a href=\"http:\/\/azure.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Azure <\/a>from the &#8220;techy&#8221; side, like <a href=\"http:\/\/www.troyhunt.com\/2015\/08\/how-did-have-i-been-pwned-perform-on.html\" target=\"_blank\" rel=\"nofollow\">Troy Hunt&#8217;s \u201cHave I been pwned?\u201d<\/a> site but I hadn&#8217;t had a chance to have a look at things like\u00a0<a href=\"http:\/\/azure.microsoft.com\/en-gb\/services\/app-service\/logic\" target=\"_blank\" rel=\"nofollow\">Logic App<\/a>. Logic App\u00a0which looks like its another workflow type services where you can drag and drop connections (kinda like SSIS) and do things like pulling tweets from <a href=\"http:\/\/www.twitter.com\/\" target=\"_blank\" rel=\"nofollow\">Twitter <\/a>into a SharePoint list, or a MS-SQL database or whatever. Again, this is the sort of thing power users can do without IT or a developers. For me this is great news, creating custom connectors in SSIS is a pain, if the power users can get data into a MS-SQL database without me developing anything, great. Makes my like a lot simpler. Combine this with some of the SharePoint features, like Access Web Apps, I can give users access to the static data so they can keep it up-to-date without the manual process without fear of them wrecking it thanks to some (hopefully) clever business logic.<\/p>\n<p>One last comment about the session, Penny completed the entire thing, including the live demos, using her Office 365\\Azure subscription. I was amazed at this as normally I find Office 365\\Azure professionals always have a &#8220;but&#8221; when it comes to them being fully cloud, they always spin up a virtual machine or such. Despite being fully cloud, she knew all the little &#8220;this isn&#8217;t on the on-prem version &#8211; yet&#8221; or &#8220;you can&#8217;t do that in the cloud&#8221; or &#8220;if you don&#8217;t see that option on on-prem you need to..&#8221;, as well as latest low down on SharePoint 2016.<\/p>\n<p>Other session going on was\u00a0<a href=\"http:\/\/web.archive.org\/web\/20160210045257\/http:\/\/sqlcambs.org.uk\/precon3\/\" target=\"_blank\" rel=\"nofollow\">A Day with Columnstore Indexes<\/a> with\u00a0<a href=\"http:\/\/www.nikoport.com\/\" target=\"_blank\" rel=\"nofollow\">Niko Neugebauer<\/a>. To be honest, I wimped out of going to this one &#8211; I tend to leave the intimate details of indexes to our Senior DBA and just pick up the summary sheet at end and apply the base config and only update it when he says so. Lazy I know, but I can&#8217;t learn everything at once!<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">Becoming a <a href=\"https:\/\/twitter.com\/hashtag\/columnstore?src=hash\" target=\"_blank\" rel=\"nofollow\">#columnstore<\/a> professional in <a href=\"https:\/\/twitter.com\/NikoNeugebauer\" target=\"_blank\" rel=\"nofollow\">@NikoNeugebauer<\/a> precon at <a href=\"https:\/\/twitter.com\/sqlsatcambs\" target=\"_blank\" rel=\"nofollow\">@sqlsatcambs<\/a> <a href=\"http:\/\/t.co\/HWlPXf8HRN\" target=\"_blank\" rel=\"nofollow\">pic.twitter.com\/HWlPXf8HRN<\/a><\/p>\n<p>&mdash; Zuzana Skrinarova (@zuzskri) <a href=\"https:\/\/twitter.com\/zuzskri\/status\/641921587889983488\" target=\"_blank\" rel=\"nofollow\">September 10, 2015<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<h2>Day 2<\/h2>\n<p>The second day was with\u00a0<a href=\"https:\/\/rasmusreinholdt.wordpress.com\/\" target=\"_blank\" rel=\"nofollow\">Rasmus Reinholdt Nielsen<\/a> &#8211;\u00a0<a href=\"http:\/\/web.archive.org\/web\/20160210074148\/http:\/\/sqlcambs.org.uk\/precon4\/\" target=\"_blank\" rel=\"nofollow\">Building tomorrows ETL architecture with BIML and MDS today<\/a>\u00a0and was the main reason for me attending, I spend most of my time in SSIS. Despite packing two laptops, I still found myself popping\u00a0out to the shops to pick up a USB mouse as I forgot to pack one. I&#8217;ve previously heard about <a href=\"http:\/\/www.bimlscript.com\/\" target=\"_blank\" rel=\"nofollow\">BIML<\/a> and despite being recommended from a lot of folks I just hadn&#8217;t had a proper look, the main reason was the resentment towards Microsoft for not providing such a intermediate language &#8211; not that <a href=\"http:\/\/www.varigence.com\" target=\"_blank\" rel=\"nofollow\">Scott Currie<\/a> hasn&#8217;t done amazing job, its just it should be merged into core product. Rasmus started with a introduction to C# which covered the basics, which he quickly skipped through as we all ready had a working knowledge of C# and got onto <a href=\"http:\/\/www.bimlscript.com\/\" target=\"_blank\" rel=\"nofollow\">BIML<\/a>.\u00a0Before too long\u00a0I had created my <a href=\"https:\/\/gist.github.com\/matt40k\/bb849ecb85ba7af13fe3\" target=\"_blank\" rel=\"nofollow\">first basic BIML script<\/a>. He then went onto some of the more complex features of SSIS and then how to achieve the same in a <a href=\"http:\/\/www.bimlscript.com\/\" target=\"_blank\" rel=\"nofollow\">BIML<\/a> script. We then moved onto\u00a0how we use some <a href=\"http:\/\/www.bimlscript.com\/\" target=\"_blank\" rel=\"nofollow\">BIML<\/a> features and those C# skills to auto generate a SSIS package,\u00a0then using\u00a0Master Data Services (MDS) as your meta library to, In short, automated staging.<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">And the <a href=\"https:\/\/twitter.com\/hashtag\/BIML?src=hash\" target=\"_blank\" rel=\"nofollow\">#BIML<\/a> precon with <a href=\"https:\/\/twitter.com\/RasmusReinholdt\" target=\"_blank\" rel=\"nofollow\">@RasmusReinholdt<\/a> that I&#39;m doing today at <a href=\"https:\/\/twitter.com\/hashtag\/sqlsatcambridge?src=hash\" target=\"_blank\" rel=\"nofollow\">#sqlsatcambridge<\/a> <a href=\"http:\/\/t.co\/GdBSeCUS4i\" target=\"_blank\" rel=\"nofollow\">pic.twitter.com\/GdBSeCUS4i<\/a><\/p>\n<p>&mdash; Zuzana Skrinarova (@zuzskri) <a href=\"https:\/\/twitter.com\/zuzskri\/status\/642255631324479488\" target=\"_blank\" rel=\"nofollow\">September 11, 2015<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>Mean while in the other session, they were not only failing over servers&#8230;<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">Just experienced a real life seamless failover during <a href=\"https:\/\/twitter.com\/regbac\" target=\"_blank\" rel=\"nofollow\">@regbac<\/a> <a href=\"https:\/\/twitter.com\/retracement\" target=\"_blank\" rel=\"nofollow\">@retracement<\/a> session on the topic at <a href=\"https:\/\/twitter.com\/hashtag\/sqlsatcambridge?src=hash\" target=\"_blank\" rel=\"nofollow\">#sqlsatcambridge<\/a> <a href=\"http:\/\/t.co\/5fqI5t8DPe\" target=\"_blank\" rel=\"nofollow\">pic.twitter.com\/5fqI5t8DPe<\/a><\/p>\n<p>&mdash; Kenneth M. Nielsen (@DoktorKermit) <a href=\"https:\/\/twitter.com\/DoktorKermit\/status\/642357856965128193\" target=\"_blank\" rel=\"nofollow\">September 11, 2015<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<h2>Day 3<\/h2>\n<p>The actual <a href=\"http:\/\/www.sqlsaturday.com\/411\/eventhome.aspx\" target=\"_blank\" rel=\"nofollow\">SQLSaturday event<\/a> was hosted at the very nice\u00a0<a href=\"http:\/\/www.mollercentre.co.uk\/\" target=\"_blank\" rel=\"nofollow\">The M\u00f8ller Centre<\/a>, unfortunately this isn&#8217;t as close to the train station as the <a href=\"http:\/\/www.cambridgecityhotel.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Cambridge City Hotel<\/a> the precons were hosted at &#8211; still it does have free parking.<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">I can think of worse ways to spend a Saturday \ud83d\ude42 <a href=\"https:\/\/twitter.com\/hashtag\/sqlsatcambridge?src=hash\" target=\"_blank\" rel=\"nofollow\">#sqlsatcambridge<\/a> <a href=\"https:\/\/twitter.com\/hashtag\/spsatcambridge?src=hash\" target=\"_blank\" rel=\"nofollow\">#spsatcambridge<\/a> <a href=\"http:\/\/t.co\/ZcEPHUJcZb\" target=\"_blank\" rel=\"nofollow\">pic.twitter.com\/ZcEPHUJcZb<\/a><\/p>\n<p>&mdash; Obilogic (@obilogic) <a href=\"https:\/\/twitter.com\/obilogic\/status\/642664423778291712\" target=\"_blank\" rel=\"nofollow\">September 12, 2015<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>The day was amazing, the people <del>were<\/del> are friendly &#8211; I managed to go up to a few and ask a few questions which they kindly answered. They even had people handing out free chocolates \ud83d\ude42<\/p>\n<p>Being a free event, you expect the sponsors to be spamming you with marketing material &#8211; it just didn&#8217;t happen, they were all playing it cool and waiting for you to come to them. I did pop over to the <a href=\"http:\/\/software.dell.com\/products\/spotlight-on-sql-server-enterprise\/\" target=\"_blank\" rel=\"nofollow\">Dell Spotlight <\/a>stand who gave me a demo of some of the cool new features in Spotlight &#8211; something we already own but hadn&#8217;t had a chance to upgrade &#8211; needless to say I&#8217;ve been poking our DBAs to upgrade since I got back in the office. I also stopped by the <a href=\"http:\/\/www.profisee.com\/\" target=\"_blank\" rel=\"nofollow\">Profisee<\/a> stand, after <a href=\"https:\/\/rasmusreinholdt.wordpress.com\/\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Rasmus<\/span><\/u><\/a>\u00a0training I was starting to look more into <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/ff487003(v=sql.120).aspx\" target=\"_blank\" rel=\"nofollow\">Master Data Services<\/a> (MDS) and the word on the street was <a href=\"http:\/\/www.profisee.com\/\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Profisee<\/span><\/u><\/a>\u00a0was the MDS experts. Even after registering for their <a href=\"http:\/\/profisee.com\/mdsonlinetraining\" target=\"_blank\" rel=\"nofollow\">free online training<\/a>, I haven&#8217;t had a single sales call.<\/p>\n<p>The <a href=\"https:\/\/sqlcambs.files.wordpress.com\/2015\/09\/sps-sqlsaturday-cambridge-2015-schedule.pdf\" target=\"_blank\" rel=\"nofollow\">sessions <\/a>were good &#8211; there was a nice range this was partly because they had joined up with the SharePoint group. For me personally this was very good as BI sits in the middle. The biggest problem was which one to pick! I managed to pick up a few tips from <a href=\"http:\/\/blog.crossjoin.co.uk\/\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Chris Webb<\/span><\/u><\/a>\u00a0with my data modelling and MDX which was one of my big ones on my to-do list. I enjoyed <a href=\"http:\/\/www.hyperbi.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Terry McCann <\/a>session on Reporting on Reporting services, its one of those problem we all have &#8211; we have these reports, but are they actually being used? And he explained his journey on how he&#8217;s tried to answered that and some of the problems he came across. Its good that he&#8217;s shared his experience, its not a particular sexy problem to solve, in fact its a very unsexy, unrewarding, boring chore that all report writers\u00a0must do and at least now I have a good head start.<\/p>\n<p>Overall I think it was a very worthwhile event. I learnt a lot, my work got some very cheap training, I met a lot of very clever people and had fun doing it all. Can&#8217;t wait till the next one \ud83d\ude42<\/p>\n<p>You can see <a href=\"https:\/\/www.flickr.com\/photos\/127113040@N04\/sets\/72157658700726789\" target=\"_blank\" rel=\"nofollow\">Rodney Kidd photos on Flickr<\/a><\/p>\n<p><a data-flickr-embed=\"true\" href=\"https:\/\/www.flickr.com\/photos\/127113040@n04\/albums\/72157658700726789\" title=\"SQL Sat Cambrdge 2015 by rodjkidd, on Flickr\" target=\"_blank\" rel=\"nofollow\"><img src=\"https:\/\/i1.wp.com\/farm1.staticflickr.com\/588\/21105531374_95cd3680ff_z.jpg?resize=640%2C533&#038;ssl=1\" alt=\"DSC_0100_DxO\" data-recalc-dims=\"1\"><\/a><script async src=\"https:\/\/embedr.flickr.com\/assets\/client-code.js\" charset=\"utf-8\"><\/script><\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 28 Sep 2015 13:51:11 +0000","created_by":1,"updated_at":"Sun, 16 Oct 2016 22:51:38 +0000","updated_by":1,"published_at":"Mon, 28 Sep 2015 13:51:11 +0000","published_by":1},{"id":478,"title":"Joys of C#","slug":"joys-of-c","markdown":"\nOn Friday, I had a problem raised, they want to change one of the automatic rename jobs which renames and moves export files to a shared drive. Lucky, I had created a SSIS package, which was a SQL Job that\u00a0runs on a scheduled every 15 mins, which\u00a0uses a script task to perform the logic. Because we also used [OctopusDeploy](http:\/\/www.octopusdeploy.com\/), this really was going to be a 5 min change.\n\nThe summary of the requirement change was this, currently we export files to:\n\n`\\Client Name\\Month Number-Month Name\\`\n\nso, for example, for the April export for Client A it would be:\n\n`\\Client A\\04-April\\`\n\nWhat they wanted to change it was:\n\n<span style=\"font-family: Courier New;\">\\Client Name\\Fiscal Month Number-Month Name\\<\/span>\n\nso, for example, for the April export for Client A would become:\n\n<span style=\"font-family: Courier New;\">\\Client A\\01-April\\<\/span>\n\nAgain, as this was a script task, it was just a question of adding a new method and adding it in. For reference, here is the method I quickly bosh together:\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/df77c8fb8b3a2c79c4c8.json\"><\/div>Thanks to some clever upfront work \u2013 with both the script task and [OctopusDeploy](http:\/\/www.OctopusDeploy.com), this change took 5 mins.\n\n\n","html":"<p>On Friday, I had a problem raised, they want to change one of the automatic rename jobs which renames and moves export files to a shared drive. Lucky, I had created a SSIS package, which was a SQL Job that\u00a0runs on a scheduled every 15 mins, which\u00a0uses a script task to perform the logic. Because we also used <a href=\"http:\/\/www.octopusdeploy.com\/\" target=\"_blank\" rel=\"nofollow\">OctopusDeploy<\/a>, this really was going to be a 5 min change.<\/p>\n<p>The summary of the requirement change was this, currently we export files to:<\/p>\n<p><code>\\Client Name\\Month Number-Month Name\\<\/code><\/p>\n<p>so, for example, for the April export for Client A it would be:<\/p>\n<p><code>\\Client A\\04-April\\<\/code><\/p>\n<p>What they wanted to change it was:<\/p>\n<p><span style=\"font-family: Courier New;\">\\Client Name\\Fiscal Month Number-Month Name\\<\/span><\/p>\n<p>so, for example, for the April export for Client A would become:<\/p>\n<p><span style=\"font-family: Courier New;\">\\Client A\\01-April\\<\/span><\/p>\n<p>Again, as this was a script task, it was just a question of adding a new method and adding it in. For reference, here is the method I quickly bosh together:<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/df77c8fb8b3a2c79c4c8.json\"><\/div>\n<p>Thanks to some clever upfront work &#8211; with both the script task and <a href=\"http:\/\/www.OctopusDeploy.com\" target=\"_blank\" rel=\"nofollow\">OctopusDeploy<\/a>, this change took 5 mins.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 10 Oct 2015 21:29:36 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:14:02 +0000","updated_by":1,"published_at":"Sat, 10 Oct 2015 21:29:36 +0000","published_by":1},{"id":487,"title":"Problem with ISNUMERIC","slug":"problem-with-isnumeric","markdown":"\nTodays problem was brought to you by a highly customizable system with poor user validation and a user who doesn\u2019t know the difference between data and formatting. First the system. The supplier has created a highly user customizable system, they can for example create a web form with zero coding \u2013 100% user config.\u00a0The problem is, technically, it creates a mess. So\u00a0your nice new\u00a0form with a number of questions stores all its answers in a single table with the data going into a nvarchar(max) column \u2013 which is fine for free-text columns, but not so good for integer fields. This is especially a problem when you have a form that has drop-down options\u00a0(luckily stored in a different table more efficiently) which generates an amount which the end user can overtype in order to moderate it up or down, which has zero validation.\n\nThe data is \u201cstored\u201d as numeric in the database so, for example,\u00a01200.34, but is formatted as currency \u2013 so \u00a31,200.34. The problem occurs when the user overtypes the amount, when they do, they overtype it, say as, 1201.34, but they don\u2019t enter 1201.34. They enter \u00a31201.34. Now this is a problem as when I load the data into the Data Mart, I store the data as a numeric(18,2), which means I need to cast it. This will of course fail if the user has overtyped it as it isn\u2019t a numeric \u2013 which has historically happened. The way I resolved it was to strip out the \u00a3 sign using a replace then to add a ISNUMERIC statement as a fail safe.\n\nHowever despite my failsafe it failed today \u2013 the problem was with ISNUMERIC \u2013 if you read the man, it says [\u201cISNUMERIC returns 1 for some characters that are not numbers, such as plus (+), minus (-), and valid currency symbols such as the dollar sign ($)\u201d](https:\/\/msdn.microsoft.com\/en-us\/library\/ms186272.aspx). What it doesn\u2019t tell you is it also covers commas \u2013 so:  \n`select cast(replace('\u00a31,220', '\u00a3', '') as int)`  \n will fail with  \n`Conversion failed when converting the varchar value '1,220' to data type int.`  \n this is despite ISNUMERIC returning 1 (ie valid)  \n`select ISNUMERIC('1,220')`\n\nThe fix is to replace (well remove) commas as well as the pound sign (\u00a3). Going forward, in SQL2012 Microsoft has introduced [Try_Cast](https:\/\/msdn.microsoft.com\/en-us\/library\/hh974669.aspx)\u00a0which might be another option.\n\n\n","html":"<p>Todays problem was brought to you by a highly customizable system with poor user validation and a user who doesn&#8217;t know the difference between data and formatting. First the system. The supplier has created a highly user customizable system, they can for example create a web form with zero coding &#8211; 100% user config.\u00a0The problem is, technically, it creates a mess. So\u00a0your nice new\u00a0form with a number of questions stores all its answers in a single table with the data going into a nvarchar(max) column &#8211; which is fine for free-text columns, but not so good for integer fields. This is especially a problem when you have a form that has drop-down options\u00a0(luckily stored in a different table more efficiently) which generates an amount which the end user can overtype in order to moderate it up or down, which has zero validation.<\/p>\n<p>The data is &#8220;stored&#8221; as numeric in the database so, for example,\u00a01200.34, but is formatted as currency &#8211; so \u00a31,200.34. The problem occurs when the user overtypes the amount, when they do, they overtype it, say as, 1201.34, but they don&#8217;t enter 1201.34. They enter \u00a31201.34. Now this is a problem as when I load the data into the Data Mart, I store the data as a numeric(18,2), which means I need to cast it. This will of course fail if the user has overtyped it as it isn&#8217;t a numeric &#8211; which has historically happened. The way I resolved it was to strip out the \u00a3 sign using a replace then to add a ISNUMERIC statement as a fail safe.<\/p>\n<p>However despite my failsafe it failed today &#8211; the problem was with ISNUMERIC &#8211; if you read the man, it says <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/ms186272.aspx\" target=\"_blank\" rel=\"nofollow\">&#8220;ISNUMERIC returns 1 for some characters that are not numbers, such as plus (+), minus (-), and valid currency symbols such as the dollar sign ($)&#8221;<\/a>. What it doesn&#8217;t tell you is it also covers commas &#8211; so:<br \/>\n<code>select cast(replace('\u00a31,220', '\u00a3', '') as int)<\/code><br \/>\nwill fail with<br \/>\n<code>Conversion failed when converting the varchar value '1,220' to data type int.<\/code><br \/>\nthis is despite ISNUMERIC returning 1 (ie valid)<br \/>\n<code>select ISNUMERIC('1,220')<\/code><\/p>\n<p>The fix is to replace (well remove) commas as well as the pound sign (\u00a3). Going forward, in SQL2012 Microsoft has introduced <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/hh974669.aspx\" target=\"_blank\" rel=\"nofollow\">Try_Cast<\/a>\u00a0which might be another option.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 27 Oct 2015 21:29:07 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:13:22 +0000","updated_by":1,"published_at":"Tue, 27 Oct 2015 21:29:07 +0000","published_by":1},{"id":490,"title":"Deploying SQL 2014, looking at SQL 2016 \\ PowerBI","slug":"deploying-sql-2014-looking-at-sql-2016-powerbi","markdown":"\nMy current thoughts on SQL2016\/PowerBI as deploying SQL2014.\n\nOk, so we\u2019re looking at moving to pure SQL 2014 for our corporate BI solution. I say\u00a0pure as we normally use\u00a0SQL server as the backend then other tools\u00a0on top, so we\u2019re looking at enabling a lot of extra features we\u2019ve technically\u00a0had for years but just not enabled\\setup\\whatever.\u00a0SQL2016 is on the way and we\u2019re most likely going to upgrade pretty quick, lots of new features that look very useful. Power BI is out, but\u2026 we\u2019re holding back, again we\u2019re going to use it, its just a question of when it becomes the main BI tool.\n\nSo, we\u2019ve already got the bulk of the data modelled in a multi-dimensional (MD) format, we just need to built a SSAS MD cube, the little pockets of data will be tabular cubes \u2013 users will use Excel for interacting with the data as well as end user reports \u2013 SharePoint will be the \u201cportal\u201d \u2013 much better then file system. SSRS will be for static reports \u2013 such as transactional reports that need to be static.\n\nGoing forward, it looks like PowerBI will replace the bulk of the Excel\\SharePoint work \u2013 this will give a superior end-user interaction with the data, not only will it allow natural language interrogation of the data, but also personalised views \u2013 so you\u2019ll see your data off the bat, you won\u2019t have to drill down from your company, then team to get to your data. Data will come off the same ssas cube, so it\u2019s still a single point for the data, its just a new way to interact with the data.\n\nIn terms of data security, we can limit PowerBI to just the summary data \u2013 via the ssas cube \u2013 so the fact PowerBI is hosted outside of the UK shouldn\u2019t be a problem. The detailed stuff will still be on-prem \u2013 so SharePoint would still be needed in terms of a repository, but the bulk of the users will be using PowerBI, so its not as key, again, the data will come off the same ssas cube so we won\u2019t have the \u201cPowerBI says this but Excel says this\u201d (insert caveat about people looking at different things \u2013 nb: need to check if can add url drill-down in PowerBI to say SSRS report with the detail).\n\nThe other bonus of the PowerBI is the friendly-ness towards the micro data sources \u2013 like the odd Excel spreadsheet. In terms of SQL2014, I was thinking about pushing towards Access Online \u2013 which backends the data into an Azure DB, still this will ultimately depend on policy on the data then the technology. Key is, we\u2019ve got options.\n\nIn terms of end-user delivery SQL2014 will be perceived as SharePoint, really it will be Excel. The SharePoint is nothing more than a gloried online file share, we could in theory use OneDrive \u2013 at least until dashboards are more common but that won\u2019t occur until the data is more readily accessible. The real power behind Excel will be using it correctly \u2013 using Excel as a visualisation tool to interact with the data and letting the SQL Server back end deal with grunt work \u2013 both in terms of the database and analysis services \u2013 rather then getting Excel to do all the grunt work and wonder why it so pants at it. The \u201cSQL2016\u201d\/PowerBI rollout should be easier to land with end-users as there is a new thing being delivered, it\u2019s easier to grasp a new product rather than an enabling some (new) features on an old tool. The key for delivering SQL2014 will be the SharePoint being the main place to go, it could become PowerBI. Plus side it means the SharePoint delivery is less critical as it could be replace if it doesn\u2019t work out, if it does, lets hope this feature request goes head \u2013 [https:\/\/support.powerbi.com\/forums\/265200-power-bi\/suggestions\/6740156-embed-in-sharepoint-office365](https:\/\/support.powerbi.com\/forums\/265200-power-bi\/suggestions\/6740156-embed-in-sharepoint-office365). Does mean I have to have a look at branding and friendly urls for PowerBI.\n\nFor public data publication, in terms of \u201cSQL2014\u201d, I am thinking Excel to get the data, then saving as a CSV (or passing onto IT to produce a standard extract, again as CSV) \u2013 opening this in notepad or such to validate it contains no unwanted (such as protected fields) data, then publishing (onto public website\\github??)\u00a0\u2013 then using Tableau Public to produce graphs for public consumption \u2013 Tableau also allows easy export data (as csv). For PowerBI \u2013 I would hope you could use PowerBI to interact with the data, then export as a csv \u2013 verify it (perhaps in a basic online viewer \u2013 similar to the way github displays csv tables), then publish it \u2013 ideally on a marketplace type thing so it\u2019s easy for others to find \u2013 again as a CSV and ideally with a [Tabular Data Package](https:\/\/github.com\/matt40k\/TabularDataPackageBuilder) definition file, then allow embedding of a simple interaction of the data on a public website for no cost. So PowerBI license to produce, no license to see \\ basic interaction of data (I guess csv file, json definition file, and d3.js) \u2013 then a PowerBI license to bring the data into own PowerBI to join with own data.\n\n\n","html":"<p>My current thoughts on SQL2016\/PowerBI as deploying SQL2014.<\/p>\n<p>Ok, so we\u2019re looking at moving to pure SQL 2014 for our corporate BI solution. I say\u00a0pure as we normally use\u00a0SQL server as the backend then other tools\u00a0on top, so we&#8217;re looking at enabling a lot of extra features we&#8217;ve technically\u00a0had for years but just not enabled\\setup\\whatever.\u00a0SQL2016 is on the way and we\u2019re most likely going to upgrade pretty quick, lots of new features that look very useful. Power BI is out, but\u2026 we\u2019re holding back, again we\u2019re going to use it, its just a question of when it becomes the main BI tool.<\/p>\n<p>So, we\u2019ve already got the bulk of the data modelled in a multi-dimensional (MD) format, we just need to built a SSAS MD cube, the little pockets of data will be tabular cubes \u2013 users will use Excel for interacting with the data as well as end user reports \u2013 SharePoint will be the \u201cportal\u201d \u2013 much better then file system. SSRS will be for static reports \u2013 such as transactional reports that need to be static.<\/p>\n<p>Going forward, it looks like PowerBI will replace the bulk of the Excel\\SharePoint work \u2013 this will give a superior end-user interaction with the data, not only will it allow natural language interrogation of the data, but also personalised views \u2013 so you\u2019ll see your data off the bat, you won\u2019t have to drill down from your company, then team to get to your data. Data will come off the same ssas cube, so it\u2019s still a single point for the data, its just a new way to interact with the data.<\/p>\n<p>In terms of data security, we can limit PowerBI to just the summary data \u2013 via the ssas cube \u2013 so the fact PowerBI is hosted outside of the UK shouldn\u2019t be a problem. The detailed stuff will still be on-prem \u2013 so SharePoint would still be needed in terms of a repository, but the bulk of the users will be using PowerBI, so its not as key, again, the data will come off the same ssas cube so we won\u2019t have the \u201cPowerBI says this but Excel says this\u201d (insert caveat about people looking at different things &#8211; nb: need to check if can add url drill-down in PowerBI to say SSRS report with the detail).<\/p>\n<p>The other bonus of the PowerBI is the friendly-ness towards the micro data sources \u2013 like the odd Excel spreadsheet. In terms of SQL2014, I was thinking about pushing towards Access Online \u2013 which backends the data into an Azure DB, still this will ultimately depend on policy on the data then the technology. Key is, we&#8217;ve got options.<\/p>\n<p>In terms of end-user delivery SQL2014 will be perceived as SharePoint, really it will be Excel. The SharePoint is nothing more than a gloried online file share, we could in theory use OneDrive \u2013 at least until dashboards are more common but that won\u2019t occur until the data is more readily accessible. The real power behind Excel will be using it correctly \u2013 using Excel as a visualisation tool to interact with the data and letting the SQL Server back end deal with grunt work \u2013 both in terms of the database and analysis services &#8211; rather then getting Excel to do all the grunt work and wonder why it so pants at it. The \u201cSQL2016\u201d\/PowerBI rollout should be easier to land with end-users as there is a new thing being delivered, it\u2019s easier to grasp a new product rather than an enabling some (new) features on an old tool. The key for delivering SQL2014 will be the SharePoint being the main place to go, it could become PowerBI. Plus side it means the SharePoint delivery is less critical as it could be replace if it doesn&#8217;t work out, if it does, lets hope this feature request goes head &#8211; <a href=\"https:\/\/support.powerbi.com\/forums\/265200-power-bi\/suggestions\/6740156-embed-in-sharepoint-office365\" target=\"_blank\" rel=\"nofollow\">https:\/\/support.powerbi.com\/forums\/265200-power-bi\/suggestions\/6740156-embed-in-sharepoint-office365<\/a>. Does mean I have to have a look at branding and friendly urls for PowerBI.<\/p>\n<p>For public data publication, in terms of \u201cSQL2014\u201d, I am thinking Excel to get the data, then saving as a CSV (or passing onto IT to produce a standard extract, again as CSV) \u2013 opening this in notepad or such to validate it contains no unwanted (such as protected fields) data, then publishing (onto public website\\github??)\u00a0\u2013 then using Tableau Public to produce graphs for public consumption \u2013 Tableau also allows easy export data (as csv). For PowerBI \u2013 I would hope you could use PowerBI to interact with the data, then export as a csv \u2013 verify it (perhaps in a basic online viewer \u2013 similar to the way github displays csv tables), then publish it \u2013 ideally on a marketplace type thing so it\u2019s easy for others to find \u2013 again as a CSV and ideally with a <a href=\"https:\/\/github.com\/matt40k\/TabularDataPackageBuilder\" target=\"_blank\" rel=\"nofollow\">Tabular Data Package<\/a> definition file, then allow embedding of a simple interaction of the data on a public website for no cost. So PowerBI license to produce, no license to see \\ basic interaction of data (I guess csv file, json definition file, and d3.js) \u2013 then a PowerBI license to bring the data into own PowerBI to join with own data.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 06 Nov 2015 13:37:02 +0000","created_by":1,"updated_at":"Fri, 06 Nov 2015 13:46:51 +0000","updated_by":1,"published_at":"Fri, 06 Nov 2015 13:37:02 +0000","published_by":1},{"id":500,"title":"Collation","slug":"collation","markdown":"\nI don\u2019t know a lot about Collation \u2013 I know how to set it in SQL Server, I know it\u2019s important, it know chaos can ensure if your not careful for example if you set it to CS rather then CI*, so my general tack is to leave it as default and hope it leaves me alone.\n\nToday however, this happened\n\n[![collation](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/11\/collation.png?fit=700%2C49&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/11\/collation.png?ssl=1)\n\nTurns out in the VS SSDT package, I have forgotten to set one of the databases collation\u00a0in project settings to Latin1_General_CI_AS to match the default on SQL Server (rather then the VS SSDT default)\n\n* Glossary  \n CI \u2013 case insensitive \u2013 recommended  \n CS \u2013 case sensitive \u2013 avoid\n\n\n","html":"<p>I don&#8217;t know a lot about Collation &#8211; I know how to set it in SQL Server, I know it&#8217;s important, it know chaos can ensure if your not careful for example if you set it to CS rather then CI*, so my general tack is to leave it as default and hope it leaves me alone.<\/p>\n<p>Today however, this happened<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/11\/collation.png?ssl=1\"><img class=\"alignnone wp-image-501 size-full\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/11\/collation.png?fit=700%2C49&#038;ssl=1\" alt=\"collation\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/11\/collation.png?w=948&amp;ssl=1 948w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/11\/collation.png?resize=300%2C21&amp;ssl=1 300w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/11\/collation.png?resize=648%2C46&amp;ssl=1 648w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2015\/11\/collation.png?resize=583%2C41&amp;ssl=1 583w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>Turns out in the VS SSDT package, I have forgotten to set one of the databases collation\u00a0in project settings to Latin1_General_CI_AS to match the default on SQL Server (rather then the VS SSDT default)<\/p>\n<p>* Glossary<br \/>\nCI &#8211; case insensitive &#8211; recommended<br \/>\nCS &#8211; case sensitive &#8211; avoid<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 24 Nov 2015 13:31:59 +0000","created_by":1,"updated_at":"Thu, 10 Dec 2015 01:44:19 +0000","updated_by":1,"published_at":"Tue, 24 Nov 2015 13:31:59 +0000","published_by":1},{"id":503,"title":"Using PowerShell to check setup","slug":"using-powershell-to-check-setup","markdown":"\nSo I was handed over some new servers, before I got started I wanted to check everything was as it was suppose to be, so I wrote a few PowerShell scripts to check each server was setup correctly. I wanted my DEV to\u00a0100% match my UAT and so on.\n\nFirst, I wanted to check who has local administrator access on the servers.\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/e1bcdefbe89b27c069aa.json\"><\/div>Next, I wanted to check the drives \u2013 I wanted to make sure each drive letter was the same across environments and all had a proper label.\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/632dd4b90688efac3bbd.json\"><\/div>Finally, I wanted to check the service accounts that my SQL services were running as, again, PowerShell to the rescue.\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/ec2b9237a112380d878c.json\"><\/div>\n","html":"<p>So I was handed over some new servers, before I got started I wanted to check everything was as it was suppose to be, so I wrote a few PowerShell scripts to check each server was setup correctly. I wanted my DEV to\u00a0100% match my UAT and so on.<\/p>\n<p>First, I wanted to check who has local administrator access on the servers.<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/e1bcdefbe89b27c069aa.json\"><\/div>\n<p>Next, I wanted to check the drives &#8211; I wanted to make sure each drive letter was the same across environments and all had a proper label.<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/632dd4b90688efac3bbd.json\"><\/div>\n<p>Finally, I wanted to check the service accounts that my SQL services were running as, again, PowerShell to the rescue.<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/ec2b9237a112380d878c.json\"><\/div>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 09 Dec 2015 20:16:49 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:12:41 +0000","updated_by":1,"published_at":"Wed, 09 Dec 2015 20:16:49 +0000","published_by":1},{"id":524,"title":"Getting collation descriptions","slug":"getting-collation-descriptions","markdown":"\nJust an [update](https:\/\/matt40k.uk\/2015\/11\/collation\/) as I noticed I forgot to say how to get the names and descriptions of the collations your SQL Server supports\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/38a9148d4744687ce0ae.json\"><\/div>\n","html":"<p>Just an <a href=\"https:\/\/matt40k.uk\/2015\/11\/collation\/\">update<\/a> as I noticed I forgot to say how to get the names and descriptions of the collations your SQL Server supports<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/38a9148d4744687ce0ae.json\"><\/div>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Thu, 10 Dec 2015 01:45:52 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:12:09 +0000","updated_by":1,"published_at":"Thu, 10 Dec 2015 01:45:52 +0000","published_by":1},{"id":529,"title":"GeoJSON","slug":"geojson","markdown":"\nSo I\u2019ve been playing wit mapping data, one of the nice things about [GitHub](https:\/\/www.github.com\/) is that it supports GeoJSON and automatically renders it\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/8627c1254b7384eab3fd.json\"><\/div>With the mapping data already imported into [Geography](https:\/\/msdn.microsoft.com\/en-us\/library\/cc280766.aspx) in SQL Server it was easy enough to convert to GeoJSON ([Stackoverflow](http:\/\/stackoverflow.com\/) to the rescue again!)\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/57fcd897d654c545bc95.json\"><\/div>\n","html":"<p>So I&#8217;ve been playing wit mapping data, one of the nice things about <a href=\"https:\/\/www.github.com\/\" target=\"_blank\" rel=\"nofollow\">GitHub<\/a> is that it supports GeoJSON and automatically renders it<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/8627c1254b7384eab3fd.json\"><\/div>\n<p>With the mapping data already imported into <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/cc280766.aspx\" target=\"_blank\" rel=\"nofollow\">Geography<\/a> in SQL Server it was easy enough to convert to GeoJSON (<a href=\"http:\/\/stackoverflow.com\/\" target=\"_blank\" rel=\"nofollow\">Stackoverflow<\/a> to the rescue again!)<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/57fcd897d654c545bc95.json\"><\/div>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Thu, 10 Dec 2015 01:50:26 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:11:55 +0000","updated_by":1,"published_at":"Thu, 10 Dec 2015 01:50:26 +0000","published_by":1},{"id":540,"title":"Automated SQL Server BI deployments with OctopusDeploy","slug":"automated-sql-server-bi-deployments-with-octopusdeploy","markdown":"\nToday, my [pull request ](https:\/\/github.com\/OctopusDeploy\/Library\/pull\/278)for the [SSAS deployment script ](https:\/\/gist.github.com\/matt40k\/ed6231dfee98261bf6bc)was merged into the [Octopus Deploy](http:\/\/octopusdeploy.com) [Community Library](https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ssas-from-package).\n\nSo what is [<u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u>](http:\/\/octopusdeploy.com)\u00a0and why should I care?\n\n> Octopus is a friendly deployment automation tool for .NET developers.\n\nBut don\u2019t be fooled. [<u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u>](http:\/\/octopusdeploy.com)\u00a0isn\u2019t just limited to .NET developers deploying hip new cloud based applications, it can do much, much more. I currently use [Octopus](http:\/\/octopusdeploy.com)\u00a0to deploy Jasper reports to our 6 HR environments, I also use it to deploy our HR interfaces which are a series of SSIS packages and SQL objects which uses\u00a0Microsoft SQL Server 2008. I use [DbUp](https:\/\/dbup.github.io\/), a open source library, for database deployment and a custom C# application for SSIS package deployment. Today, we surpassed 1,000 report deployments to production, we\u2019ve also deploy over 270 SSIS package changes in about a year.\n\nSo when it came to upgrading our BI platform from SQL 2008 to SQL 2014, one of the key things I want was deployment automation. The SQL 2008 platform required manual deployments which often lead to mistakes and ended up writing the entire day off, per deployment. Unfortunately, my current process was pretty basic. Database deployments are idempotent, it drop any objects and recreated them, every time. This is fine for interfaces where tables only hold in transit data, but for BI, the idea of dropping a staging table with 140 million rows that takes over 4 hours to load doesn\u2019t make me want to do any deployments. Luckily, the problem is already solved. SSDT. And there is already a [PowerShell step template ](https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-sql-deploy-dacpac)on the [<u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u>](http:\/\/octopusdeploy.com) [<u><span style=\"color: #0066cc;\">Community Library<\/span><\/u>](https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ssas-from-package).\n\nAlso moving to SQL 2014 allowed me to use the new ISPAC, again, there is already a [PowerShell step template ](https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ispac-ssis-project-from-a-package)on the [<u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u>](http:\/\/octopusdeploy.com) [<u><span style=\"color: #0066cc;\">Community Library<\/span><\/u>](https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ssas-from-package). There is even a[ PowerShell step template for SSRS](https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ssrs-reports-from-a-package).\n\nThe only thing missing was SSAS. After watching [Chris Webb\u2019s ](http:\/\/blog.crossjoin.co.uk\/)video tutorial \u2013 [Cube Deployment, Processing and Admin](https:\/\/projectbotticelli.com\/knowledge\/ssas-cube-deployment-processing-and-admin-video-tutorial)\u00a0on [Project Botticelli](https:\/\/projectbotticelli.com\/knowledge\/ssas-cube-deployment-processing-and-admin-video-tutorial), I decided it had to use [Microsoft.AnalysisServices.Deployment.exe](https:\/\/msdn.microsoft.com\/en-us\/library\/ms162758.aspx). After a bit of scripting and testing, I managed to write a PowerShell that updates the xml config files for the deployment \u2013 it sets the **ProcessingOption** to **\u2018**<span class=\"pl-s\">**DoNotProcess\u2019.** It updates the **Data source** \u2013 where the cube will refresh the data from. The script isn\u2019t perfect. For starters, what if you have more then one data source? Also what if your not using SQL Server 2014? Still the great thing about open source is that other can update it. Anyone can improve it, its not reliant on me having free time. So hopefully by the time we move to SQL 2016 someone will have already updated it to work with SQL 2016.<\/span>\n\nIn a future post I\u2019m going to blog about [<u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u>](http:\/\/octopusdeploy.com) in a bit more detail and how I\u2019ve setup my SQL Server BI deployment process (in a lot of detail). I\u2019m hoping to try using [Microsoft Visual Studio Team Services ](https:\/\/www.visualstudio.com\/en-us\/products\/visual-studio-team-services-vs.aspx)to build the Octopus packages. Currently I use a on-prem [TeamCity](https:\/\/www.jetbrains.com\/teamcity\/), which is excellent, its just\u2026 I don\u2019t like managing extra servers when I can use SaaS. I like development over administration.\n\nI\u2019ll leave you will a screenshot of my deployment screen in [<u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u>](http:\/\/octopusdeploy.com), and yes, that\u2019s **one** button press to get my changes into UAT\n\n[![octopusbi](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?fit=700%2C376&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?ssl=1)\n\n\n","html":"<p>Today, my <a href=\"https:\/\/github.com\/OctopusDeploy\/Library\/pull\/278\" target=\"_blank\" rel=\"nofollow\">pull request <\/a>for the <a href=\"https:\/\/gist.github.com\/matt40k\/ed6231dfee98261bf6bc\" target=\"_blank\" rel=\"nofollow\">SSAS deployment script <\/a>was merged into the <a href=\"http:\/\/octopusdeploy.com\" target=\"_blank\" rel=\"nofollow\">Octopus Deploy<\/a> <a href=\"https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ssas-from-package\" target=\"_blank\" rel=\"nofollow\">Community Library<\/a>.<\/p>\n<p>So what is <a href=\"http:\/\/octopusdeploy.com\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u><\/a>\u00a0and why should I care?<\/p>\n<blockquote><p>Octopus is a friendly deployment automation tool for .NET developers.<\/p><\/blockquote>\n<p>But don&#8217;t be fooled. <a href=\"http:\/\/octopusdeploy.com\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u><\/a>\u00a0isn&#8217;t just limited to .NET developers deploying hip new cloud based applications, it can do much, much more. I currently use <a href=\"http:\/\/octopusdeploy.com\" target=\"_blank\" rel=\"nofollow\">Octopus<\/a>\u00a0to deploy Jasper reports to our 6 HR environments, I also use it to deploy our HR interfaces which are a series of SSIS packages and SQL objects which uses\u00a0Microsoft SQL Server 2008. I use <a href=\"https:\/\/dbup.github.io\/\" target=\"_blank\" rel=\"nofollow\">DbUp<\/a>, a open source library, for database deployment and a custom C# application for SSIS package deployment. Today, we surpassed 1,000 report deployments to production, we&#8217;ve also deploy over 270 SSIS package changes in about a year.<\/p>\n<p>So when it came to upgrading our BI platform from SQL 2008 to SQL 2014, one of the key things I want was deployment automation. The SQL 2008 platform required manual deployments which often lead to mistakes and ended up writing the entire day off, per deployment. Unfortunately, my current process was pretty basic. Database deployments are idempotent, it drop any objects and recreated them, every time. This is fine for interfaces where tables only hold in transit data, but for BI, the idea of dropping a staging table with 140 million rows that takes over 4 hours to load doesn&#8217;t make me want to do any deployments. Luckily, the problem is already solved. SSDT. And there is already a <a href=\"https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-sql-deploy-dacpac\" target=\"_blank\" rel=\"nofollow\">PowerShell step template <\/a>on the <a href=\"http:\/\/octopusdeploy.com\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u><\/a> <a href=\"https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ssas-from-package\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Community Library<\/span><\/u><\/a>.<\/p>\n<p>Also moving to SQL 2014 allowed me to use the new ISPAC, again, there is already a <a href=\"https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ispac-ssis-project-from-a-package\" target=\"_blank\" rel=\"nofollow\">PowerShell step template <\/a>on the <a href=\"http:\/\/octopusdeploy.com\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u><\/a> <a href=\"https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ssas-from-package\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Community Library<\/span><\/u><\/a>. There is even a<a href=\"https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-deploy-ssrs-reports-from-a-package\" target=\"_blank\" rel=\"nofollow\"> PowerShell step template for SSRS<\/a>.<\/p>\n<p>The only thing missing was SSAS. After watching <a href=\"http:\/\/blog.crossjoin.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Chris Webb&#8217;s <\/a>video tutorial &#8211; <a href=\"https:\/\/projectbotticelli.com\/knowledge\/ssas-cube-deployment-processing-and-admin-video-tutorial\" target=\"_blank\" rel=\"nofollow\">Cube Deployment, Processing and Admin<\/a>\u00a0on <a href=\"https:\/\/projectbotticelli.com\/knowledge\/ssas-cube-deployment-processing-and-admin-video-tutorial\" target=\"_blank\" rel=\"nofollow\">Project Botticelli<\/a>, I decided it had to use <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/ms162758.aspx\" target=\"_blank\" rel=\"nofollow\">Microsoft.AnalysisServices.Deployment.exe<\/a>. After a bit of scripting and testing, I managed to write a PowerShell that updates the xml config files for the deployment &#8211; it sets the <strong>ProcessingOption<\/strong> to <strong>&#8216;<\/strong><span class=\"pl-s\"><strong>DoNotProcess&#8217;.<\/strong> It updates the <strong>Data source<\/strong> &#8211; where the cube will refresh the data from. The script isn&#8217;t perfect. For starters, what if you have more then one data source? Also what if your not using SQL Server 2014? Still the great thing about open source is that other can update it. Anyone can improve it, its not reliant on me having free time. So hopefully by the time we move to SQL 2016 someone will have already updated it to work with SQL 2016.<\/span><\/p>\n<p>In a future post I&#8217;m going to blog about <a href=\"http:\/\/octopusdeploy.com\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u><\/a> in a bit more detail and how I&#8217;ve setup my SQL Server BI deployment process (in a lot of detail). I&#8217;m hoping to try using <a href=\"https:\/\/www.visualstudio.com\/en-us\/products\/visual-studio-team-services-vs.aspx\" target=\"_blank\" rel=\"nofollow\">Microsoft Visual Studio Team Services <\/a>to build the Octopus packages. Currently I use a on-prem <a href=\"https:\/\/www.jetbrains.com\/teamcity\/\" target=\"_blank\" rel=\"nofollow\">TeamCity<\/a>, which is excellent, its just&#8230; I don&#8217;t like managing extra servers when I can use SaaS. I like development over administration.<\/p>\n<p>I&#8217;ll leave you will a screenshot of my deployment screen in <a href=\"http:\/\/octopusdeploy.com\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Octopus Deploy<\/span><\/u><\/a>, and yes, that&#8217;s <strong>one<\/strong> button press to get my changes into UAT<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?ssl=1\" rel=\"attachment wp-att-548\"><img class=\"alignnone wp-image-548 size-full\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?fit=700%2C376&#038;ssl=1\" alt=\"octopusbi\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?w=1600&amp;ssl=1 1600w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?resize=300%2C161&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?resize=768%2C413&amp;ssl=1 768w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?resize=1024%2C550&amp;ssl=1 1024w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?resize=648%2C348&amp;ssl=1 648w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?resize=357%2C192&amp;ssl=1 357w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/octopusbi.png?w=1400&amp;ssl=1 1400w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 15 Jan 2016 21:50:50 +0000","created_by":1,"updated_at":"Fri, 15 Jan 2016 23:31:16 +0000","updated_by":1,"published_at":"Fri, 15 Jan 2016 21:50:50 +0000","published_by":1},{"id":542,"title":"East Anglia SQL Server User Group","slug":"east-anglia-sql-server-user-group","markdown":"\nAnyone working with SQL Server will be well aware of the mountains of[ training material](http:\/\/projectbotticelli.com\/), [blog posts](http:\/\/blog.crossjoin.co.uk), [videos](https:\/\/www.youtube.com\/user\/PASSBIVC), [code snippets](https:\/\/gist.github.com\/in2bi\/c82b6486b5ca7bc39b01),\u00a0[events ](http:\/\/sqlcambs.org.uk\/)and other helpful resources that helps anyone who comes into contact SQL Server regardless if they are a beginner or a seasoned veteran (even [MVPs](https:\/\/mvp.microsoft.com\/)!). One of the pools of knowledge is [SQL PASS](https:\/\/www.sqlpass.org\/).\n\n> is an independent, not-for-profit organization run by and for the community. With a growing membership of more than 100K, PASS supports data professionals throughout the world who use the Microsoft data platform.\n\nNot only do they do [Virtual Chapters](http:\/\/www.sqlpass.org\/PASSChapters\/VirtualChapters.aspx), but they also do [Local Chapters](http:\/\/sqlea.org.uk\/). Local Chapters are an excellent way to make connections with (physically) local fellow experts. I would highly recommend if your working with SQL Server to join, both a [<u><span style=\"color: #0066cc;\">Virtual Chapter<\/span><\/u>](http:\/\/www.sqlpass.org\/PASSChapters\/VirtualChapters.aspx)\u00a0and [Local Chapter](http:\/\/www.sqlpass.org\/PASSChapters\/LocalChapters.aspx), as they are both excellent ways to learn and build a network of friends who you can point you in the right direction when your stuck. Best of all, its **FREE!!**\n\nMy Local Chapter is run [Mark Broadbent](http:\/\/tenbulls.co.uk\/miscellaneous\/about\/), a\u00a0Microsoft Certified Master in SQL Server\u00a0(MCM) and Microsoft Data Platform MVP ([<u><span style=\"color: #0066cc;\">Most Valuable Professional<\/span><\/u>](https:\/\/mvp.microsoft.com\/en-us\/ \"most valuable professional\")). [Mark ](http:\/\/tenbulls.co.uk)has this year, rebranded SQL Server User Group from [SQL Cambs ](http:\/\/sqlcambs.org.uk\/)to [East Anglia SQL Server User Group](http:\/\/sqlea.org.uk\/). He done this after myself and a few others spoke to him about running more local user groups. I personally, didn\u2019t want to setup a new, separate, user group that will end up competing\u00a0with the other. Suffolk, Norfolk and Cambridgeshire are neighbours, they should be working together, not competing. Hopefully the new User Group name reflects this. I\u2019ve been working with [Mark ](http:\/\/tenbulls.co.uk)at setting up the first [East Anglia SQL Server User Group](http:\/\/sqlea.org.uk\/), which I am delighted is being held in Ipswich at the [University Campus Suffolk (UCS) Waterfront Building](http:\/\/www.ucs.ac.uk\/Faculties-and-Centres\/Ourcampusnetwork\/UCSIpswich\/Waterfront%20building.aspx).\u00a0This is lovely modern building that, selfishly, is a 20min walk from my home or work \u2013 can\u2019t get much more local! \u00a0It is also a 20 min walk to the train station and has free parking in the evenings so hopefully I\u2019m not the only one who likes this venue\u00a0\ud83d\ude42\n\n[![UCS](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/UCS-300x212.jpg?fit=300%2C212&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/UCS.jpg?ssl=1)\n\nThe first speaker\u00a0(under the new name), will be [Prathy Kamasani ](https:\/\/twitter.com\/pkamasani)who\u00a0has\u00a0by some miracle been able to compress all the [**What\u2019s new in SQL Server 2016 for a BI Professional**](http:\/\/sqlea.org.uk\/2016\/01\/15\/meetup20160128\/) into a single presentation.\u00a0If you\u2019ve been living under a rock for the past year, Microsoft has pulled out all[](https:\/\/powerbi.microsoft.com\/en-us\/documentation\/powerbi-desktop-latest-update\/)the stops with SQL Server 2016 and given the whole Microsoft BI stack a update, even Reporting Services (SSRS)! They\u2019ve been announcing some pretty major new features every month. It\u2019s truly incredible but at the same time rather overwhelming. At the end of the meetup, you\u2019ll up to speed with all the cool new features in SQL Server 2016.\n\n[Register here for free for **<u><span style=\"color: #0066cc;\">What\u2019s new in SQL Server 2016 for a BI Professional.<\/span><\/u>**](http:\/\/www.eventbrite.co.uk\/e\/sqlea-january-meetup-ipswich-tickets-20759595509)\n\nHopefully I\u2019ll see a lot of you there and we\u2019ll have many more User Groups in 2016 and beyond and yes,\u00a0pizza will be provided\u00a0\ud83d\ude42\n\nThis [East Anglia SQL Server User Group](http:\/\/sqlea.org.uk\/2016\/01\/15\/meetup20160128\/) meetup is sponsored by: [![sqlcloud_image](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/sqlcloud_image.png?fit=170%2C60&ssl=1)](http:\/\/sqlcloud.co.uk\/)\n\n\n","html":"<p>Anyone working with SQL Server will be well aware of the mountains of<a href=\"http:\/\/projectbotticelli.com\/\" target=\"_blank\" rel=\"nofollow\"> training material<\/a>, <a href=\"http:\/\/blog.crossjoin.co.uk\" target=\"_blank\" rel=\"nofollow\">blog posts<\/a>, <a href=\"https:\/\/www.youtube.com\/user\/PASSBIVC\" target=\"_blank\" rel=\"nofollow\">videos<\/a>, <a href=\"https:\/\/gist.github.com\/in2bi\/c82b6486b5ca7bc39b01\" target=\"_blank\" rel=\"nofollow\">code snippets<\/a>,\u00a0<a href=\"http:\/\/sqlcambs.org.uk\/\" target=\"_blank\" rel=\"nofollow\">events <\/a>and other helpful resources that helps anyone who comes into contact SQL Server regardless if they are a beginner or a seasoned veteran (even <a href=\"https:\/\/mvp.microsoft.com\/\" target=\"_blank\" rel=\"nofollow\">MVPs<\/a>!). One of the pools of knowledge is <a href=\"https:\/\/www.sqlpass.org\/\" target=\"_blank\" rel=\"nofollow\">SQL PASS<\/a>.<\/p>\n<blockquote><p>is an independent, not-for-profit organization run by and for the community. With a growing membership of more than 100K, PASS supports data professionals throughout the world who use the Microsoft data platform.<\/p><\/blockquote>\n<p>Not only do they do <a href=\"http:\/\/www.sqlpass.org\/PASSChapters\/VirtualChapters.aspx\" target=\"_blank\" rel=\"nofollow\">Virtual Chapters<\/a>, but they also do <a href=\"http:\/\/sqlea.org.uk\/\" target=\"_blank\" rel=\"nofollow\">Local Chapters<\/a>. Local Chapters are an excellent way to make connections with (physically) local fellow experts. I would highly recommend if your working with SQL Server to join, both a <a href=\"http:\/\/www.sqlpass.org\/PASSChapters\/VirtualChapters.aspx\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Virtual Chapter<\/span><\/u><\/a>\u00a0and <a href=\"http:\/\/www.sqlpass.org\/PASSChapters\/LocalChapters.aspx\" target=\"_blank\" rel=\"nofollow\">Local Chapter<\/a>, as they are both excellent ways to learn and build a network of friends who you can point you in the right direction when your stuck. Best of all, its <strong>FREE!!<\/strong><\/p>\n<p>My Local Chapter is run <a href=\"http:\/\/tenbulls.co.uk\/miscellaneous\/about\/\" target=\"_blank\" rel=\"nofollow\">Mark Broadbent<\/a>, a\u00a0Microsoft Certified Master in SQL Server\u00a0(MCM) and Microsoft Data Platform MVP (<a title=\"most valuable professional\" href=\"https:\/\/mvp.microsoft.com\/en-us\/\" target=\"_blank\" rel=\"nofollow\"><u><span style=\"color: #0066cc;\">Most Valuable Professional<\/span><\/u><\/a>). <a href=\"http:\/\/tenbulls.co.uk\" target=\"_blank\" rel=\"nofollow\">Mark <\/a>has this year, rebranded SQL Server User Group from <a href=\"http:\/\/sqlcambs.org.uk\/\" target=\"_blank\" rel=\"nofollow\">SQL Cambs <\/a>to <a href=\"http:\/\/sqlea.org.uk\/\" target=\"_blank\" rel=\"nofollow\">East Anglia SQL Server User Group<\/a>. He done this after myself and a few others spoke to him about running more local user groups. I personally, didn&#8217;t want to setup a new, separate, user group that will end up competing\u00a0with the other. Suffolk, Norfolk and Cambridgeshire are neighbours, they should be working together, not competing. Hopefully the new User Group name reflects this. I&#8217;ve been working with <a href=\"http:\/\/tenbulls.co.uk\" target=\"_blank\" rel=\"nofollow\">Mark <\/a>at setting up the first <a href=\"http:\/\/sqlea.org.uk\/\" target=\"_blank\" rel=\"nofollow\">East Anglia SQL Server User Group<\/a>, which I am delighted is being held in Ipswich at the <a href=\"http:\/\/www.ucs.ac.uk\/Faculties-and-Centres\/Ourcampusnetwork\/UCSIpswich\/Waterfront%20building.aspx\" target=\"_blank\" rel=\"nofollow\">University Campus Suffolk (UCS) Waterfront Building<\/a>.\u00a0This is lovely modern building that, selfishly, is a 20min walk from my home or work &#8211; can&#8217;t get much more local! \u00a0It is also a 20 min walk to the train station and has free parking in the evenings so hopefully I&#8217;m not the only one who likes this venue\u00a0\ud83d\ude42<\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/UCS.jpg?ssl=1\" rel=\"attachment wp-att-545\"><img class=\"alignnone size-medium wp-image-545\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/UCS-300x212.jpg?fit=300%2C212&#038;ssl=1\" alt=\"UCS\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/UCS.jpg?resize=300%2C212&amp;ssl=1 300w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/UCS.jpg?resize=271%2C192&amp;ssl=1 271w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/UCS.jpg?w=630&amp;ssl=1 630w\" sizes=\"(max-width: 300px) 100vw, 300px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>The first speaker\u00a0(under the new name), will be <a href=\"https:\/\/twitter.com\/pkamasani\" target=\"_blank\" rel=\"nofollow\">Prathy Kamasani <\/a>who\u00a0has\u00a0by some miracle been able to compress all the <a href=\"http:\/\/sqlea.org.uk\/2016\/01\/15\/meetup20160128\/\" target=\"_blank\" rel=\"nofollow\"><strong>What\u2019s new in SQL Server 2016 for a BI Professional<\/strong><\/a> into a single presentation.\u00a0If you&#8217;ve been living under a rock for the past year, Microsoft has pulled out all<a href=\"https:\/\/powerbi.microsoft.com\/en-us\/documentation\/powerbi-desktop-latest-update\/\" target=\"_blank\" rel=\"nofollow\"> <\/a>the stops with SQL Server 2016 and given the whole Microsoft BI stack a update, even Reporting Services (SSRS)! They&#8217;ve been announcing some pretty major new features every month. It&#8217;s truly incredible but at the same time rather overwhelming. At the end of the meetup, you&#8217;ll up to speed with all the cool new features in SQL Server 2016.<\/p>\n<p><a href=\"http:\/\/www.eventbrite.co.uk\/e\/sqlea-january-meetup-ipswich-tickets-20759595509\" target=\"_blank\" rel=\"nofollow\">Register here for free for <strong><u><span style=\"color: #0066cc;\">What\u2019s new in SQL Server 2016 for a BI Professional.<\/span><\/u><\/strong><\/a><\/p>\n<p>Hopefully I&#8217;ll see a lot of you there and we&#8217;ll have many more User Groups in 2016 and beyond and yes,\u00a0pizza will be provided\u00a0\ud83d\ude42<\/p>\n<p>This <a href=\"http:\/\/sqlea.org.uk\/2016\/01\/15\/meetup20160128\/\" target=\"_blank\" rel=\"nofollow\">East Anglia SQL Server User Group<\/a> meetup is sponsored by: <a href=\"http:\/\/sqlcloud.co.uk\/\" rel=\"attachment wp-att-544\" target=\"_blank\" rel=\"nofollow\"><img class=\"alignnone size-full wp-image-544\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/01\/sqlcloud_image.png?fit=170%2C60&#038;ssl=1\" alt=\"sqlcloud_image\" data-recalc-dims=\"1\" \/><\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 15 Jan 2016 23:15:30 +0000","created_by":1,"updated_at":"Fri, 15 Jan 2016 23:15:30 +0000","updated_by":1,"published_at":"Fri, 15 Jan 2016 23:15:30 +0000","published_by":1},{"id":551,"title":"Automatic build and deployment process for Microsoft BI","slug":"temp-slug-55","markdown":"\nI\u2019ve previously [blogged about how I was going to detail how I build and deploy my Microsoft BI projects](\/2016\/01\/automated-sql-server-bi-deployments-with-octopusdeploy\/)\u00a0and to be honest, I\u2019ve been putting it off. The main reason is my work has been looking at [Visual Studio Team Services](https:\/\/www.visualstudio.com\/products\/visual-studio-team-services-vs), formally [Visual Studio Online](https:\/\/www.visualstudio.com\/products\/visual-studio-team-services-vs)\u00a0and I was looking at using the Build functionality that is included. This should make the whole setup process a lot easier for anyone else trying to replicate my setup. Unfortunately this doesn\u2019t look like its going to happen this quarter.\n\n\n## How I got here\n\nSo when I started in BI we where using Microsoft SQL Server 2008.\n\nSSIS packages used XML configuration files and deployment files were created, manually copied to the SQL Server, then you logged onto the server \u2013 via RDP, ran the SSIS deployment file \u2013 which basically created a copy of the files and changed the variables in the XML configuration file.\n\nDatabase changes was done by a giant SQL script \u2013 it started out as a\u00a0simple script out the database objects, but future changes happened by simply updating the SQL script, manually.\n\nDeployments were a pain. Every deployment had to be (re)deployed to DEV, then to UAT before finally getting to PROD. They took time and because they took time you tried to avoid them. Which meant every deployment was bigger. If you **had** to do something you would try and do it easiest way, ie manually change the raw SSIS package. This of course leads to drift.\n\nWhen I started my job, one of the first tasks was to bring\u00a0UAT up-to-date (after\u00a0setting up auditing). After a quick look at the database schema I could tell the database objects were out-of-date,\u00a0database compare tools were absolute life saver.\u00a0Unsurprisingly, they (who shall remain nameless) didn\u2019t commit the code to version control either. The only copy of the code was PROD, DEV had a even more updated version, however it was left in a unfinished state.\n\nRight, enough with the horror stories of how I started my journey\u00a0in BI.\n\n\n## Fresh start\n\nWhen we started to talk about upgrade from SQL Server 2008 to SQL Server 2014 I thought about some of the things I wanted.\n\nI wanted a single tool to design the whole end-to-end product. From the database, to the ETL packages to the data model all the way to the end user reports. Guess what? Its Visual Studio.\n\nPreviously I had been to [my local SQL Pass User Group](http:\/\/sqlea.org.uk\/2014\/06\/20\/usergroup-meetups-8-31st-july-and-9-28th-august-announced\/) where [Alex\u00a0Yates](http:\/\/workingwithdevs.com\/)\u00a0and explain the whole continuous integration and deployment methodology, but aimed at the DBA. To put it simply, it forces you to use version control, which I **love**. The\u00a0continuous integration basically means build on a dedicated machine \u2013 this gets around the whole \u201cwell it works me for me\u201d arguments, if you forgot to commit a file and the build fails, its clearly your fault. If it builds OK on the clean build server, but doesn\u2019t build on your colleagues, you know they have a problem, not you. The deployment is pretty straight forward, you don\u2019t really need it when you have a single component, but when you have something like BI, where you have multiple components that have dependencies on one another, like the SQL database objects, the SSIS packages and the SSAS packages, you need to create an \u201cinstaller\u201d. I also wanted to a \u201cstandard\u201d deployment method, if the automated process failed, I want to be able to run it manually.\n\n\n## The solution\n\nFor the continuous integration element, the build process, I\u2019ve used [TeamCity](https:\/\/www.jetbrains.com\/teamcity\/) from the very excellent [JetBrains](https:\/\/www.jetbrains.com\/).\u00a0[TeamCity](https:\/\/www.jetbrains.com\/teamcity\/)\u00a0is a very mature stable product, my one \u201cgrip\u201d is that based on Tomcat, luckily\u00a0[JetBrains](https:\/\/www.jetbrains.com\/)\u00a0have bundled it very well so its not really a problem. The main reasons for using it are, its a stable product (on Windows OS), its a got excellent support (ie you can find help on the internet) and it has a free tier \u2013 Professional Server license gives you 20 build configurations.\n\nFor the\u00a0continuous deployment element, I\u2019ve used [OctopusDeploy](https:\/\/octopusdeploy.com\/).\n\n\n","html":"<p>I&#8217;ve previously <a href=\"\/2016\/01\/automated-sql-server-bi-deployments-with-octopusdeploy\/\">blogged about how I was going to detail how I build and deploy my Microsoft BI projects<\/a>\u00a0and to be honest, I&#8217;ve been putting it off. The main reason is my work has been looking at <a href=\"https:\/\/www.visualstudio.com\/products\/visual-studio-team-services-vs\" target=\"_blank\" rel=\"nofollow\">Visual Studio Team Services<\/a>, formally <a href=\"https:\/\/www.visualstudio.com\/products\/visual-studio-team-services-vs\" target=\"_blank\" rel=\"nofollow\">Visual Studio Online<\/a>\u00a0and I was looking at using the Build functionality that is included. This should make the whole setup process a lot easier for anyone else trying to replicate my setup. Unfortunately this doesn&#8217;t look like its going to happen this quarter.<\/p>\n<h2>How I got here<\/h2>\n<p>So when I started in BI we where using Microsoft SQL Server 2008.<\/p>\n<p>SSIS packages used XML configuration files and deployment files were created, manually copied to the SQL Server, then you logged onto the server &#8211; via RDP, ran the SSIS deployment file &#8211; which basically created a copy of the files and changed the variables in the XML configuration file.<\/p>\n<p>Database changes was done by a giant SQL script &#8211; it started out as a\u00a0simple script out the database objects, but future changes happened by simply updating the SQL script, manually.<\/p>\n<p>Deployments were a pain. Every deployment had to be (re)deployed to DEV, then to UAT before finally getting to PROD. They took time and because they took time you tried to avoid them. Which meant every deployment was bigger. If you <strong>had<\/strong> to do something you would try and do it easiest way, ie manually change the raw SSIS package. This of course leads to drift.<\/p>\n<p>When I started my job, one of the first tasks was to bring\u00a0UAT up-to-date (after\u00a0setting up auditing). After a quick look at the database schema I could tell the database objects were out-of-date,\u00a0database compare tools were absolute life saver.\u00a0Unsurprisingly, they (who shall remain nameless) didn&#8217;t commit the code to version control either. The only copy of the code was PROD, DEV had a even more updated version, however it was left in a unfinished state.<\/p>\n<p>Right, enough with the horror stories of how I started my journey\u00a0in BI.<\/p>\n<h2>Fresh start<\/h2>\n<p>When we started to talk about upgrade from SQL Server 2008 to SQL Server 2014 I thought about some of the things I wanted.<\/p>\n<p>I wanted a single tool to design the whole end-to-end product. From the database, to the ETL packages to the data model all the way to the end user reports. Guess what? Its Visual Studio.<\/p>\n<p>Previously I had been to <a href=\"http:\/\/sqlea.org.uk\/2014\/06\/20\/usergroup-meetups-8-31st-july-and-9-28th-august-announced\/\" target=\"_blank\" rel=\"nofollow\">my local SQL Pass User Group<\/a> where <a href=\"http:\/\/workingwithdevs.com\/\" target=\"_blank\" rel=\"nofollow\">Alex\u00a0Yates<\/a>\u00a0and explain the whole continuous integration and deployment methodology, but aimed at the DBA. To put it simply, it forces you to use version control, which I <strong>love<\/strong>. The\u00a0continuous integration basically means build on a dedicated machine &#8211; this gets around the whole &#8220;well it works me for me&#8221; arguments, if you forgot to commit a file and the build fails, its clearly your fault. If it builds OK on the clean build server, but doesn&#8217;t build on your colleagues, you know they have a problem, not you. The deployment is pretty straight forward, you don&#8217;t really need it when you have a single component, but when you have something like BI, where you have multiple components that have dependencies on one another, like the SQL database objects, the SSIS packages and the SSAS packages, you need to create an &#8220;installer&#8221;. I also wanted to a &#8220;standard&#8221; deployment method, if the automated process failed, I want to be able to run it manually.<\/p>\n<h2>The solution<\/h2>\n<p>For the continuous integration element, the build process, I&#8217;ve used <a href=\"https:\/\/www.jetbrains.com\/teamcity\/\" target=\"_blank\" rel=\"nofollow\">TeamCity<\/a> from the very excellent <a href=\"https:\/\/www.jetbrains.com\/\" target=\"_blank\" rel=\"nofollow\">JetBrains<\/a>.\u00a0<a href=\"https:\/\/www.jetbrains.com\/teamcity\/\" target=\"_blank\" rel=\"nofollow\">TeamCity<\/a>\u00a0is a very mature stable product, my one &#8220;grip&#8221; is that based on Tomcat, luckily\u00a0<a href=\"https:\/\/www.jetbrains.com\/\" target=\"_blank\" rel=\"nofollow\">JetBrains<\/a>\u00a0have bundled it very well so its not really a problem. The main reasons for using it are, its a stable product (on Windows OS), its a got excellent support (ie you can find help on the internet) and it has a free tier &#8211; Professional Server license gives you 20 build configurations.<\/p>\n<p>For the\u00a0continuous deployment element, I&#8217;ve used <a href=\"https:\/\/octopusdeploy.com\/\" target=\"_blank\" rel=\"nofollow\">OctopusDeploy<\/a>.<\/p>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 01 Feb 2016 23:16:27 +0000","created_by":1,"updated_at":"Mon, 01 Feb 2016 23:16:27 +0000","updated_by":1,"published_at":"","published_by":1},{"id":557,"title":"DacPac vs SqlCmd variables","slug":"dacpac-vs-sqlcmd-variables","markdown":"\nI recently discovered the ability to reference other database project (I know, I know), anyway, this cause my lovely automate build\\deployment process to fail. Investigating the error led me to, yes, you guessed it a [Jamie Thomson\u2019s blog](http:\/\/sqlblog.com\/blogs\/jamie_thomson\/archive\/2012\/11\/13\/a-dacpac-limitation-deploy-dacpac-wizard-does-not-understand-sqlcmd-variables.aspx)\u00a0(from 2012).\n\nThankfully, I managed to figure out a clean solution, the [DacPac solution on Octopus Deploy library ](https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-sql-deploy-dacpac)has an option to pass **Profile Name**, which is the publish profile XML file. He is the cut-down version I\u2019ve used, just the missing variables\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/1c1999ec349d00018037.json\"><\/div>\n","html":"<p>I recently discovered the ability to reference other database project (I know, I know), anyway, this cause my lovely automate build\\deployment process to fail. Investigating the error led me to, yes, you guessed it a <a href=\"http:\/\/sqlblog.com\/blogs\/jamie_thomson\/archive\/2012\/11\/13\/a-dacpac-limitation-deploy-dacpac-wizard-does-not-understand-sqlcmd-variables.aspx\" target=\"_blank\" rel=\"nofollow\">Jamie Thomson&#8217;s blog<\/a>\u00a0(from 2012).<\/p>\n<p>Thankfully, I managed to figure out a clean solution, the <a href=\"https:\/\/library.octopusdeploy.com\/#!\/step-template\/actiontemplate-sql-deploy-dacpac\" target=\"_blank\" rel=\"nofollow\">DacPac solution on Octopus Deploy library <\/a>has an option to pass <strong>Profile Name<\/strong>, which is the publish profile XML file. He is the cut-down version I&#8217;ve used, just the missing variables<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/1c1999ec349d00018037.json\"><\/div>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 02 Feb 2016 23:58:33 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:10:42 +0000","updated_by":1,"published_at":"Tue, 02 Feb 2016 23:58:33 +0000","published_by":1},{"id":568,"title":"Clever SQL Jobs?","slug":"clever-sql-jobs","markdown":"\nJust thinking out load (because its good to get feedback)\n\n> Dont suppose anyone has a clever way of scheduling sql jobs? Looking at you [@jamiet](https:\/\/twitter.com\/jamiet)\n> \n> \u2014 Matt Smith (@matt40k) [February 9, 2016](https:\/\/twitter.com\/matt40k\/status\/697050198120464384)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\nJust to expand on my tweet. I\u2019ve lot of SSIS packages for load and building my BI warehouse (SSAS cubes), now currently I have a SQL job that has multiple steps\n\nFor example\n\n1. Load data from Source system into Staging\n2. Build\u00a0ODS intermediate tables\n3. Build Warehouse tables\n\nAnd this works for DataMart where they are a denormalized copy of a single source system, but when the source system, or the intermediate tables, are used multiple times, you don\u2019t want to run them multiple times. Equally\u00a0I don\u2019t want to figure this out each time we\u00a0add a new package.\n\nI basically want a controller task that manages it.\n\nWe have a automation build\\deploy process, \u00a0so you commit the (SSDT\\SSIS\\SSAS) packages and it deploys it and creates a SQL job for each SSIS package. We could add step to trigger the controller to update the schedules based on the change.\n\nNow we would need to define the dependencies, basically we need build a hierarchy. Technically I could read the SSIS packages then parse the select statements then create some logic to work it out automatically, but for now, it\u2019ll be a static table(s).\n\nSo. Do I create a SQL stored procedure to create a SQL job(s) with multiple steps or a SSIS package using something like BIML?\n\n\u00a0\n\n\u00a0\n\n\n","html":"<p>Just thinking out load (because its good to get feedback)<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">Dont suppose anyone has a clever way of scheduling sql jobs? Looking at you <a href=\"https:\/\/twitter.com\/jamiet\" target=\"_blank\" rel=\"nofollow\">@jamiet<\/a><\/p>\n<p>&mdash; Matt Smith (@matt40k) <a href=\"https:\/\/twitter.com\/matt40k\/status\/697050198120464384\" target=\"_blank\" rel=\"nofollow\">February 9, 2016<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>Just to expand on my tweet. I&#8217;ve lot of SSIS packages for load and building my BI warehouse (SSAS cubes), now currently I have a SQL job that has multiple steps<\/p>\n<p>For example<\/p>\n<ol>\n<li>Load data from Source system into Staging<\/li>\n<li>Build\u00a0ODS intermediate tables<\/li>\n<li>Build Warehouse tables<\/li>\n<\/ol>\n<p>And this works for DataMart where they are a denormalized copy of a single source system, but when the source system, or the intermediate tables, are used multiple times, you don&#8217;t want to run them multiple times. Equally\u00a0I don&#8217;t want to figure this out each time we\u00a0add a new package.<\/p>\n<p>I basically want a controller task that manages it.<\/p>\n<p>We have a automation build\\deploy process, \u00a0so you commit the (SSDT\\SSIS\\SSAS) packages and it deploys it and creates a SQL job for each SSIS package. We could add step to trigger the controller to update the schedules based on the change.<\/p>\n<p>Now we would need to define the dependencies, basically we need build a hierarchy. Technically I could read the SSIS packages then parse the select statements then create some logic to work it out automatically, but for now, it&#8217;ll be a static table(s).<\/p>\n<p>So. Do I create a SQL stored procedure to create a SQL job(s) with multiple steps or a SSIS package using something like BIML?<\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 09 Feb 2016 14:24:44 +0000","created_by":1,"updated_at":"Tue, 09 Feb 2016 14:24:44 +0000","updated_by":1,"published_at":"Tue, 09 Feb 2016 14:24:44 +0000","published_by":1},{"id":573,"title":"Web hosting renewal","slug":"web-hosting-renewal","markdown":"\nOne of the bad habbits I have picked up from working in Local Government is reviewing your options, regularly. As I approach my renewal for this site\u2019s web hosting, I decided to revaluate the market.\n\n(Short version,\u00a0I\u2019m with\u00a0[Mythic-Beasts](https:\/\/mythic-beasts.com)\u00a0for another year)\n\nCurrently, I have the site hosted with [Mythic-Beasts](https:\/\/mythic-beasts.com). They are pretty cool folks, unfortantely one of there DC had a power cut recently \u2013 ok, only a few hours and I pay peanuts so I don\u2019t expect much in terms of reduancy or fancy SLAs, but it did make me look at my options for a bit longer then normal.\n\nRecently, I discovered\u00a0[Project Nami](http:\/\/projectnami.org\/), a fork of WordPress that replaces the MySQL database with MS-SQL (which I quite like). As you would expect, its bundled really nice for [Azure](https:\/\/azure.microsoft.com\/en-gb\/). I setup a quick test site on\u00a0[Azure](https:\/\/azure.microsoft.com\/en-gb\/)\u00a0and had a play, it worked a exceedingly well, but the lack of IPv6 left me with a bitter taste. Why hasn\u2019t Microsoft added support for IPv6! This would mean I would have to use [CloudFlare](https:\/\/www.cloudflare.com\/), which isn\u2019t exactly a problem. The summary outcome was Azure was overly complex, I\u2019m not saying Microsoft hasn\u2019t done a excellent job making it simple to setup and use, its just its overly complex for what I want, my content is static. Again,\u00a0[Project Nami](http:\/\/projectnami.org\/)\u00a0is excellent, its just, an extra complexity.\u00a0[CloudFlare](https:\/\/www.cloudflare.com\/), I\u2019m still 50\/50 on. I have another site using\u00a0[CloudFlare](https:\/\/www.cloudflare.com\/)\u00a0and I\u2019ve had no problem, its just, again, its\u00a0overly complex solution to simple problem. Lots of bells and whistles.\n\nGoing the other way, I looked at [WordPress.com](https:\/\/www.wordpress.com). This would the similest solution, but that comes at a price, at nearly 3x times the cost per year and alot more restrictions \u2013 no PowerBI iframes (well they haven\u2019t added support\u2026 yet)*\n\nSo, now I\u2019m back to\u00a0[Mythic-Beasts](https:\/\/mythic-beasts.com), they have IPv6 support, are UK based, have excellent support, good value for money. They\u2019ve also added support for [LetsEncrypt](https:\/\/letsencrypt.org). So HTTPS is free and only a few clicks \u2013 something that you can do with Azure, but with a \u00a345 or above package. Sigh.\n\nIf nothing else this \u201cforced\u201d me to look at\u00a0[Project Nami](http:\/\/projectnami.org\/)\u00a0and look deeper into\u00a0[Azure](https:\/\/azure.microsoft.com\/en-gb\/).\u00a0[Azure](https:\/\/azure.microsoft.com\/en-gb\/)\u00a0is a pretty big beast thats getting bigger by the day. I\u2019ve also reconfigured a few bits on my websites on\u00a0[Mythic-Beasts](https:\/\/mythic-beasts.com)\u00a0(I still have a few things left to do!), so as always, it was worth reviewing the market.\n\n* Yes, I am aware I haven\u2019t published any public PowerBI reports\u2026 yet!\n\n\n","html":"<p>One of the bad habbits I have picked up from working in Local Government is reviewing your options, regularly. As I approach my renewal for this site&#8217;s web hosting, I decided to revaluate the market.<\/p>\n<p>(Short version,\u00a0I&#8217;m with\u00a0<a href=\"https:\/\/mythic-beasts.com\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a>\u00a0for another year)<\/p>\n<p>Currently, I have the site hosted with <a href=\"https:\/\/mythic-beasts.com\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a>. They are pretty cool folks, unfortantely one of there DC had a power cut recently &#8211; ok, only a few hours and I pay peanuts so I don&#8217;t expect much in terms of reduancy or fancy SLAs, but it did make me look at my options for a bit longer then normal.<\/p>\n<p>Recently, I discovered\u00a0<a href=\"http:\/\/projectnami.org\/\" target=\"_blank\" rel=\"nofollow\">Project Nami<\/a>, a fork of WordPress that replaces the MySQL database with MS-SQL (which I quite like). As you would expect, its bundled really nice for <a href=\"https:\/\/azure.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Azure<\/a>. I setup a quick test site on\u00a0<a href=\"https:\/\/azure.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Azure<\/a>\u00a0and had a play, it worked a exceedingly well, but the lack of IPv6 left me with a bitter taste. Why hasn&#8217;t Microsoft added support for IPv6! This would mean I would have to use <a href=\"https:\/\/www.cloudflare.com\/\" target=\"_blank\" rel=\"nofollow\">CloudFlare<\/a>, which isn&#8217;t exactly a problem. The summary outcome was Azure was overly complex, I&#8217;m not saying Microsoft hasn&#8217;t done a excellent job making it simple to setup and use, its just its overly complex for what I want, my content is static. Again,\u00a0<a href=\"http:\/\/projectnami.org\/\" target=\"_blank\" rel=\"nofollow\">Project Nami<\/a>\u00a0is excellent, its just, an extra complexity.\u00a0<a href=\"https:\/\/www.cloudflare.com\/\" target=\"_blank\" rel=\"nofollow\">CloudFlare<\/a>, I&#8217;m still 50\/50 on. I have another site using\u00a0<a href=\"https:\/\/www.cloudflare.com\/\" target=\"_blank\" rel=\"nofollow\">CloudFlare<\/a>\u00a0and I&#8217;ve had no problem, its just, again, its\u00a0overly complex solution to simple problem. Lots of bells and whistles.<\/p>\n<p>Going the other way, I looked at <a href=\"https:\/\/www.wordpress.com\" target=\"_blank\" rel=\"nofollow\">WordPress.com<\/a>. This would the similest solution, but that comes at a price, at nearly 3x times the cost per year and alot more restrictions &#8211; no PowerBI iframes (well they haven&#8217;t added support&#8230; yet)*<\/p>\n<p>So, now I&#8217;m back to\u00a0<a href=\"https:\/\/mythic-beasts.com\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a>, they have IPv6 support, are UK based, have excellent support, good value for money. They&#8217;ve also added support for <a href=\"https:\/\/letsencrypt.org\" target=\"_blank\" rel=\"nofollow\">LetsEncrypt<\/a>. So HTTPS is free and only a few clicks &#8211; something that you can do with Azure, but with a \u00a345 or above package. Sigh.<\/p>\n<p>If nothing else this &#8220;forced&#8221; me to look at\u00a0<a href=\"http:\/\/projectnami.org\/\" target=\"_blank\" rel=\"nofollow\">Project Nami<\/a>\u00a0and look deeper into\u00a0<a href=\"https:\/\/azure.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Azure<\/a>.\u00a0<a href=\"https:\/\/azure.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Azure<\/a>\u00a0is a pretty big beast thats getting bigger by the day. I&#8217;ve also reconfigured a few bits on my websites on\u00a0<a href=\"https:\/\/mythic-beasts.com\" target=\"_blank\" rel=\"nofollow\">Mythic-Beasts<\/a>\u00a0(I still have a few things left to do!), so as always, it was worth reviewing the market.<\/p>\n<p>* Yes, I am aware I haven&#8217;t published any public PowerBI reports&#8230; yet!<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 13 Feb 2016 22:00:00 +0000","created_by":1,"updated_at":"Sun, 14 Feb 2016 23:17:45 +0000","updated_by":1,"published_at":"Sat, 13 Feb 2016 22:00:00 +0000","published_by":1},{"id":621,"title":"Showing SIMS Bulk Import some love","slug":"showing-sims-bulk-import-some-love","markdown":"\n> Missus decided to dye her hair, so spent the time moving from [@teamcity](https:\/\/twitter.com\/teamcity) on [@Azure](https:\/\/twitter.com\/Azure) vm to [@appveyor](https:\/\/twitter.com\/appveyor) for [@simsbulkimport](https:\/\/twitter.com\/simsbulkimport)\n> \n> \u2014 Matt Smith (@matt40k) [February 14, 2016](https:\/\/twitter.com\/matt40k\/status\/698912438150938628)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\nSo today I managed to move [SIMS Bulk Import](https:\/\/simsbulkimport.uk) over to\u00a0[Appveyor](http:\/\/www.appveyor.com\/). So what does this mean? Well it means I don\u2019t have to worry about going over my Azure credit limit each month for starters!\u00a0[Appveyor](http:\/\/www.appveyor.com\/)\u00a0has excellent support for [GitHub](https:\/\/GitHub.com), so each commit is automatically build, tested, and (when I enable it) a new release created.\n\nThe next release will include\n\n- Pupil username creation \u2013 you can blame\\thank\u00a0[Andrew Mulholland](https:\/\/twitter.com\/gbaman1)\u00a0for this, I saw his project PiNet and thought [we can make this better](http:\/\/pinet.org.uk\/articles\/manage-users\/csv-import.html).\n- PowerShell module \u2013 you can blame\\thank\u00a0[Ryan Yates](https:\/\/twitter.com\/ryanyates1990)\u00a0for making me want to do this one\n- Log submission \u2013 I\u2019ve finally started pull this together, I\u2019ve\u00a0desensitised the log file by basically creating two. One for log submissions and other for local debugging. The main issue is testing, both the web service and the application.\n\n\n","html":"<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">Missus decided to dye her hair, so spent the time moving from <a href=\"https:\/\/twitter.com\/teamcity\" target=\"_blank\" rel=\"nofollow\">@teamcity<\/a> on <a href=\"https:\/\/twitter.com\/Azure\" target=\"_blank\" rel=\"nofollow\">@Azure<\/a> vm to <a href=\"https:\/\/twitter.com\/appveyor\" target=\"_blank\" rel=\"nofollow\">@appveyor<\/a> for <a href=\"https:\/\/twitter.com\/simsbulkimport\" target=\"_blank\" rel=\"nofollow\">@simsbulkimport<\/a><\/p>\n<p>&mdash; Matt Smith (@matt40k) <a href=\"https:\/\/twitter.com\/matt40k\/status\/698912438150938628\" target=\"_blank\" rel=\"nofollow\">February 14, 2016<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>So today I managed to move <a href=\"https:\/\/simsbulkimport.uk\" target=\"_blank\" rel=\"nofollow\">SIMS Bulk Import<\/a> over to\u00a0<a href=\"http:\/\/www.appveyor.com\/\" target=\"_blank\" rel=\"nofollow\">Appveyor<\/a>. So what does this mean? Well it means I don&#8217;t have to worry about going over my Azure credit limit each month for starters!\u00a0<a href=\"http:\/\/www.appveyor.com\/\" target=\"_blank\" rel=\"nofollow\">Appveyor<\/a>\u00a0has excellent support for <a href=\"https:\/\/GitHub.com\" target=\"_blank\" rel=\"nofollow\">GitHub<\/a>, so each commit is automatically build, tested, and (when I enable it) a new release created.<\/p>\n<p>The next release will include<\/p>\n<ul>\n<li>Pupil username creation &#8211; you can blame\\thank\u00a0<a href=\"https:\/\/twitter.com\/gbaman1\" target=\"_blank\" rel=\"nofollow\">Andrew Mulholland<\/a>\u00a0for this, I saw his project PiNet and thought <a href=\"http:\/\/pinet.org.uk\/articles\/manage-users\/csv-import.html\" target=\"_blank\" rel=\"nofollow\">we can make this better<\/a>.<\/li>\n<li>PowerShell module &#8211; you can blame\\thank\u00a0<a href=\"https:\/\/twitter.com\/ryanyates1990\" target=\"_blank\" rel=\"nofollow\">Ryan Yates<\/a>\u00a0for making me want to do this one<\/li>\n<li>Log submission &#8211; I&#8217;ve finally started pull this together, I&#8217;ve\u00a0desensitised the log file by basically creating two. One for log submissions and other for local debugging. The main issue is testing, both the web service and the application.<\/li>\n<\/ul>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 14 Feb 2016 23:32:41 +0000","created_by":1,"updated_at":"Sun, 14 Feb 2016 23:33:14 +0000","updated_by":1,"published_at":"Sun, 14 Feb 2016 23:32:41 +0000","published_by":1},{"id":646,"title":"Building a test system","slug":"building-a-test-system","markdown":"\nSo eariler this month I switched from\u00a0my [Azure](https:\/\/azure.microsoft.com\/en-gb\/) hosted [TeamCity](https:\/\/www.jetbrains.com\/teamcity) server to [Appveyor](https:\/\/www.appveyor.com), which freed up some much need\u00a0[Azure](https:\/\/azure.microsoft.com\/en-gb\/)\u00a0credit. This month, it looks like its going to be going on a [Visual Studio Ultimate vm for some SharePoint development](https:\/\/blogs.msdn.microsoft.com\/visualstudio\/2015\/01\/08\/azure-virtual-machine-images-for-visual-studio\/). Hopefully this won\u2019t take too long to do as I really want to get on with machine learning after a demo from [Ric Howe](https:\/\/twitter.com\/ijanric).\n\nI\u2019m also looking at building a few test machines locally \u2013 old school I know! I found this\u00a0article on\u00a0[Oxford SBS Guy](http:\/\/www.oxfordsbsguy.com\/ \"Oxford SBS Guy\")\u00a0really useful for building the template image.\n\n\n","html":"<p>So eariler this month I switched from\u00a0my <a href=\"https:\/\/azure.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Azure<\/a> hosted <a href=\"https:\/\/www.jetbrains.com\/teamcity\" target=\"_blank\" rel=\"nofollow\">TeamCity<\/a> server to <a href=\"https:\/\/www.appveyor.com\" target=\"_blank\" rel=\"nofollow\">Appveyor<\/a>, which freed up some much need\u00a0<a href=\"https:\/\/azure.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">Azure<\/a>\u00a0credit. This month, it looks like its going to be going on a <a href=\"https:\/\/blogs.msdn.microsoft.com\/visualstudio\/2015\/01\/08\/azure-virtual-machine-images-for-visual-studio\/\" target=\"_blank\" rel=\"nofollow\">Visual Studio Ultimate vm for some SharePoint development<\/a>. Hopefully this won&#8217;t take too long to do as I really want to get on with machine learning after a demo from <a href=\"https:\/\/twitter.com\/ijanric\" target=\"_blank\" rel=\"nofollow\">Ric Howe<\/a>.<\/p>\n<p>I&#8217;m also looking at building a few test machines locally &#8211; old school I know! I found this\u00a0article on\u00a0<a title=\"Oxford SBS Guy\" href=\"http:\/\/www.oxfordsbsguy.com\/\" rel=\"home\" target=\"_blank\" rel=\"nofollow\">Oxford SBS Guy<\/a>\u00a0really useful for building the template image.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 20 Feb 2016 20:47:09 +0000","created_by":1,"updated_at":"Wed, 24 Feb 2016 20:34:38 +0000","updated_by":1,"published_at":"Sat, 20 Feb 2016 20:47:09 +0000","published_by":1},{"id":670,"title":"Visual Studio SSIS error","slug":"temp-slug-61","markdown":"\n[![error-ssis](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/03\/error-ssis-300x81.png?fit=300%2C81&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/03\/error-ssis.png?ssl=1)\n\n\n","html":"<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/03\/error-ssis.png?ssl=1\" rel=\"attachment wp-att-671\"><img src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/03\/error-ssis-300x81.png?fit=300%2C81&#038;ssl=1\" alt=\"error-ssis\" class=\"alignnone size-medium wp-image-671\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/03\/error-ssis.png?resize=300%2C81&amp;ssl=1 300w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/03\/error-ssis.png?resize=648%2C176&amp;ssl=1 648w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/03\/error-ssis.png?resize=583%2C158&amp;ssl=1 583w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/03\/error-ssis.png?w=723&amp;ssl=1 723w\" sizes=\"(max-width: 300px) 100vw, 300px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 21 Mar 2016 08:12:17 +0000","created_by":1,"updated_at":"Mon, 21 Mar 2016 08:12:17 +0000","updated_by":1,"published_at":"","published_by":1},{"id":673,"title":"Auditing - SSAS","slug":"auditing-ssas","markdown":"\nThere are various types of Auditing in the\u00a0Microsoft BI stack. There is auditing in SSRS, SharePoint, SSAS and not forgetting SQL has its own auditing.\n\nToday I am looking at the SSAS auditing \u2013 you can find out more about it on [TechNet](https:\/\/technet.microsoft.com\/en-us\/library\/cc917676.aspx).\n\n[Olaf Helper](https:\/\/gallery.technet.microsoft.com\/scriptcenter\/Basic-OlapQueryLog-Analysis-20ba455d) has published some TSQL code for querying the audit data -on the [Script Center](https:\/\/gallery.technet.microsoft.com\/scriptcenter\/Basic-OlapQueryLog-Analysis-20ba455d).\n\nBut first, we need a table to store the data, here is a TSQL script for creating the table:\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/5e0ce19d66216a25be02.json\"><\/div>\u00a0\n\n\n","html":"<p>There are various types of Auditing in the\u00a0Microsoft BI stack. There is auditing in SSRS, SharePoint, SSAS and not forgetting SQL has its own auditing.<\/p>\n<p>Today I am looking at the SSAS auditing &#8211; you can find out more about it on <a href=\"https:\/\/technet.microsoft.com\/en-us\/library\/cc917676.aspx\" target=\"_blank\" rel=\"nofollow\">TechNet<\/a>.<\/p>\n<p><a href=\"https:\/\/gallery.technet.microsoft.com\/scriptcenter\/Basic-OlapQueryLog-Analysis-20ba455d\" target=\"_blank\" rel=\"nofollow\">Olaf Helper<\/a> has published some TSQL code for querying the audit data -on the <a href=\"https:\/\/gallery.technet.microsoft.com\/scriptcenter\/Basic-OlapQueryLog-Analysis-20ba455d\" target=\"_blank\" rel=\"nofollow\">Script Center<\/a>.<\/p>\n<p>But first, we need a table to store the data, here is a TSQL script for creating the table:<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/5e0ce19d66216a25be02.json\"><\/div>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 26 Mar 2016 23:30:16 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:10:04 +0000","updated_by":1,"published_at":"Sat, 26 Mar 2016 23:30:16 +0000","published_by":1},{"id":693,"title":"Visual Studio 2015 for BI","slug":"temp-slug-63","markdown":"\n[![ssismulti](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/ssismulti-300x166.png?fit=300%2C166&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/ssismulti.png?ssl=1)\n\n[![vs2015ssas](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas-300x56.png?fit=300%2C56&ssl=1)1200](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas.png?ssl=1)\n\n.asdatabasea>\n\n\n","html":"<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/ssismulti.png?ssl=1\" rel=\"attachment wp-att-694\"><img src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/ssismulti-300x166.png?fit=300%2C166&#038;ssl=1\" alt=\"ssismulti\" class=\"alignnone size-medium wp-image-694\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/ssismulti.png?resize=300%2C166&amp;ssl=1 300w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/ssismulti.png?resize=768%2C425&amp;ssl=1 768w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/ssismulti.png?resize=648%2C359&amp;ssl=1 648w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/ssismulti.png?resize=347%2C192&amp;ssl=1 347w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/ssismulti.png?w=862&amp;ssl=1 862w\" sizes=\"(max-width: 300px) 100vw, 300px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas.png?ssl=1\" rel=\"attachment wp-att-695\"><img src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas-300x56.png?fit=300%2C56&#038;ssl=1\" alt=\"vs2015ssas\" class=\"alignnone size-medium wp-image-695\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas.png?resize=300%2C56&amp;ssl=1 300w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas.png?resize=768%2C143&amp;ssl=1 768w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas.png?resize=1024%2C191&amp;ssl=1 1024w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas.png?resize=648%2C121&amp;ssl=1 648w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas.png?resize=583%2C109&amp;ssl=1 583w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/04\/vs2015ssas.png?w=1169&amp;ssl=1 1169w\" sizes=\"(max-width: 300px) 100vw, 300px\" data-recalc-dims=\"1\" \/>1200<\/p>\n<p>.asdatabasea><\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 04 Apr 2016 17:09:35 +0000","created_by":1,"updated_at":"Mon, 04 Apr 2016 17:09:35 +0000","updated_by":1,"published_at":"","published_by":1},{"id":729,"title":"Auditing - Who's viewed my record?","slug":"auditing-whos-viewed-my-record","markdown":"\nAs some of you are aware I currently working for a local authority and anyone who has been following local government news in England will know the bonds between local authority and the health authority, aka the NHS, are growing. As are other parts of the government for that matter, both central, other local authorities as well as charities, but for now, I am focusing on the health part. Specifically the part around what that means. Health data has much stricter rules, the data is no more sensitive then some data already held by the local authority in my opinion. Perhaps, they are perceived as stricter when in fact they are, more evolved. Sharing health data is a lot more common nowadays, it\u2019s more defined, it\u2019s been through the growing pains (boy has the NHS had some IT growing pains) and has grown into stable mature process. This is of course making the local authority sound bad, it isn\u2019t, they have been quietly learning from its elder brother, observing what has gone wrong and using the things that have gone right. There is however, still too much manual spreadsheets occurring, it\u2019s a long road and but progress is being made.\n\nSo with the new business intelligence platform being developed, we need to review our existing platform, for this post, I\u2019m talking (well writing) about auditing. Auditing on old platform was enabled. But it wasn\u2019t really auditing. It was usage. It had a business focus.\u00a0\n\n- What? Reports \/ Users\n- When? When was it run\n- Why? Was it worth writing the report\n\nOn the new platform we need true auditing. We almost need the same level of auditing as banks. BI is however, read-only, our auditing requirement needs to only be reactive, we don\u2019t need to define triggers on the data to kick off workflow. We can get away with running an ETL job to extract the audit logs and transform it into a standard star fact\/dimensions data structure.\n\nThe solution I have design for us, is to use the uber fast multi dimensional cube for analysis (which is what it designed for) and Reporting Services (SSRS) using raw T-SQL for detail. Sensitive data is not placed in the cube. The idea is cube has numbers with the ability to slice and dice using a variety of items (dimensions) \u2013 to a certain point. So for example, say there are 50 children in care, you could then slice this by gender, then by age group, then by ethnicity and so on. This data in itself isn\u2019t sensitive. If you print this off and left it on a train, what would happen? Not much. This data is often published by the government and quoted by charities. NB: A word of warning however, a direct link into the raw system can be a dangerous things. Entering data is prone to mistakes and giving direct access will remove the quality gate data stewards provide, that said more prompt data more frequently, even with a few mistakes is often going to be better then out-of-date.\n\nThis leads me up to the detail. The detail allows a select few to go beyond those numbers, to drill into those numbers into a SSRS report. Now, one of the nice abilities of having an on-prem BI platform is we can store the raw uncut original data from the source system. This means we can work our way down to the bottom grain of data. Which makes debugging and testing a lot easier. It however make the definition of what is sensitive a lot harder. It sounds simple, but it can get rather messy when you get down to the nitty gritty. This nitty gritty gets audited. It gets audited using the standard Audit feature in SQL Server which has been a part of SQL Server since 2008 version. This has, from what I\u2019ve seen from UAT, reading and talking to others, provided a low performance impact binary file audit log. This in turn gets ETL via a SSIS package into warehouse. They was a little design consideration round the to-be audited star schema, luckily the sensitive fields were already in one dimension and bit of ETL magic to make it a bit more bulletproof.\n\nThe end result. The business controls access for users to self-serve data analysis, in near realtime, without buying a license, in short they can give users access without access to the raw data. The business can use the same tools and drill down to the raw data. Access to the raw is fully audited and can be reported on by the business so we can be held accountable. It\u2019s all about trust.\n\n\n","html":"<p>As some of you are aware I currently working for a local authority and anyone who has been following local government news in England will know the bonds between local authority and the health authority, aka the NHS, are growing. As are other parts of the government for that matter, both central, other local authorities as well as charities, but for now, I am focusing on the health part. Specifically the part around what that means. Health data has much stricter rules, the data is no more sensitive then some data already held by the local authority in my opinion. Perhaps, they are perceived as stricter when in fact they are, more evolved. Sharing health data is a lot more common nowadays, it&#8217;s more defined, it&#8217;s been through the growing pains (boy has the NHS had some IT growing pains) and has grown into stable mature process. This is of course making the local authority sound bad, it isn&#8217;t, they have been quietly learning from its elder brother, observing what has gone wrong and using the things that have gone right. There is however, still too much manual spreadsheets occurring, it&#8217;s a long road and but progress is being made.<\/p>\n<p>So with the new business intelligence platform being developed, we need to review our existing platform, for this post, I&#8217;m talking (well writing) about auditing. Auditing on old platform was enabled. But it wasn&#8217;t really auditing. It was usage. It had a business focus.&nbsp;<\/p>\n<ul>\n<li>What? Reports \/ Users<\/li>\n<li>When? When was it run<\/li>\n<li>Why? Was it worth writing the report<\/li>\n<\/ul>\n<p>On the new platform we need true auditing. We almost need the same level of auditing as banks. BI is however, read-only, our auditing requirement needs to only be reactive, we don&#8217;t need to define triggers on the data to kick off workflow. We can get away with running an ETL job to extract the audit logs and transform it into a standard star fact\/dimensions data structure.<\/p>\n<p>The solution I have design for us, is to use the uber fast multi dimensional cube for analysis (which is what it designed for) and Reporting Services (SSRS) using raw T-SQL for detail. Sensitive data is not placed in the cube. The idea is cube has numbers with the ability to slice and dice using a variety of items (dimensions) &#8211; to a certain point. So for example, say there are 50 children in care, you could then slice this by gender, then by age group, then by ethnicity and so on. This data in itself isn&#8217;t sensitive. If you print this off and left it on a train, what would happen? Not much. This data is often published by the government and quoted by charities. NB: A word of warning however, a direct link into the raw system can be a dangerous things. Entering data is prone to mistakes and giving direct access will remove the quality gate data stewards provide, that said more prompt data more frequently, even with a few mistakes is often going to be better then out-of-date.<\/p>\n<p>This leads me up to the detail. The detail allows a select few to go beyond those numbers, to drill into those numbers into a SSRS report. Now, one of the nice abilities of having an on-prem BI platform is we can store the raw uncut original data from the source system. This means we can work our way down to the bottom grain of data. Which makes debugging and testing a lot easier. It however make the definition of what is sensitive a lot harder. It sounds simple, but it can get rather messy when you get down to the nitty gritty. This nitty gritty gets audited. It gets audited using the standard Audit feature in SQL Server which has been a part of SQL Server since 2008 version. This has, from what I&#8217;ve seen from UAT, reading and talking to others, provided a low performance impact binary file audit log. This in turn gets ETL via a SSIS package into warehouse. They was a little design consideration round the to-be audited star schema, luckily the sensitive fields were already in one dimension and bit of ETL magic to make it a bit more bulletproof.<\/p>\n<p>The end result. The business controls access for users to self-serve data analysis, in near realtime, without buying a license, in short they can give users access without access to the raw data. The business can use the same tools and drill down to the raw data. Access to the raw is fully audited and can be reported on by the business so we can be held accountable. It&#8217;s all about trust.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 06 Apr 2016 00:22:09 +0000","created_by":1,"updated_at":"Wed, 06 Apr 2016 00:22:09 +0000","updated_by":1,"published_at":"Wed, 06 Apr 2016 00:22:09 +0000","published_by":1},{"id":731,"title":"The connection is broken and recovery is not possible","slug":"the-connection-is-broken-and-recovery-is-not-possible","markdown":"\n> Msg 0, Level 11, State 0, Line 0\n> \n> The connection is broken and recovery is not possible.\u00a0 The client driver attempted to recover the connection one or more times and all attempts failed.\u00a0 Increase the value of ConnectRetryCount to increase the number of recovery attempts.\n\nIn short, you\u2019ve lost your network connection, either your WiFi has dropped out or your network cable has \ud83d\ude42\n\n\n","html":"<blockquote><p>Msg 0, Level 11, State 0, Line 0<\/p>\n<p>The connection is broken and recovery is not possible.\u00a0 The client driver attempted to recover the connection one or more times and all attempts failed.\u00a0 Increase the value of ConnectRetryCount to increase the number of recovery attempts.<\/p><\/blockquote>\n<p>In short, you&#8217;ve lost your network connection, either your WiFi has dropped out or your network cable has \ud83d\ude42<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 20 Apr 2016 21:06:30 +0000","created_by":1,"updated_at":"Wed, 20 Apr 2016 21:06:30 +0000","updated_by":1,"published_at":"Wed, 20 Apr 2016 21:06:30 +0000","published_by":1},{"id":739,"title":"SQL Compare failed","slug":"sql-compare-failed","markdown":"\nAnother day, another problem. Todays problem was incorrect column length which was causing a SSIS package to fail. Historically I use a freeware tool to compare the different environments schema, but lately I just don\u2019t bother, I have continuous deployment so its easier just to hit the deploy button then it is to try and figure it out. Well today I decided I wanted to it old school \u2013 although I\u2019ve been using the SSDT SQL compare in my deployments, I\u2019ve not actually used it in terms of viewing the differences.\n\nDoing so its pretty easy, I already have a my database project setup in Visual Studio, all I then did was right-click then Schema Compare\u2026\n\nThe app will then open and you select, from the right hand menu, the target, the database you want to compare your project with. Then you just click the compare button.\n\nThis appeared to work but didn\u2019t display any results. When you look at the bottom status bar it reads\n\n> Comparison complete. No differences detected. Restricted comparison. See Error List for details.\n\nI knew there we at least some differences. I then click on the Error List table below it which revealed\n\n> The reverse engineering operation cannot continue because you do not have View Definition permission on the \u2018Warehouse\u2019\n\nGoogling the problem lead me to a number of recommendations, some didn\u2019t work (like restricting it to only tables), others I didn\u2019t want to do\u00a0\u2013 I don\u2019t want to give myself\u00a0db_owner on production.\u00a0The final solution came as a simple one liner\n\n`GRANT\u00a0VIEW\u00a0Definition\u00a0TO\u00a0[DOMAIN\\user]`\n\nJust added it to my Database Project as Post-Deployment script and its now comparing ok within Visual Studio (SSDT).\n\n\n","html":"<p>Another day, another problem. Todays problem was incorrect column length which was causing a SSIS package to fail. Historically I use a freeware tool to compare the different environments schema, but lately I just don&#8217;t bother, I have continuous deployment so its easier just to hit the deploy button then it is to try and figure it out. Well today I decided I wanted to it old school &#8211; although I&#8217;ve been using the SSDT SQL compare in my deployments, I&#8217;ve not actually used it in terms of viewing the differences.<\/p>\n<p>Doing so its pretty easy, I already have a my database project setup in Visual Studio, all I then did was right-click then Schema Compare&#8230;<\/p>\n<p>The app will then open and you select, from the right hand menu, the target, the database you want to compare your project with. Then you just click the compare button.<\/p>\n<p>This appeared to work but didn&#8217;t display any results. When you look at the bottom status bar it reads<\/p>\n<blockquote><p>Comparison complete. No differences detected. Restricted comparison. See Error List for details.<\/p><\/blockquote>\n<p>I knew there we at least some differences. I then click on the Error List table below it which revealed<\/p>\n<blockquote><p>The reverse engineering operation cannot continue because you do not have View Definition permission on the &#8216;Warehouse&#8217;<\/p><\/blockquote>\n<p>Googling the problem lead me to a number of recommendations, some didn&#8217;t work (like restricting it to only tables), others I didn&#8217;t want to do\u00a0&#8211; I don&#8217;t want to give myself\u00a0db_owner on production.\u00a0The final solution came as a simple one liner<\/p>\n<p><code>GRANT\u00a0VIEW\u00a0Definition\u00a0TO\u00a0[DOMAIN\\user]<\/code><\/p>\n<p>Just added it to my Database Project as Post-Deployment script and its now comparing ok within Visual Studio (SSDT).<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Thu, 12 May 2016 22:32:03 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:07:42 +0000","updated_by":1,"published_at":"Thu, 12 May 2016 22:32:03 +0000","published_by":1},{"id":743,"title":"Power BI","slug":"power-bi","markdown":"\nPower BI is a cloud-based business analytics service that helps create live operational dashboards from on-premises and cloud data in one central location that you can access across a range of devices. Power BI helps you stay up to date with the information that matters to you. You can connect to multiple datasets to bring all of the relevant data together in one place. With Power BI, dashboards help you keep a finger on the pulse of your business. Your dashboards display tiles that you can click to explore further with reports.\n\nPower BI Desktop puts visual analytics at your fingertips with intuitive report authoring. You can drag-and-drop to place content exactly where you want it on the flexible and fluid canvas. Quickly discover patterns as you explore a single unified view of linked, interactive visualizations.\n\nTo top it off, stay connected to your data from anywhere, anytime with the Power BI app for Windows, iOS, and Android. Get a 360\u00b0 view of your business data on the go \u2013 at the touch of your fingertips.\n\n\n","html":"<p>Power BI is a cloud-based business analytics service that helps create live operational dashboards from on-premises and cloud data in one central location that you can access across a range of devices. Power BI helps you stay up to date with the information that matters to you. You can connect to multiple datasets to bring all of the relevant data together in one place. With Power BI, dashboards help you keep a finger on the pulse of your business. Your dashboards display tiles that you can click to explore further with reports.<\/p>\n<p>Power BI Desktop puts visual analytics at your fingertips with intuitive report authoring. You can drag-and-drop to place content exactly where you want it on the flexible and fluid canvas. Quickly discover patterns as you explore a single unified view of linked, interactive visualizations.<\/p>\n<p>To top it off, stay connected to your data from anywhere, anytime with the Power BI app for Windows, iOS, and Android. Get a 360\u00b0 view of your business data on the go &#8211; at the touch of your fingertips.<\/p>\n","image":null,"featured":0,"page":1,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 01 Jun 2016 08:20:18 +0000","created_by":1,"updated_at":"Wed, 01 Jun 2016 08:23:30 +0000","updated_by":1,"published_at":"Wed, 01 Jun 2016 08:20:18 +0000","published_by":1},{"id":746,"title":"Power BI - custom visuals","slug":"power-bi-custom-visuals","markdown":"\nPower BI is Microsoft new cloud based Business Intelligence platform, one of the cool things about it is it built atop internet standards and leveraging open source libraries like [D3.js](https:\/\/d3js.org\/) for its visuals. Microsoft has continued on the path of open source-ness by [open sourcing](https:\/\/github.com\/Microsoft\/PowerBI-visuals) some of its codes allowing Joe Public to [submit custom visuals to Power-BI](https:\/\/github.com\/Microsoft\/PowerBI-visuals), all via [GitHub](https:\/\/github.com\/Microsoft\/PowerBI-visuals).\n\nYesterday saw the introduction of 4 new visuals, one in particular looked very interesting \u2013\u00a0[Hierarchy Slicer](https:\/\/app.powerbi.com\/visuals\/show\/HierarchySlicer1458836712039)\u00a0by [Jan Pieter Posthuma](https:\/\/twitter.com\/jppp).  \n[![Hierarchy Slicer](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/Cj2NG1EXAAA8cAh.jpg?fit=220%2C176&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/Cj2NG1EXAAA8cAh.jpg?ssl=1)This brings in some more missing features into [Power-BI](https:\/\/powerbi.microsoft.com). For more information on [Hierarchy Slicer visit his blog](http:\/\/azurebi.jppp.org\/2016\/04\/02\/power-bi-hierarchy-slicer\/).\n\nThe other one worth a mention \u2013 as it adds some comedy to any report is the\u00a0<span style=\"line-height: 1.75;\">[Meme](https:\/\/app.powerbi.com\/visuals\/show\/Meme1464101143173)\u00a0visual by\u00a0[Sachin Patney](https:\/\/github.com\/spatney).<\/span>\n\n<span style=\"line-height: 1.75;\">[![Meme](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/Cj05NcVXAAAth1F.jpg?fit=246%2C295&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/Cj05NcVXAAAth1F.jpg?ssl=1)<\/span>\n\nIf \u00a0your interesting in learning more about Custom Visuals,\u00a0[Marco Russo](http:\/\/www.sqlbi.com\/articles\/author\/marco-russo\/) is speaking at\u00a0the [London Power BI User Group](http:\/\/www.meetup.com\/London-PUG\/) where is is going to talk about [Using Custom Visuals in Power BI](https:\/\/skillsmatter.com\/meetups\/8107-power-bi-meetup).\n\n\n","html":"<p>Power BI is Microsoft new cloud based Business Intelligence platform, one of the cool things about it is it built atop internet standards and leveraging open source libraries like <a href=\"https:\/\/d3js.org\/\" target=\"_blank\" rel=\"nofollow\">D3.js<\/a> for its visuals. Microsoft has continued on the path of open source-ness by <a href=\"https:\/\/github.com\/Microsoft\/PowerBI-visuals\" target=\"_blank\" rel=\"nofollow\">open sourcing<\/a> some of its codes allowing Joe Public to <a href=\"https:\/\/github.com\/Microsoft\/PowerBI-visuals\" target=\"_blank\" rel=\"nofollow\">submit custom visuals to Power-BI<\/a>, all via <a href=\"https:\/\/github.com\/Microsoft\/PowerBI-visuals\" target=\"_blank\" rel=\"nofollow\">GitHub<\/a>.<\/p>\n<p>Yesterday saw the introduction of 4 new visuals, one in particular looked very interesting &#8211;\u00a0<a href=\"https:\/\/app.powerbi.com\/visuals\/show\/HierarchySlicer1458836712039\" target=\"_blank\" rel=\"nofollow\">Hierarchy Slicer<\/a>\u00a0by <a href=\"https:\/\/twitter.com\/jppp\" target=\"_blank\" rel=\"nofollow\">Jan Pieter Posthuma<\/a>.<br \/>\n<a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/Cj2NG1EXAAA8cAh.jpg?ssl=1\"><img class=\"aligncenter wp-image-747 size-full\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/Cj2NG1EXAAA8cAh.jpg?fit=220%2C176&#038;ssl=1\" alt=\"Hierarchy Slicer\" data-recalc-dims=\"1\" \/><\/a>This brings in some more missing features into <a href=\"https:\/\/powerbi.microsoft.com\" target=\"_blank\" rel=\"nofollow\">Power-BI<\/a>. For more information on <a href=\"http:\/\/azurebi.jppp.org\/2016\/04\/02\/power-bi-hierarchy-slicer\/\" target=\"_blank\" rel=\"nofollow\">Hierarchy Slicer visit his blog<\/a>.<\/p>\n<p>The other one worth a mention &#8211; as it adds some comedy to any report is the\u00a0<span style=\"line-height: 1.75;\"><a href=\"https:\/\/app.powerbi.com\/visuals\/show\/Meme1464101143173\" target=\"_blank\" rel=\"nofollow\">Meme<\/a>\u00a0visual by\u00a0<a href=\"https:\/\/github.com\/spatney\" target=\"_blank\" rel=\"nofollow\">Sachin Patney<\/a>.<\/span><\/p>\n<p><span style=\"line-height: 1.75;\"><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/Cj05NcVXAAAth1F.jpg?ssl=1\"><img class=\"size-full wp-image-748 aligncenter\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/Cj05NcVXAAAth1F.jpg?fit=246%2C295&#038;ssl=1\" alt=\"Meme\" data-recalc-dims=\"1\" \/><\/a><\/span><\/p>\n<p>If \u00a0your interesting in learning more about Custom Visuals,\u00a0<a href=\"http:\/\/www.sqlbi.com\/articles\/author\/marco-russo\/\" target=\"_blank\" rel=\"nofollow\">Marco Russo<\/a> is speaking at\u00a0the <a href=\"http:\/\/www.meetup.com\/London-PUG\/\" target=\"_blank\" rel=\"nofollow\">London Power BI User Group<\/a> where is is going to talk about <a href=\"https:\/\/skillsmatter.com\/meetups\/8107-power-bi-meetup\" target=\"_blank\" rel=\"nofollow\">Using Custom Visuals in Power BI<\/a>.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 01 Jun 2016 08:57:38 +0000","created_by":1,"updated_at":"Wed, 01 Jun 2016 08:59:53 +0000","updated_by":1,"published_at":"Wed, 01 Jun 2016 08:57:38 +0000","published_by":1},{"id":734,"title":"SQL Server vs Containers","slug":"sql-server-vs-containers","markdown":"\nI was at event that\u00a0[Simon Sabin](https:\/\/twitter.com\/simon_sabin)\u00a0arranged,\u00a0[SQL SERVER TOOLS and SSDT shape the future](https:\/\/www.eventbrite.com\/e\/sql-server-tools-and-ssdt-shape-the-future-tickets-25256718525)\u00a0and one of the questions that was asked, sorry, I forgot who asked (joys of leaving it too long before blogging about it \u2013 I want to say [Gavin](https:\/\/twitter.com\/Gavin592)) was,\n\n> How does (Windows) Containers fit into SQL Server?\n\nThis is basically Microsoft integrating the Docker technology into the Windows OS, so you in effect, ship a more complete solution. So for example, traditionally you\u2019d ship the .NET application, with \u201cDocker\u201d you\u2019d ship .NET and the OS along with the application \u2013 its not quite right, but that\u2019s the basic idea.\n\nAt one of my local user groups, [Suffolk Devs, back in Sept 2015,\u00a0Richard Vickerstaff done a talk on Docker](http:\/\/www.meetup.com\/Suffolk-Developers\/events\/225341172\/). One of the things I took away was this was very dev friendly, Richard was honest in the fact he has yet to deploy to production in this manner and the general feedback from the room at the time was no one else had \u2013 this doesn\u2019t mean no-one has since of course, but you start to get the feeling the DBAs back home wouldn\u2019t be happy. The other thing was the dev nature of it, for example, when your developing, you don\u2019t want to be held back by \u201crules\u201d that protect data, it is after all, development, your not going to have production data in your dev environment, right? So, if you don\u2019t \u201cpin\u201d your storage to a persistent path, it\u2019ll get purge when you stop your docker image. Can you image if you forgot to set the production config correctly and come a reboot all your data disappears? I can already here my friendly DBA screaming.\n\nTo get a docker\\container for SQL Server, you\u2019d either have to select one from list of images with SQL Server and its going to be huge, at least until they get SQL Server 2016 on [Nano Server](https:\/\/blogs.technet.microsoft.com\/windowsserver\/2015\/04\/08\/microsoft-announces-nano-server-for-modern-apps-and-cloud\/). Or you\u2019d have to have PowerShell DSC to install and configure SQL Server.\n\nIn terms of Microsoft SQL Server, or really any database, I don\u2019t believe you\u2019d need to have it in a container, docker or otherwise. Since SQL Server 2012 you could have\u00a0contained databases, this is where the login information that is normally stored in the instance master database within the application database. This pretty much made database independent of each other within the same SQL Server instance. I\u2019d admit this was introduced for Azure, but this leads me onto my next point.\n\nThe best thing to manage is the the thing you don\u2019t have to manage. So why would you want to spend time setting up SQL Server (as developer), regardless of if its in a container if you can just click a button or run a script to auto provision a Azure DB? Surely if your developing anything new, which is going to use a SQL Server database, surely you should be aiming for Azure DB? Even if you\u2019re not, there aren\u2019t that many types of SQL Server,\u00a0you don\u2019t often run into dependency hell with SQL Server, none that justifies building individual containers, at least, in my opinion.\n\n\n","html":"<p>I was at event that\u00a0<a href=\"https:\/\/twitter.com\/simon_sabin\" target=\"_blank\" rel=\"nofollow\">Simon Sabin<\/a>\u00a0arranged,\u00a0<a href=\"https:\/\/www.eventbrite.com\/e\/sql-server-tools-and-ssdt-shape-the-future-tickets-25256718525\" target=\"_blank\" rel=\"nofollow\">SQL SERVER TOOLS and SSDT shape the future<\/a>\u00a0and one of the questions that was asked, sorry, I forgot who asked (joys of leaving it too long before blogging about it &#8211; I want to say <a href=\"https:\/\/twitter.com\/Gavin592\" target=\"_blank\" rel=\"nofollow\">Gavin<\/a>) was,<\/p>\n<blockquote><p>How does (Windows) Containers fit into SQL Server?<\/p><\/blockquote>\n<p>This is basically Microsoft integrating the Docker technology into the Windows OS, so you in effect, ship a more complete solution. So for example, traditionally you&#8217;d ship the .NET application, with &#8220;Docker&#8221; you&#8217;d ship .NET and the OS along with the application &#8211; its not quite right, but that&#8217;s the basic idea.<\/p>\n<p>At one of my local user groups, <a href=\"http:\/\/www.meetup.com\/Suffolk-Developers\/events\/225341172\/\" target=\"_blank\" rel=\"nofollow\">Suffolk Devs, back in Sept 2015,\u00a0Richard Vickerstaff done a talk on Docker<\/a>. One of the things I took away was this was very dev friendly, Richard was honest in the fact he has yet to deploy to production in this manner and the general feedback from the room at the time was no one else had &#8211; this doesn&#8217;t mean no-one has since of course, but you start to get the feeling the DBAs back home wouldn&#8217;t be happy. The other thing was the dev nature of it, for example, when your developing, you don&#8217;t want to be held back by &#8220;rules&#8221; that protect data, it is after all, development, your not going to have production data in your dev environment, right? So, if you don&#8217;t &#8220;pin&#8221; your storage to a persistent path, it&#8217;ll get purge when you stop your docker image. Can you image if you forgot to set the production config correctly and come a reboot all your data disappears? I can already here my friendly DBA screaming.<\/p>\n<p>To get a docker\\container for SQL Server, you&#8217;d either have to select one from list of images with SQL Server and its going to be huge, at least until they get SQL Server 2016 on <a href=\"https:\/\/blogs.technet.microsoft.com\/windowsserver\/2015\/04\/08\/microsoft-announces-nano-server-for-modern-apps-and-cloud\/\" target=\"_blank\" rel=\"nofollow\">Nano Server<\/a>. Or you&#8217;d have to have PowerShell DSC to install and configure SQL Server.<\/p>\n<p>In terms of Microsoft SQL Server, or really any database, I don&#8217;t believe you&#8217;d need to have it in a container, docker or otherwise. Since SQL Server 2012 you could have\u00a0contained databases, this is where the login information that is normally stored in the instance master database within the application database. This pretty much made database independent of each other within the same SQL Server instance. I&#8217;d admit this was introduced for Azure, but this leads me onto my next point.<\/p>\n<p>The best thing to manage is the the thing you don&#8217;t have to manage. So why would you want to spend time setting up SQL Server (as developer), regardless of if its in a container if you can just click a button or run a script to auto provision a Azure DB? Surely if your developing anything new, which is going to use a SQL Server database, surely you should be aiming for Azure DB? Even if you&#8217;re not, there aren&#8217;t that many types of SQL Server,\u00a0you don&#8217;t often run into dependency hell with SQL Server, none that justifies building individual containers, at least, in my opinion.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 01 Jun 2016 09:56:30 +0000","created_by":1,"updated_at":"Wed, 01 Jun 2016 10:06:24 +0000","updated_by":1,"published_at":"Wed, 01 Jun 2016 09:56:30 +0000","published_by":1},{"id":759,"title":"New laptop, error running SSIS package","slug":"new-laptop-error-running-ssis-package","markdown":"\nSo today I went to run a SSIS package on my new laptop and bam, error message.\n\n> Microsoft.SqlServer.Dts.Runtime.DtsRuntimeException: The package failed to load due to error 0xC0011008 \u201cError loading from XML. No further detailed error information can be specified for this problem because no Events object was passed where detailed error information can be stored.\u201d. This occurs when CPackage::LoadFromXML fails.\u00a0\u00a0 \u2014> System.Runtime.InteropServices.COMException: The package failed to load due to error 0xC0011008 \u201cError loading from XML. No further detailed error information can be specified for this problem because no Events object was passed where detailed error information can be stored.\u201d. This occurs when CPackage::LoadFromXML fails.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.Wrapper.IDTSPackagePersist100.LoadPackageFromXML(Object vSource, Boolean vbSourceIsLocation, IDTSEvents100 pEvents)\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.Package.LoadFromXML(String packageXml, IDTSEvents events)\u00a0\u00a0\u00a0\u00a0 \u2014 End of inner exception stack trace \u2014at Microsoft.SqlServer.Dts.Runtime.Package.LoadFromXML(String packageXml, IDTSEvents events)\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.Project.LoadPackage(IProjectStorage storage, Package package, String streamName, IDTSEvents events)\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.PackageItem.Load(IDTSEvents events)\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.PackageItem.get_Package()\u00a0\u00a0\u00a0\u00a0 at Microsoft.DataTransformationServices.Project.DataTransformationsProjectBuilder.IncrementalBuildThroughObj(IOutputWindow outputWindow)\u00a0\u00a0\u00a0\u00a0 at Microsoft.DataTransformationServices.Project.DataTransformationsProjectBuilder.BuildIncremental(IOutputWindow outputWindow)\n\nTranslates as I hadn\u2019t installed the Oracle client and the [Microsoft Connectors v3.0](https:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=44582). Speaking of the connectors, the Attunity Oracle adapters are amazing, if your connecting SSIS to Oracle, these are a must (especially as they are free!)\n\n\n","html":"<p>So today I went to run a SSIS package on my new laptop and bam, error message.<\/p>\n<blockquote><p>Microsoft.SqlServer.Dts.Runtime.DtsRuntimeException: The package failed to load due to error 0xC0011008 &#8220;Error loading from XML. No further detailed error information can be specified for this problem because no Events object was passed where detailed error information can be stored.&#8221;. This occurs when CPackage::LoadFromXML fails.\u00a0\u00a0 &#8212;&gt; System.Runtime.InteropServices.COMException: The package failed to load due to error 0xC0011008 &#8220;Error loading from XML. No further detailed error information can be specified for this problem because no Events object was passed where detailed error information can be stored.&#8221;. This occurs when CPackage::LoadFromXML fails.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.Wrapper.IDTSPackagePersist100.LoadPackageFromXML(Object vSource, Boolean vbSourceIsLocation, IDTSEvents100 pEvents)\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.Package.LoadFromXML(String packageXml, IDTSEvents events)\u00a0\u00a0\u00a0\u00a0 &#8212; End of inner exception stack trace &#8212;at Microsoft.SqlServer.Dts.Runtime.Package.LoadFromXML(String packageXml, IDTSEvents events)\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.Project.LoadPackage(IProjectStorage storage, Package package, String streamName, IDTSEvents events)\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.PackageItem.Load(IDTSEvents events)\u00a0\u00a0\u00a0\u00a0 at Microsoft.SqlServer.Dts.Runtime.PackageItem.get_Package()\u00a0\u00a0\u00a0\u00a0 at Microsoft.DataTransformationServices.Project.DataTransformationsProjectBuilder.IncrementalBuildThroughObj(IOutputWindow outputWindow)\u00a0\u00a0\u00a0\u00a0 at Microsoft.DataTransformationServices.Project.DataTransformationsProjectBuilder.BuildIncremental(IOutputWindow outputWindow)<\/p><\/blockquote>\n<p>Translates as I hadn&#8217;t installed the Oracle client and the <a href=\"https:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=44582\" target=\"_blank\" rel=\"nofollow\">Microsoft Connectors v3.0<\/a>. Speaking of the connectors, the Attunity Oracle adapters are amazing, if your connecting SSIS to Oracle, these are a must (especially as they are free!)<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 01 Jun 2016 23:06:32 +0000","created_by":1,"updated_at":"Wed, 01 Jun 2016 23:06:32 +0000","updated_by":1,"published_at":"Wed, 01 Jun 2016 23:06:32 +0000","published_by":1},{"id":762,"title":"MDSCHEMA_CUBES DMV not returning all cubes","slug":"mdschema_cubes-dmv-not-returning-all-cubes","markdown":"\nI had previously created a SSIS package with a simple Process Full on the SSAS MD database, however, as the project has progressed this hasn\u2019t been ideal. Its basically all or nothing. In order reduce the damage a failure can cause I\u2019ve setup a Process Full for\u00a0each dimension and cube so each is processed independently of each other. I\u2019ve used the data from the Analysis Services Dynamic Management Views, or\u00a0DMV for short, which I\u2019ve [used for the documentation](https:\/\/matt40k.uk\/2015\/08\/documentation\/)\u00a0to feed the foreach loop.\n\nHowever there is a major problem with the DMVs. They only list processed cubes (and their dimensions). So how do you get a list of unprocessed cubes (and their dimensions)?\n\nAnswer? Using the Analysis Management Objects (AMO). This will return the same list as SQL Server Management Studio (SSMS), rather then just the processed, like the DMV\u00a0or Excel lists. I\u2019m currently trying out a few ideas to find the best solution \u2013 so as a script component (source) or a stored procedure. As the saying goes, it\u2019s production ready, but its not [GitHub ready](https:\/\/github.com\/matt40k) \u2013 not yet anyway.\n\nThanks again to Chris Webb for pointing me in the right direction\n\n> [@matt40k](https:\/\/twitter.com\/matt40k) SSMS might well be using AMO or something similar from the admin interface\n> \n> \u2014 Christopher Webb (@Technitrain) [May 18, 2016](https:\/\/twitter.com\/Technitrain\/status\/732886507019767808)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\n\u00a0\n\n\n","html":"<p>I had previously created a SSIS package with a simple Process Full on the SSAS MD database, however, as the project has progressed this hasn&#8217;t been ideal. Its basically all or nothing. In order reduce the damage a failure can cause I&#8217;ve setup a Process Full for\u00a0each dimension and cube so each is processed independently of each other. I&#8217;ve used the data from the Analysis Services Dynamic Management Views, or\u00a0DMV for short, which I&#8217;ve <a href=\"https:\/\/matt40k.uk\/2015\/08\/documentation\/\">used for the documentation<\/a>\u00a0to feed the foreach loop.<\/p>\n<p>However there is a major problem with the DMVs. They only list processed cubes (and their dimensions). So how do you get a list of unprocessed cubes (and their dimensions)?<\/p>\n<p>Answer? Using the Analysis Management Objects (AMO). This will return the same list as SQL Server Management Studio (SSMS), rather then just the processed, like the DMV\u00a0or Excel lists. I&#8217;m currently trying out a few ideas to find the best solution &#8211; so as a script component (source) or a stored procedure. As the saying goes, it&#8217;s production ready, but its not <a href=\"https:\/\/github.com\/matt40k\" target=\"_blank\" rel=\"nofollow\">GitHub ready<\/a> &#8211; not yet anyway.<\/p>\n<p>Thanks again to Chris Webb for pointing me in the right direction<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\"><a href=\"https:\/\/twitter.com\/matt40k\" target=\"_blank\" rel=\"nofollow\">@matt40k<\/a> SSMS might well be using AMO or something similar from the admin interface<\/p>\n<p>&mdash; Christopher Webb (@Technitrain) <a href=\"https:\/\/twitter.com\/Technitrain\/status\/732886507019767808\" target=\"_blank\" rel=\"nofollow\">May 18, 2016<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 07 Jun 2016 21:01:13 +0000","created_by":1,"updated_at":"Tue, 07 Jun 2016 21:01:13 +0000","updated_by":1,"published_at":"Tue, 07 Jun 2016 21:01:13 +0000","published_by":1},{"id":764,"title":"Enterprise vs Enterprise Core","slug":"enterprise-vs-enterprise-core","markdown":"\nThis month saw the release of SQL Server 2016, which from a BI\\Report point of view is huge. Once we had access to it\n\n> [@matt40k](https:\/\/twitter.com\/matt40k) yeah, already been on msdn. Can't believe we're being made to wait!!!\n> \n> \u2014 Dave Kerby (@davekerby) [June 1, 2016](https:\/\/twitter.com\/davekerby\/status\/737912147703934976)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\nI spotted something odd.\n\n> So whats the diff? Enterprise is only core licensed \u2013 [https:\/\/t.co\/2NgZG7siUD](https:\/\/t.co\/2NgZG7siUD) [#sqlhelp](https:\/\/twitter.com\/hashtag\/sqlhelp?src=hash) [@sqlserver](https:\/\/twitter.com\/SQLServer) [@SQLServerBI](https:\/\/twitter.com\/SQLServerBI) [pic.twitter.com\/SP8OC5eLvD](https:\/\/t.co\/SP8OC5eLvD)\n> \n> \u2014 Matt Smith (@matt40k) [June 6, 2016](https:\/\/twitter.com\/matt40k\/status\/739752396046372864)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\nNow, in SQL Server terms there are two types of licensing\n\n- Server license + CALs\n- Cores (processors)\n\nExpect for Enterprise, you can only get Core licenses.\n\nThe next question was, have they made a edition for Windows Server Core, a cut-down version \u2013 but the files sizes are the same, so this was unlikely, Microsoft also hadn\u2019t made any statement about a cut-down version (which you\u2019d expect), so again, this was unlikely.\n\nOnce again, Twitter\u00a0came to the rescue, more precisely [Joey D\u2019Antoni](https:\/\/twitter.com\/jdanton) did. The answer is legacy. Any old Microsoft licensing agreement with software assurance (SA) can get the latest version. This means that anyone who had an old SQL Server Enterprise Server\\CAL license is now on the core based licensing \u2013 there are a few gotchas which Joey refers to \u2013 your still limited my the number of CALs, but your also limited to a max of 20 cores.\n\nSo in short\n\n- SQL Server 2016 Enterprise Core is limited to 20 cores and is for legacy license holders.\n- SQL Server 2016 Enterprise isn\u2019t limited.\n\n\n","html":"<p>This month saw the release of SQL Server 2016, which from a BI\\Report point of view is huge. Once we had access to it<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\"><a href=\"https:\/\/twitter.com\/matt40k\" target=\"_blank\" rel=\"nofollow\">@matt40k<\/a> yeah, already been on msdn. Can&#39;t believe we&#39;re being made to wait!!!<\/p>\n<p>&mdash; Dave Kerby (@davekerby) <a href=\"https:\/\/twitter.com\/davekerby\/status\/737912147703934976\" target=\"_blank\" rel=\"nofollow\">June 1, 2016<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>I spotted something odd.<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">So whats the diff? Enterprise is only core licensed &#8211; <a href=\"https:\/\/t.co\/2NgZG7siUD\" target=\"_blank\" rel=\"nofollow\">https:\/\/t.co\/2NgZG7siUD<\/a> <a href=\"https:\/\/twitter.com\/hashtag\/sqlhelp?src=hash\" target=\"_blank\" rel=\"nofollow\">#sqlhelp<\/a> <a href=\"https:\/\/twitter.com\/SQLServer\" target=\"_blank\" rel=\"nofollow\">@sqlserver<\/a> <a href=\"https:\/\/twitter.com\/SQLServerBI\" target=\"_blank\" rel=\"nofollow\">@SQLServerBI<\/a> <a href=\"https:\/\/t.co\/SP8OC5eLvD\" target=\"_blank\" rel=\"nofollow\">pic.twitter.com\/SP8OC5eLvD<\/a><\/p>\n<p>&mdash; Matt Smith (@matt40k) <a href=\"https:\/\/twitter.com\/matt40k\/status\/739752396046372864\" target=\"_blank\" rel=\"nofollow\">June 6, 2016<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>Now, in SQL Server terms there are two types of licensing<\/p>\n<ul>\n<li>Server license + CALs<\/li>\n<li>Cores (processors)<\/li>\n<\/ul>\n<p>Expect for Enterprise, you can only get Core licenses.<\/p>\n<p>The next question was, have they made a edition for Windows Server Core, a cut-down version &#8211; but the files sizes are the same, so this was unlikely, Microsoft also hadn&#8217;t made any statement about a cut-down version (which you&#8217;d expect), so again, this was unlikely.<\/p>\n<p>Once again, Twitter\u00a0came to the rescue, more precisely <a href=\"https:\/\/twitter.com\/jdanton\" target=\"_blank\" rel=\"nofollow\">Joey D&#8217;Antoni<\/a> did. The answer is legacy. Any old Microsoft licensing agreement with software assurance (SA) can get the latest version. This means that anyone who had an old SQL Server Enterprise Server\\CAL license is now on the core based licensing &#8211; there are a few gotchas which Joey refers to &#8211; your still limited my the number of CALs, but your also limited to a max of 20 cores.<\/p>\n<p>So in short<\/p>\n<ul>\n<li>SQL Server 2016 Enterprise Core is limited to 20 cores and is for legacy license holders.<\/li>\n<li>SQL Server 2016 Enterprise isn&#8217;t limited.<\/li>\n<\/ul>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 07 Jun 2016 21:32:57 +0000","created_by":1,"updated_at":"Tue, 07 Jun 2016 21:32:57 +0000","updated_by":1,"published_at":"Tue, 07 Jun 2016 21:32:57 +0000","published_by":1},{"id":768,"title":"Logging ConnectionStrings in SSIS","slug":"logging-connectionstrings-in-ssis","markdown":"\nAnother day, another reference to an old [Jamie Thomson blog post](http:\/\/sqlblog.com\/blogs\/jamie_thomson\/archive\/2011\/10\/25\/verify-a-connection-before-using-it-ssis.aspx) \u2013 today it was getting the ConnectionString to output to the information. Admittedly I wasn\u2019t looking for how to fire the connection string into an information event, just the ConnectionString, still another great idea and its useful for debugging.\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/191f8e28c3bc68df5d6340d9a30f9859.json\"><\/div>\u00a0\n\n\n","html":"<p>Another day, another reference to an old <a href=\"http:\/\/sqlblog.com\/blogs\/jamie_thomson\/archive\/2011\/10\/25\/verify-a-connection-before-using-it-ssis.aspx\" target=\"_blank\" rel=\"nofollow\">Jamie Thomson blog post<\/a> &#8211; today it was getting the ConnectionString to output to the information. Admittedly I wasn&#8217;t looking for how to fire the connection string into an information event, just the ConnectionString, still another great idea and its useful for debugging.<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/191f8e28c3bc68df5d6340d9a30f9859.json\"><\/div>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Thu, 09 Jun 2016 21:18:45 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:06:59 +0000","updated_by":1,"published_at":"Thu, 09 Jun 2016 21:18:45 +0000","published_by":1},{"id":770,"title":"Microsoft shows Data Pros some love","slug":"microsoft-shows-data-pros-some-love","markdown":"\nMicrosoft has released [SQL Server 2016 Developer, for free](https:\/\/blogs.technet.microsoft.com\/dataplatforminsider\/2016\/03\/31\/microsoft-sql-server-developer-edition-is-now-free\/). That\u2019s right, zero, zip, nothing. Completely free. The developer edition is fully featured, it contains the same goodness as the $$$ Enterprise edition. The catch? Its not for production.\n\n\n","html":"<p>Microsoft has released <a href=\"https:\/\/blogs.technet.microsoft.com\/dataplatforminsider\/2016\/03\/31\/microsoft-sql-server-developer-edition-is-now-free\/\" target=\"_blank\" rel=\"nofollow\">SQL Server 2016 Developer, for free<\/a>. That&#8217;s right, zero, zip, nothing. Completely free. The developer edition is fully featured, it contains the same goodness as the $$$ Enterprise edition. The catch? Its not for production.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Thu, 09 Jun 2016 21:23:40 +0000","created_by":1,"updated_at":"Thu, 09 Jun 2016 21:23:40 +0000","updated_by":1,"published_at":"Thu, 09 Jun 2016 21:23:40 +0000","published_by":1},{"id":772,"title":"Error building SSDT package","slug":"error-building-ssdt-package","markdown":"\nToday my colleague had a problem opening our BI solution, the solution had multiple projects, including 3 SSDT projects. Although the project builds correctly on both my machine, the build machine and another colleague machine it refused to build stating that the reference to the object in another project was invalid.\n\nAfter thinking for a few moments, I remembered I had seem this before. The problem was a bug in SSDT. The solution was to click on **Tools > Extensions and Updates**, then click **Updates** from the left-menu on the window that appears.\n\n\n","html":"<p>Today my colleague had a problem opening our BI solution, the solution had multiple projects, including 3 SSDT projects. Although the project builds correctly on both my machine, the build machine and another colleague machine it refused to build stating that the reference to the object in another project was invalid.<\/p>\n<p>After thinking for a few moments, I remembered I had seem this before. The problem was a bug in SSDT. The solution was to click on <strong>Tools &gt; Extensions and Updates<\/strong>, then click <strong>Updates<\/strong> from the left-menu on the window that appears.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 10 Jun 2016 21:05:15 +0000","created_by":1,"updated_at":"Fri, 10 Jun 2016 21:05:15 +0000","updated_by":1,"published_at":"Fri, 10 Jun 2016 21:05:15 +0000","published_by":1},{"id":254,"title":"What's wrong with Excel?","slug":"temp-slug-76","markdown":"\n\u00a0\n\nhttp:\/\/glengilchrist.co.uk\/\n\nhttp:\/\/paultebraak.wordpress.com\/2014\/07\/02\/flawless-excel-in-business-intelligence\/\n\n\n","html":"<p>&nbsp;<\/p>\n<p>http:\/\/glengilchrist.co.uk\/<\/p>\n<p>http:\/\/paultebraak.wordpress.com\/2014\/07\/02\/flawless-excel-in-business-intelligence\/<\/p>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 10 Jun 2016 21:07:16 +0000","created_by":1,"updated_at":"Fri, 10 Jun 2016 21:07:16 +0000","updated_by":1,"published_at":"","published_by":1},{"id":780,"title":"Is today Day Zero or Day One?","slug":"is-today-day-zero-or-day-one","markdown":"\nThis might sound pretty pointless and silly but when talking about a 20 working day SLA a day can mean alot between a massive fine or compliance.\n\nDuring one of my [driving lessons](https:\/\/directdrive.academy\/) with [Gary](https:\/\/directdrive.academy\/) we were talking about his recent [streak of passes](https:\/\/www.facebook.com\/garygibbsADI\/videos\/1153963814665251\/). The conversation then lead on to pass rates and us wondering how this broken down \u2013 for example, by gender, ethnicity, age, driving instructor type (intense driving school \\ chain \\ individual driving instructor \\ family etc).\n\nStill curious, I decided to send off an a FOI request, before doing so, I went looking to see if someone else has which lead me to find some rather shocking data (see the bottom of the post). For those who don\u2019t know, FOI stands for Freedom of Information. This is where Joe Public can request (reasonable) information from the public sector \u2013 after all, it is your (tax) money that they are spending. Logging FOI is dead straightforward thanks to [WhatDoTheyKnow](https:\/\/www.whatdotheyknow.com\/). Anyway, the Freedom of Information Act requires them (public sector folks) to reply within 20 working days.\n\nFirst question. If I log a call on Sunday, what day is day one? So firstly, Sunday doesn\u2019t count. It\u2019s not a weekday. So Monday\u2019s day 1? That\u2019s what I would think, and it\u2019s even what [WhatDoTheyKnow](https:\/\/www.whatdotheyknow.com\/)\u00a0says, but the DVLA say its the Tuesday. After a few emails between them both, I went off an ask ICO,\u00a0Information Commissioner\u2019s Office who\u2019s responsible for these things. Here is their response\n\n> *counting the first working day **after\u00a0**a valid\u00a0request is received as the first day*\n\nSo, if you log a FOI over the weekend, they receive it on the Monday, that\u2019s Day Zero. Day One is actually the second day.\n\nThey also say\n\n> *Working day means any day other than a Saturday, Sunday, or public holidays and bank holidays; this may or may not be the same as the days they\u00a0are open for business or staff are in work.*\n\n\u00a0\n\nSo its important that public sector don\u2019t close for extra days as they risk eating into that time they have to respond to FOI request and failure to reply can (ultimately) result in fines.\n\nGoing off topic \u2013 there are some determined people in Suffolk who really want to drive.\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/0c0c34f381f37b42023dfcefee8ab584.json\"><\/div>Source: [FOI request via WhatDoTheyKnow](https:\/\/www.whatdotheyknow.com\/request\/learners_failing_driving_tests_i#incoming-382765)\n\n\u00a0\n\n\n","html":"<p>This might sound pretty pointless and silly but when talking about a 20 working day SLA a day can mean alot between a massive fine or compliance.<\/p>\n<p>During one of my <a href=\"https:\/\/directdrive.academy\/\" target=\"_blank\" rel=\"nofollow\">driving lessons<\/a> with <a href=\"https:\/\/directdrive.academy\/\" target=\"_blank\" rel=\"nofollow\">Gary<\/a> we were talking about his recent <a href=\"https:\/\/www.facebook.com\/garygibbsADI\/videos\/1153963814665251\/\" target=\"_blank\" rel=\"nofollow\">streak of passes<\/a>. The conversation then lead on to pass rates and us wondering how this broken down &#8211; for example, by gender, ethnicity, age, driving instructor type (intense driving school \\ chain \\ individual driving instructor \\ family etc).<\/p>\n<p>Still curious, I decided to send off an a FOI request, before doing so, I went looking to see if someone else has which lead me to find some rather shocking data (see the bottom of the post). For those who don&#8217;t know, FOI stands for Freedom of Information. This is where Joe Public can request (reasonable) information from the public sector &#8211; after all, it is your (tax) money that they are spending. Logging FOI is dead straightforward thanks to <a href=\"https:\/\/www.whatdotheyknow.com\/\" target=\"_blank\" rel=\"nofollow\">WhatDoTheyKnow<\/a>. Anyway, the Freedom of Information Act requires them (public sector folks) to reply within 20 working days.<\/p>\n<p>First question. If I log a call on Sunday, what day is day one? So firstly, Sunday doesn&#8217;t count. It&#8217;s not a weekday. So Monday&#8217;s day 1? That&#8217;s what I would think, and it&#8217;s even what <a href=\"https:\/\/www.whatdotheyknow.com\/\" target=\"_blank\" rel=\"nofollow\">WhatDoTheyKnow<\/a>\u00a0says, but the DVLA say its the Tuesday. After a few emails between them both, I went off an ask ICO,\u00a0Information Commissioner\u2019s Office who&#8217;s responsible for these things. Here is their response<\/p>\n<blockquote><p><em>counting the first working day <strong>after\u00a0<\/strong>a valid\u00a0request is received as the first day<\/em><\/p><\/blockquote>\n<p>So, if you log a FOI over the weekend, they receive it on the Monday, that&#8217;s Day Zero. Day One is actually the second day.<\/p>\n<p>They also say<\/p>\n<blockquote><p><em>Working day means any day other than a Saturday, Sunday, or public holidays and bank holidays; this may or may not be the same as the days they\u00a0are open for business or staff are in work.<\/em><\/p><\/blockquote>\n<p>&nbsp;<\/p>\n<p>So its important that public sector don&#8217;t close for extra days as they risk eating into that time they have to respond to FOI request and failure to reply can (ultimately) result in fines.<\/p>\n<p>Going off topic &#8211; there are some determined people in Suffolk who really want to drive.<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/0c0c34f381f37b42023dfcefee8ab584.json\"><\/div>\n<p>Source: <a href=\"https:\/\/www.whatdotheyknow.com\/request\/learners_failing_driving_tests_i#incoming-382765\" target=\"_blank\" rel=\"nofollow\">FOI request via WhatDoTheyKnow<\/a><\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 10 Jun 2016 22:00:02 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 22:05:38 +0000","updated_by":1,"published_at":"Fri, 10 Jun 2016 22:00:02 +0000","published_by":1},{"id":782,"title":"Getting a list of AD Groups and their members using PowerQuery","slug":"getting-a-list-of-ad-groups-and-their-members-using-powerquery","markdown":"\n> The Power Query Formula Language (informally known as \u201cM\u201d) is a powerful mashup query language optimized for building queries that mashup data. It is a functional, case sensitive language similar to F#,\u00a0\u00a0which can be used with Power Query in Excel and Power BI Desktop.\n\nA few days ago I got asked to produce a list of users (and their email address)\u00a0in a number of AD Groups. I already had a SSIS package that had a script task to pull this data from Active Directory and push it into a SQL database and we have a PowerShell script to get the same data\u00a0in our code repo. After work I set about repeating it but using PowerQuery.\n\nApart from one quirk the process was pretty straightforward. PowerQuery has built in support for Active Directory. Just click the **Data** tab, then select **New Query** > **From Other Sources** > **From Active Directory**\n\n[![PowerQuery - Excel > Menu](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_menu.png?fit=700%2C433&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_menu.png?ssl=1)\n\nThis will then pop up with a windows asking for you to select your domain, assuming your machine is joined to the domain and your logged on as a domain user, this should be prefilled in with the correct domain.\n\n[![PowerQuery - Excel > Connection](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_connection.png?fit=602%2C215&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_connection.png?ssl=1)\n\nThe next window just asks you confirm your credentials, you\u2019ll most likely want to use your current windows user.\n\nAfter you\u2019ve connected to your\u00a0Active Directory, you\u2019ll be able to navigator, your be able to select your domain from your forest and then select the object you want to query. For this example, select your domain then select **group**, then click **Edit**.\n\n[![PowerQuery - Excel > Navigator](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_navigator.png?fit=700%2C557&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_navigator.png?ssl=1)\n\nThis will then open up the Query Editor\n\n[![PowerQuery - Excel > Query Editor](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?fit=700%2C266&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?ssl=1)\n\nThis will then list out the groups, or at least a sample. Click on the left\\right arrow on **securityPrincipal** column header, this then bring up a filter window, select **sAMAccountName** and click on OK. This will give you the friendly name your more then likely to know the groups by.\n\nNow its a question of filtering the list \u2013 if you right-click on the **sAMAccountName** and select **Text Filters** > **Begin With**. You can select one of the other options, if you make a mistake or you want to refine it, on the right-hand side, you have **Query Settings** > **Applied Steps**, if you click the cog next to **Filtered Rows** your get\n\n[![PowerQuery - Filter](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_filter.png?fit=602%2C215&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_filter.png?ssl=1)\n\nthis hopefully doesn\u2019t need any explanation. You can of course filter on other\u00a0columns if\u00a0required, such as OU group.\n\nAdding the users involves\u00a0expanding the member\n\nAnd the final M script looks like field like we did with securityPrincipal until we get to the individual user object.\n\nThe last point is where I hit a few snags. Firstly, I couldn\u2019t expand into the user object, luckily, clicking on **Advanced Editor** on the **Home** tab revealed the M code. I\u2019ve included my code below which I hope will help.\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/7ded896bf9fc14bc21602ceebf6be7dd.json\"><\/div>I\u2019ve personally found this a useful dive into PowerQuery, hopefully you have too \ud83d\ude42\n\n\n","html":"<blockquote><p>The Power Query Formula Language (informally known as &#8220;M&#8221;) is a powerful mashup query language optimized for building queries that mashup data. It is a functional, case sensitive language similar to F#,\u00a0\u00a0which can be used with Power Query in Excel and Power BI Desktop.<\/p><\/blockquote>\n<p>A few days ago I got asked to produce a list of users (and their email address)\u00a0in a number of AD Groups. I already had a SSIS package that had a script task to pull this data from Active Directory and push it into a SQL database and we have a PowerShell script to get the same data\u00a0in our code repo. After work I set about repeating it but using PowerQuery.<\/p>\n<p>Apart from one quirk the process was pretty straightforward. PowerQuery has built in support for Active Directory. Just click the <strong>Data<\/strong> tab, then select <strong>New Query<\/strong> &gt; <strong>From Other Sources<\/strong> &gt; <strong>From Active Directory<\/strong><\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_menu.png?ssl=1\"><img class=\"alignnone size-full wp-image-784\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_menu.png?fit=700%2C433&#038;ssl=1\" alt=\"PowerQuery - Excel &gt; Menu\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_menu.png?w=913&amp;ssl=1 913w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_menu.png?resize=300%2C186&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_menu.png?resize=768%2C475&amp;ssl=1 768w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>This will then pop up with a windows asking for you to select your domain, assuming your machine is joined to the domain and your logged on as a domain user, this should be prefilled in with the correct domain.<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_connection.png?ssl=1\"><img class=\"alignnone size-full wp-image-785\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_connection.png?fit=602%2C215&#038;ssl=1\" alt=\"PowerQuery - Excel &gt; Connection\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_connection.png?w=602&amp;ssl=1 602w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_connection.png?resize=300%2C107&amp;ssl=1 300w\" sizes=\"(max-width: 602px) 100vw, 602px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>The next window just asks you confirm your credentials, you&#8217;ll most likely want to use your current windows user.<\/p>\n<p>After you&#8217;ve connected to your\u00a0Active Directory, you&#8217;ll be able to navigator, your be able to select your domain from your forest and then select the object you want to query. For this example, select your domain then select <strong>group<\/strong>, then click <strong>Edit<\/strong>.<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_navigator.png?ssl=1\"><img class=\"alignnone size-full wp-image-786\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_navigator.png?fit=700%2C557&#038;ssl=1\" alt=\"PowerQuery - Excel &gt; Navigator\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_navigator.png?w=885&amp;ssl=1 885w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_navigator.png?resize=300%2C239&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_navigator.png?resize=768%2C611&amp;ssl=1 768w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>This will then open up the Query Editor<\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?ssl=1\"><img class=\"alignnone size-full wp-image-787\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?fit=700%2C266&#038;ssl=1\" alt=\"PowerQuery - Excel &gt; Query Editor\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?w=1534&amp;ssl=1 1534w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?resize=300%2C114&amp;ssl=1 300w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?resize=768%2C291&amp;ssl=1 768w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?resize=1024%2C389&amp;ssl=1 1024w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?resize=1200%2C455&amp;ssl=1 1200w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_query.png?w=1400&amp;ssl=1 1400w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>This will then list out the groups, or at least a sample. Click on the left\\right arrow on <strong>securityPrincipal<\/strong> column header, this then bring up a filter window, select <strong>sAMAccountName<\/strong> and click on OK. This will give you the friendly name your more then likely to know the groups by.<\/p>\n<p>Now its a question of filtering the list &#8211; if you right-click on the <strong>sAMAccountName<\/strong> and select <strong>Text Filters<\/strong> &gt; <strong>Begin With<\/strong>. You can select one of the other options, if you make a mistake or you want to refine it, on the right-hand side, you have <strong>Query Settings<\/strong> &gt; <strong>Applied Steps<\/strong>, if you click the cog next to <strong>Filtered Rows<\/strong> your get<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_filter.png?ssl=1\"><img class=\"alignnone size-full wp-image-789\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_filter.png?fit=602%2C215&#038;ssl=1\" alt=\"PowerQuery - Filter\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_filter.png?w=602&amp;ssl=1 602w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/06\/pq_filter.png?resize=300%2C107&amp;ssl=1 300w\" sizes=\"(max-width: 602px) 100vw, 602px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>this hopefully doesn&#8217;t need any explanation. You can of course filter on other\u00a0columns if\u00a0required, such as OU group.<\/p>\n<p>Adding the users involves\u00a0expanding the member<\/p>\n<p>And the final M script looks like field like we did with securityPrincipal until we get to the individual user object.<\/p>\n<p>The last point is where I hit a few snags. Firstly, I couldn&#8217;t expand into the user object, luckily, clicking on <strong>Advanced Editor<\/strong> on the <strong>Home<\/strong> tab revealed the M code. I&#8217;ve included my code below which I hope will help.<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/7ded896bf9fc14bc21602ceebf6be7dd.json\"><\/div>\n<p>I&#8217;ve personally found this a useful dive into PowerQuery, hopefully you have too \ud83d\ude42<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 14 Jun 2016 21:54:36 +0000","created_by":1,"updated_at":"Tue, 14 Jun 2016 21:54:36 +0000","updated_by":1,"published_at":"Tue, 14 Jun 2016 21:54:36 +0000","published_by":1},{"id":256,"title":"BI resources","slug":"bi-resources","markdown":"\nBelow is a list of useful BI links\n\n[http:\/\/www.kimballgroup.com\/](http:\/\/www.kimballgroup.com\/)\n\n[https:\/\/gqbi.wordpress.com\/](https:\/\/gqbi.wordpress.com\/)\n\n[https:\/\/bipassion.wordpress.com\/](https:\/\/bipassion.wordpress.com\/)\n\n[https:\/\/blog.crossjoin.co.uk\/](https:\/\/blog.crossjoin.co.uk\/)\n\n\u00a0\n\n\n","html":"<p>Below is a list of useful BI links<\/p>\n<p><a href=\"http:\/\/www.kimballgroup.com\/\" target=\"_blank\" rel=\"nofollow\">http:\/\/www.kimballgroup.com\/<\/a><\/p>\n<p><a href=\"https:\/\/gqbi.wordpress.com\/\" target=\"_blank\" rel=\"nofollow\">https:\/\/gqbi.wordpress.com\/<\/a><\/p>\n<p><a href=\"https:\/\/bipassion.wordpress.com\/\" target=\"_blank\" rel=\"nofollow\">https:\/\/bipassion.wordpress.com\/<\/a><\/p>\n<p><a href=\"https:\/\/blog.crossjoin.co.uk\/\" target=\"_blank\" rel=\"nofollow\">https:\/\/blog.crossjoin.co.uk\/<\/a><\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 24 Jun 2016 08:01:15 +0000","created_by":1,"updated_at":"Wed, 24 Aug 2016 14:38:48 +0000","updated_by":1,"published_at":"Fri, 24 Jun 2016 08:01:15 +0000","published_by":1},{"id":794,"title":"Feature request - Add Azure Data Catalog support to SSDT","slug":"feature-request-add-azure-data-catalog-support-to-ssdt","markdown":"\nOne of the annoy parts of building a warehouse is building the staging database, its an important first step. The staging database is replica\u00a0of the source systems. [BIML](http:\/\/bimlscript.com\/) can provide away to\u00a0accelerate this process, however its not perfect. BIML is designed to create SSIS packages \u2013 and it does this very, very, well. SQL database objects, not so well. SSDT does this well.\n\nThe first step in the designing a warehouse is discovery, [Azure Data Catalog](https:\/\/azure.microsoft.com\/en-gb\/services\/data-catalog\/) is an excellent tool for doing the discovery, it allows you to connect to a wide array of data source types and gather the meta data that can be used to build the staging database.\n\nMy feature request is to add support for Azure Data Catalog to SSDT. In a nutshell add a item to this menu list\n\n[![Feature request - SSDT](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/IWouldLike.png?fit=700%2C283&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/IWouldLike.png?ssl=1)\n\n\u00a0\n\n\n","html":"<p>One of the annoy parts of building a warehouse is building the staging database, its an important first step. The staging database is replica\u00a0of the source systems. <a href=\"http:\/\/bimlscript.com\/\" target=\"_blank\" rel=\"nofollow\">BIML<\/a> can provide away to\u00a0accelerate this process, however its not perfect. BIML is designed to create SSIS packages &#8211; and it does this very, very, well. SQL database objects, not so well. SSDT does this well.<\/p>\n<p>The first step in the designing a warehouse is discovery, <a href=\"https:\/\/azure.microsoft.com\/en-gb\/services\/data-catalog\/\" target=\"_blank\" rel=\"nofollow\">Azure Data Catalog<\/a> is an excellent tool for doing the discovery, it allows you to connect to a wide array of data source types and gather the meta data that can be used to build the staging database.<\/p>\n<p>My feature request is to add support for Azure Data Catalog to SSDT. In a nutshell add a item to this menu list<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/IWouldLike.png?ssl=1\"><img class=\"alignnone size-full wp-image-795\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/IWouldLike.png?fit=700%2C283&#038;ssl=1\" alt=\"Feature request - SSDT\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/IWouldLike.png?w=727&amp;ssl=1 727w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/IWouldLike.png?resize=300%2C121&amp;ssl=1 300w\" sizes=\"(max-width: 700px) 100vw, 700px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 17 Jul 2016 23:11:46 +0000","created_by":1,"updated_at":"Sun, 17 Jul 2016 23:11:46 +0000","updated_by":1,"published_at":"Sun, 17 Jul 2016 23:11:46 +0000","published_by":1},{"id":798,"title":"SQL Auditing sucks","slug":"sql-auditing-sucks","markdown":"\nBack in SQL Server 2008 Microsoft introduced auditing, specifically the\u00a0Database Audit Specification. It\u2019s pretty good \u2013 despite the title I do actually think its nice feature, it pretty much works and doesn\u2019t have much of a performance impact, my problem is not much love has gone into it since it was released in SQL2008. It claims to meet various regulations such as the EU data Protection Directive, HIPAA, PCI DSS and to be fair, I\u2019m sure it does. Assuming to implement it correctly.\n\nFor example, I have it enabled on ACS.DimPersonSensitive \u2013 as you can guess, it holds sensitive information about a individual. If I want to break it, all I need to do is use parameters, ie  \n```\ndeclare @per_id int = 123456<br><\/br>\nselect * from [ACS].[DimPersonSensitive] where per_id = @per_id```\n\nNow if I look at the logs, I literary see @per_id, so I have no idea what id that was pass. There is no column in the audit logs that tell me what that parameter was.\n\nThe other issue I was hit with today was SSDT, it really doesn\u2019t support it. Here is the error I got today\n\n[![error-audit-ssdt](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/error-audit-ssdt.png?fit=700%2C17&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/error-audit-ssdt.png?ssl=1)\n\nIt\u2019s basically blocking me from changing the table because it has auditing enabled on it. No nice way around it. It\u2019s another Pre-Deployment script. This isn\u2019t terrible. The terrible bit is it doesn\u2019t reapply the auditing once you\u2019ve removed it and updated the table, despite the auditing being defined in SSDT project.\n\n\n","html":"<p>Back in SQL Server 2008 Microsoft introduced auditing, specifically the\u00a0Database Audit Specification. It&#8217;s pretty good &#8211; despite the title I do actually think its nice feature, it pretty much works and doesn&#8217;t have much of a performance impact, my problem is not much love has gone into it since it was released in SQL2008. It claims to meet various regulations such as the EU data Protection Directive, HIPAA, PCI DSS and to be fair, I&#8217;m sure it does. Assuming to implement it correctly.<\/p>\n<p>For example, I have it enabled on ACS.DimPersonSensitive &#8211; as you can guess, it holds sensitive information about a individual. If I want to break it, all I need to do is use parameters, ie<br \/>\n<code>declare @per_id int = 123456<br \/>\nselect * from [ACS].[DimPersonSensitive] where per_id = @per_id<\/code><\/p>\n<p>Now if I look at the logs, I literary see @per_id, so I have no idea what id that was pass. There is no column in the audit logs that tell me what that parameter was.<\/p>\n<p>The other issue I was hit with today was SSDT, it really doesn&#8217;t support it. Here is the error I got today<\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/error-audit-ssdt.png?ssl=1\"><img class=\"alignnone size-full wp-image-799\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/error-audit-ssdt.png?fit=700%2C17&#038;ssl=1\" alt=\"error-audit-ssdt\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/error-audit-ssdt.png?w=930&amp;ssl=1 930w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/error-audit-ssdt.png?resize=300%2C7&amp;ssl=1 300w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/error-audit-ssdt.png?resize=768%2C19&amp;ssl=1 768w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>It&#8217;s basically blocking me from changing the table because it has auditing enabled on it. No nice way around it. It&#8217;s another Pre-Deployment script. This isn&#8217;t terrible. The terrible bit is it doesn&#8217;t reapply the auditing once you&#8217;ve removed it and updated the table, despite the auditing being defined in SSDT project.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 23 Jul 2016 01:25:55 +0000","created_by":1,"updated_at":"Sat, 23 Jul 2016 01:25:55 +0000","updated_by":1,"published_at":"Sat, 23 Jul 2016 01:25:55 +0000","published_by":1},{"id":801,"title":"Incorrect x-axis dates","slug":"incorrect-x-axis-dates","markdown":"\nSo yesterday I was playing with [PowerBI](http:\/\/powerbi.com\/) and I hit a problem.\n\n[![XAxis-Error](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-Error.png?fit=332%2C335&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-Error.png?ssl=1)\n\nAs you can see, the x-axis is wrong. For some reason it wasn\u2019t creating the correct range.\n\nAfter a little while I thought I\u2019d try out Microsoft\u2019s feedback option \u2013 the smiley faces \u2013 in the top menu you have a smiley face. Click it, then you can send feedback.\n\n[![Feedback](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/Feedback.png?fit=346%2C228&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/Feedback.png?ssl=1)\n\nSure enough after a little while, Justin Schneider from the [Power BI ](http:\/\/powerbi.com)team replied asking a few more questions \u2013 basically asking me to check the data was correct, which was in this case and even offered a solution.\n\nThe problem was the auto options for the X-Axis range was wrong and he recommended setting it manually.\n\nTo this is simple, click on the visual with the faulty X-Axis, then on the left hand menu, click the paint brush, then expand the X-Axis and manually enter the start and end\n\n[![XAxis-fix](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fix.png?fit=216%2C418&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fix.png?ssl=1)\n\nAnd voil\u00e0 its fixed!\n\n[![XAxis-fixed](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fixed.png?fit=342%2C335&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fixed.png?ssl=1)\n\n\n","html":"<p>So yesterday I was playing with <a href=\"http:\/\/powerbi.com\/\" target=\"_blank\" rel=\"nofollow\">PowerBI<\/a> and I hit a problem.<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-Error.png?ssl=1\"><img class=\"alignnone size-full wp-image-802\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-Error.png?fit=332%2C335&#038;ssl=1\" alt=\"XAxis-Error\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-Error.png?w=332&amp;ssl=1 332w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-Error.png?resize=150%2C150&amp;ssl=1 150w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-Error.png?resize=297%2C300&amp;ssl=1 297w\" sizes=\"(max-width: 332px) 100vw, 332px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>As you can see, the x-axis is wrong. For some reason it wasn&#8217;t creating the correct range.<\/p>\n<p>After a little while I thought I&#8217;d try out Microsoft&#8217;s feedback option &#8211; the smiley faces &#8211; in the top menu you have a smiley face. Click it, then you can send feedback.<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/Feedback.png?ssl=1\"><img class=\"alignnone size-full wp-image-805\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/Feedback.png?fit=346%2C228&#038;ssl=1\" alt=\"Feedback\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/Feedback.png?w=346&amp;ssl=1 346w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/Feedback.png?resize=300%2C198&amp;ssl=1 300w\" sizes=\"(max-width: 346px) 100vw, 346px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>Sure enough after a little while, Justin Schneider from the <a href=\"http:\/\/powerbi.com\" target=\"_blank\" rel=\"nofollow\">Power BI <\/a>team replied asking a few more questions &#8211; basically asking me to check the data was correct, which was in this case and even offered a solution.<\/p>\n<p>The problem was the auto options for the X-Axis range was wrong and he recommended setting it manually.<\/p>\n<p>To this is simple, click on the visual with the faulty X-Axis, then on the left hand menu, click the paint brush, then expand the X-Axis and manually enter the start and end<\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fix.png?ssl=1\"><img class=\"alignnone size-full wp-image-803\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fix.png?fit=216%2C418&#038;ssl=1\" alt=\"XAxis-fix\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fix.png?w=216&amp;ssl=1 216w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fix.png?resize=155%2C300&amp;ssl=1 155w\" sizes=\"(max-width: 216px) 100vw, 216px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>And voil\u00e0 its fixed!<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fixed.png?ssl=1\"><img class=\"alignnone size-full wp-image-804\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fixed.png?fit=342%2C335&#038;ssl=1\" alt=\"XAxis-fixed\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fixed.png?w=342&amp;ssl=1 342w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/07\/XAxis-fixed.png?resize=300%2C294&amp;ssl=1 300w\" sizes=\"(max-width: 342px) 100vw, 342px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 27 Jul 2016 10:18:04 +0000","created_by":1,"updated_at":"Wed, 27 Jul 2016 10:18:04 +0000","updated_by":1,"published_at":"Wed, 27 Jul 2016 10:18:04 +0000","published_by":1},{"id":811,"title":"School MIS systems in the England","slug":"school-mis-systems-in-the-england","markdown":"\nUpdated 10\/10\/2016 \u2013 Added Map using the [new Shapes option in PowerBI](https:\/\/powerbi.microsoft.com\/en-us\/documentation\/powerbi-desktop-shape-map\/).\n\nEvery School in England regularly publish data to the Department of Education and Graham Reed has published a spreadsheet of the software each school used to submit their returns.\n\nBelow is a PowerBI report I\u2019ve created based on his data. [You can also access by clicking here](https:\/\/app.powerbi.com\/view?r=eyJrIjoiYTM5ODQyMzUtODI5Mi00Y2EwLTliMzAtODQyYWI5YzkyODFlIiwidCI6ImRhZmFiZWU0LWIwODMtNDk1OC1hYjBhLWQxZGFiNjI2ZGE3OCIsImMiOjh9)\n\n<iframe allowfullscreen=\"allowfullscreen\" frameborder=\"0\" height=\"700\" src=\"https:\/\/app.powerbi.com\/view?r=eyJrIjoiYTM5ODQyMzUtODI5Mi00Y2EwLTliMzAtODQyYWI5YzkyODFlIiwidCI6ImRhZmFiZWU0LWIwODMtNDk1OC1hYjBhLWQxZGFiNjI2ZGE3OCIsImMiOjh9\" width=\"933\"><\/iframe>\n\n\n","html":"<p>Updated 10\/10\/2016 &#8211; Added Map using the <a href=\"https:\/\/powerbi.microsoft.com\/en-us\/documentation\/powerbi-desktop-shape-map\/\" target=\"_blank\" rel=\"nofollow\">new Shapes option in PowerBI<\/a>.<\/p>\n<p>Every School in England regularly publish data to the Department of Education and Graham Reed has published a spreadsheet of the software each school used to submit their returns.<\/p>\n<p>Below is a PowerBI report I&#8217;ve created based on his data. <a href=\"https:\/\/app.powerbi.com\/view?r=eyJrIjoiYTM5ODQyMzUtODI5Mi00Y2EwLTliMzAtODQyYWI5YzkyODFlIiwidCI6ImRhZmFiZWU0LWIwODMtNDk1OC1hYjBhLWQxZGFiNjI2ZGE3OCIsImMiOjh9\" target=\"_blank\" rel=\"nofollow\">You can also access by clicking here<\/a><\/p>\n<p><iframe src=\"https:\/\/app.powerbi.com\/view?r=eyJrIjoiYTM5ODQyMzUtODI5Mi00Y2EwLTliMzAtODQyYWI5YzkyODFlIiwidCI6ImRhZmFiZWU0LWIwODMtNDk1OC1hYjBhLWQxZGFiNjI2ZGE3OCIsImMiOjh9\" width=\"933\" height=\"700\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\"><\/iframe><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 30 Jul 2016 18:49:45 +0000","created_by":1,"updated_at":"Mon, 10 Oct 2016 15:12:45 +0000","updated_by":1,"published_at":"Sat, 30 Jul 2016 18:49:45 +0000","published_by":1},{"id":817,"title":"Toy cars","slug":"toy-cars","markdown":"\n<figure class=\"wp-caption alignright\" id=\"attachment_842\" style=\"width: 280px\">[![Darcy (7)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/FullSizeRender.jpg?resize=280%2C470&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/FullSizeRender.jpg?ssl=1)<figcaption class=\"wp-caption-text\">The Darc (7)<\/figcaption><\/figure>Over the summer holidays I got my son to create a spreadsheet detailing\u00a0some of his toy cars which we\u00a0then imported into [PowerBI](http:\/\/powerbi.microsoft.com\/en-gb\/).\n\nCreated by a 7 year old in under an hour\n\n<iframe allowfullscreen=\"allowfullscreen\" frameborder=\"0\" height=\"510\" src=\"https:\/\/app.powerbi.com\/view?r=eyJrIjoiZjNjMDAwNjYtNTZhNy00OTI5LWFkMTItMGY4ZGM5OGNjOWZmIiwidCI6ImRhZmFiZWU0LWIwODMtNDk1OC1hYjBhLWQxZGFiNjI2ZGE3OCIsImMiOjh9\" width=\"680\"><\/iframe>\n\n\u00a0\n\n\n","html":"<figure id=\"attachment_842\" style=\"width: 280px\" class=\"wp-caption alignright\"><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/FullSizeRender.jpg?ssl=1\"><img class=\" wp-image-842\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/FullSizeRender.jpg?resize=280%2C470&#038;ssl=1\" alt=\"Darcy (7)\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/FullSizeRender.jpg?w=866&amp;ssl=1 866w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/FullSizeRender.jpg?resize=179%2C300&amp;ssl=1 179w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/FullSizeRender.jpg?resize=768%2C1289&amp;ssl=1 768w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/FullSizeRender.jpg?resize=610%2C1024&amp;ssl=1 610w\" sizes=\"(max-width: 280px) 100vw, 280px\" data-recalc-dims=\"1\" \/><\/a><figcaption class=\"wp-caption-text\">The Darc (7)<\/figcaption><\/figure>\n<p>Over the summer holidays I got my son to create a spreadsheet detailing\u00a0some of his toy cars which we\u00a0then imported into <a href=\"http:\/\/powerbi.microsoft.com\/en-gb\/\" target=\"_blank\" rel=\"nofollow\">PowerBI<\/a>.<\/p>\n<p>Created by a 7 year old in under an hour<\/p>\n<p><iframe src=\"https:\/\/app.powerbi.com\/view?r=eyJrIjoiZjNjMDAwNjYtNTZhNy00OTI5LWFkMTItMGY4ZGM5OGNjOWZmIiwidCI6ImRhZmFiZWU0LWIwODMtNDk1OC1hYjBhLWQxZGFiNjI2ZGE3OCIsImMiOjh9\" width=\"680\" height=\"510\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\"><\/iframe><\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 14 Aug 2016 16:21:22 +0000","created_by":1,"updated_at":"Fri, 02 Sep 2016 12:14:16 +0000","updated_by":1,"published_at":"Sun, 14 Aug 2016 16:21:22 +0000","published_by":1},{"id":825,"title":"Build problem and duplicate releases","slug":"build-problem-and-duplicate-releases","markdown":"\nYesterday I went to investigate a problem someone had reported only to discover a butt load of releases\n\n[![](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4294.png?fit=700%2C394&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4294.png?ssl=1)  \n As you can see, I have more releases then commits. A build was triggered by a commit, but this doesn\u2019t explain why.\n\nI tried switching it up so it only builds when you put [build] in the commit message \u2013 which resulted in having to commit the yaml file as the feature isn\u2019t available via the web interface, it does make sense to have this under version control. However it continued to loop.\n\nLooking at the build history revealed it was looping, per commit\n\n[![](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4296.png?fit=700%2C394&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4296.png?ssl=1)\n\nAn email off to support resulted in speedy response.\n\n> Add \u201cskip_tags: true\u201d to your appveyor.yml.  \n>  -Feodor Fitsner, AppVeyor\n\nBingo. It was looping because I create a GitHub release for each build and tag the release. Which was then causing a build, which created a release that then got tagged, which created a release\u2026\n\nI\u2019m grateful I\u2019m not paying per build! Hopefully this will serve as a warning for others.\n\nI\u2019ve started to remove the releases but I\u2019ve hit the API limit last night. Hopefully I\u2019ll clean up my PowerShell script to deal with it, failing that I may have to rely on the kindnesses of GitHub human.\n\n> \u201cI have always depended on the kindness of strangers.\u201d\n> \n> \u2013 Blanche DuBois\n\n### Update\n\nI\u2019ve managed to remove the duff tags as well and [SIMS Bulk Import](https:\/\/simsbulkimport.uk\/) is down to two releases on [GitHub](https:\/\/github.com\/SIMSBulkImport\/SIMSBulkImport). I\u2019ve been slightly heavy handed when it came to deleting. Thankfully all the duff releases where pre-release so the problem wasn\u2019t as bad is it could have been.\n\nBelow is the PowerShell\u00a0script I quickly knocked together, the tags I did over lunch at work, thus the proxy bit \u2013 note that isn\u2019t our actual proxy address \ud83d\ude09\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/8ca025a7b260ce59a0d9a9a461479ac8.json\"><\/div>\n","html":"<p>Yesterday I went to investigate a problem someone had reported only to discover a butt load of releases<\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4294.png?ssl=1\"><img class=\"alignnone size-full wp-image-822\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4294.png?fit=700%2C394&#038;ssl=1\" alt=\"\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4294.png?w=1334&amp;ssl=1 1334w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4294.png?resize=300%2C169&amp;ssl=1 300w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4294.png?resize=768%2C432&amp;ssl=1 768w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4294.png?resize=1024%2C576&amp;ssl=1 1024w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4294.png?resize=1200%2C675&amp;ssl=1 1200w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><br \/>\nAs you can see, I have more releases then commits. A build was triggered by a commit, but this doesn&#8217;t explain why.<\/p>\n<p>I tried switching it up so it only builds when you put [build] in the commit message &#8211; which resulted in having to commit the yaml file as the feature isn&#8217;t available via the web interface, it does make sense to have this under version control. However it continued to loop.<\/p>\n<p>Looking at the build history revealed it was looping, per commit<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4296.png?ssl=1\"><img class=\"alignnone size-full wp-image-824\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4296.png?fit=700%2C394&#038;ssl=1\" alt=\"\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4296.png?w=1334&amp;ssl=1 1334w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4296.png?resize=300%2C169&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4296.png?resize=768%2C432&amp;ssl=1 768w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4296.png?resize=1024%2C576&amp;ssl=1 1024w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/08\/img_4296.png?resize=1200%2C675&amp;ssl=1 1200w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>An email off to support resulted in speedy response.<\/p>\n<blockquote><p>Add &#8220;skip_tags: true&#8221; to your appveyor.yml.<br \/>\n-Feodor Fitsner, AppVeyor<\/p><\/blockquote>\n<p>Bingo. It was looping because I create a GitHub release for each build and tag the release. Which was then causing a build, which created a release that then got tagged, which created a release&#8230;<\/p>\n<p>I&#8217;m grateful I&#8217;m not paying per build! Hopefully this will serve as a warning for others.<\/p>\n<p>I&#8217;ve started to remove the releases but I&#8217;ve hit the API limit last night. Hopefully I&#8217;ll clean up my PowerShell script to deal with it, failing that I may have to rely on the kindnesses of GitHub human.<\/p>\n<blockquote><p>&#8220;I have always depended on the kindness of strangers.&#8221;<\/p>\n<p>&#8211; Blanche DuBois<\/p><\/blockquote>\n<h3>Update<\/h3>\n<p>I&#8217;ve managed to remove the duff tags as well and <a href=\"https:\/\/simsbulkimport.uk\/\" target=\"_blank\" rel=\"nofollow\">SIMS Bulk Import<\/a> is down to two releases on <a href=\"https:\/\/github.com\/SIMSBulkImport\/SIMSBulkImport\" target=\"_blank\" rel=\"nofollow\">GitHub<\/a>. I&#8217;ve been slightly heavy handed when it came to deleting. Thankfully all the duff releases where pre-release so the problem wasn&#8217;t as bad is it could have been.<\/p>\n<p>Below is the PowerShell\u00a0script I quickly knocked together, the tags I did over lunch at work, thus the proxy bit &#8211; note that isn&#8217;t our actual proxy address \ud83d\ude09<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/8ca025a7b260ce59a0d9a9a461479ac8.json\"><\/div>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 15 Aug 2016 08:14:03 +0000","created_by":1,"updated_at":"Mon, 15 Aug 2016 12:57:43 +0000","updated_by":1,"published_at":"Mon, 15 Aug 2016 08:14:03 +0000","published_by":1},{"id":828,"title":"Speedy little website","slug":"temp-slug-86","markdown":"\nSometimes we need a simple website \u2013 maybe only a few pages, maybe only one. The problem is getting quality hosting for the site for a reasonable price.\n\nIdeally it should be\n\n- served over a CDN\n- available over IPv6 (and IPv4)\n- use SSL (https)\n- Cheap \u2013 not free\n\n\u00a0\n\n\n","html":"<p>Sometimes we need a simple website &#8211; maybe only a few pages, maybe only one. The problem is getting quality hosting for the site for a reasonable price.<\/p>\n<p>Ideally it should be<\/p>\n<ul>\n<li>served over a CDN<\/li>\n<li>available over IPv6 (and IPv4)<\/li>\n<li>use SSL (https)<\/li>\n<li>Cheap &#8211; not free<\/li>\n<\/ul>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 16 Aug 2016 11:23:46 +0000","created_by":1,"updated_at":"Tue, 16 Aug 2016 11:23:46 +0000","updated_by":1,"published_at":"","published_by":1},{"id":833,"title":"Glossary","slug":"temp-slug-87","markdown":"\n**idempotent** \u2013 something that is repeatable, that remains unchanged in value when repeatedly executed either\u00a0independently or\u00a0on by itself.\n\n**SSRS** \u2013 SQL Server Reporting Services part of Microsoft SQL Server. Used to deliver static reports that can be viewed via a web browser and exported to a number of formats including Excel, PDF and CSV.\n\n**SSAS** \u2013 SQL Server Analysis Services part of Microsoft SQL Server.\n\n**SSIS** \u2013 SQL Server Integration Services part of Microsoft SQL Server. Originally designed\u00a0as a ETL tool to build a data warehouse but has expanded and is able to automate a number of SQL Server related tasks.\n\n**PowerBI** \u2013\n\n**Kimball** \u2013\n\n**C#** \u2013\n\n**PowerShell** \u2013\n\n**MIS** \u2013 Management Information System\n\n**MI** \u2013\u00a0Management Information\n\n\u00a0\n\n\n","html":"<p><strong>idempotent<\/strong> &#8211; something that is repeatable, that remains unchanged in value when repeatedly executed either\u00a0independently or\u00a0on by itself.<\/p>\n<p><strong>SSRS<\/strong> &#8211; SQL Server Reporting Services part of Microsoft SQL Server. Used to deliver static reports that can be viewed via a web browser and exported to a number of formats including Excel, PDF and CSV.<\/p>\n<p><strong>SSAS<\/strong> &#8211; SQL Server Analysis Services part of Microsoft SQL Server.<\/p>\n<p><strong>SSIS<\/strong> &#8211; SQL Server Integration Services part of Microsoft SQL Server. Originally designed\u00a0as a ETL tool to build a data warehouse but has expanded and is able to automate a number of SQL Server related tasks.<\/p>\n<p><strong>PowerBI<\/strong> &#8211;<\/p>\n<p><strong>Kimball<\/strong> &#8211;<\/p>\n<p><strong>C#<\/strong> &#8211;<\/p>\n<p><strong>PowerShell<\/strong> &#8211;<\/p>\n<p><strong>MIS<\/strong> &#8211; Management Information System<\/p>\n<p><strong>MI<\/strong> &#8211;\u00a0Management Information<\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 24 Aug 2016 07:59:29 +0000","created_by":1,"updated_at":"Wed, 24 Aug 2016 07:59:29 +0000","updated_by":1,"published_at":"","published_by":1},{"id":837,"title":"Why does Bing sucks","slug":"why-does-bing-sucks","markdown":"\n> The only thing you search for on Bing is Google.\n\nMicrosoft has for a long time been in the search engine business with numerous rebranding exercises \u2013\u00a0MSN Search (1998 \u2013 2006),\u00a0Windows Live Search (2006 \u2013 2007) then\u00a0Live Search (2007 \u2013 2009) and finally Bing (2009 \u2013 present). Despite all the time and money Microsoft has poured into its search engine\u00a0Google still has **3 times** the number of\u00a0of the search engine market share as Bing. This is even with\u00a0Satya Nadella backing it, it being the default search engine on Windows 10 and things generally improving.\n\nSo why is this? I once asked [my driving instructor ](https:\/\/directdrive.academy\/)why he had quite a lot of students passing first time (with him), what was he doing that other driving instructors were missing. His answer was simple\n\n> I give honest, blunt feedback. If you forgot to check your mirrors, I don\u2019t sugar coat it, I tell you.\n\nThis is one of the key parts of machine learning. You need have a feedback loop. It might work perfectly today, but what about tomorrow? How do you improve it? How is that going to work when you\u2019ve got thousands of users? What about millions? What about billions?\n\nYou might think about putting in some web form so users can provide feedback. This is a dumb idea. Twitter does this for ads and I can honestly say I just randomly pick reasons, I don\u2019t care, I just want the ad to disappear because it has annoyed me.\n\nSo what is the answer? Simply put, I think its [Google Analytics](https:\/\/www.google.co.uk\/analytics\/).\u00a0Most websites have it enabled and why not? Its free, it provides highly valuable insight into your website and its simple to setup and use.\n\nFrom Googles point-of-view, its a win-win, they know how popular your site really is, it doesn\u2019t matter if you\u2019ve found the site via Bing or any other search engine, if the site got [Google Analytics](https:\/\/www.google.co.uk\/analytics\/) enabled, \u00a0Google knows and it knows what keywords got the end-user to the site. It also knows how long a user spent on the site and if they hit the sites target \u2013 ie did they buy anything.\n\n[Google Analytics](https:\/\/www.google.co.uk\/analytics\/)\u00a0is Google feedback loop.\n\n\n","html":"<blockquote><p>The only thing you search for on Bing is Google.<\/p><\/blockquote>\n<p>Microsoft has for a long time been in the search engine business with numerous rebranding exercises &#8211;\u00a0MSN Search (1998 &#8211; 2006),\u00a0Windows Live Search (2006 &#8211; 2007) then\u00a0Live Search (2007 &#8211; 2009) and finally Bing (2009 &#8211; present). Despite all the time and money Microsoft has poured into its search engine\u00a0Google still has <strong>3 times<\/strong> the number of\u00a0of the search engine market share as Bing. This is even with\u00a0Satya Nadella backing it, it being the default search engine on Windows 10 and things generally improving.<\/p>\n<p>So why is this? I once asked <a href=\"https:\/\/directdrive.academy\/\" target=\"_blank\" rel=\"nofollow\">my driving instructor <\/a>why he had quite a lot of students passing first time (with him), what was he doing that other driving instructors were missing. His answer was simple<\/p>\n<blockquote><p>I give honest, blunt feedback. If you forgot to check your mirrors, I don&#8217;t sugar coat it, I tell you.<\/p><\/blockquote>\n<p>This is one of the key parts of machine learning. You need have a feedback loop. It might work perfectly today, but what about tomorrow? How do you improve it? How is that going to work when you&#8217;ve got thousands of users? What about millions? What about billions?<\/p>\n<p>You might think about putting in some web form so users can provide feedback. This is a dumb idea. Twitter does this for ads and I can honestly say I just randomly pick reasons, I don&#8217;t care, I just want the ad to disappear because it has annoyed me.<\/p>\n<p>So what is the answer? Simply put, I think its <a href=\"https:\/\/www.google.co.uk\/analytics\/\" target=\"_blank\" rel=\"nofollow\">Google Analytics<\/a>.\u00a0Most websites have it enabled and why not? Its free, it provides highly valuable insight into your website and its simple to setup and use.<\/p>\n<p>From Googles point-of-view, its a win-win, they know how popular your site really is, it doesn&#8217;t matter if you&#8217;ve found the site via Bing or any other search engine, if the site got <a href=\"https:\/\/www.google.co.uk\/analytics\/\" target=\"_blank\" rel=\"nofollow\">Google Analytics<\/a> enabled, \u00a0Google knows and it knows what keywords got the end-user to the site. It also knows how long a user spent on the site and if they hit the sites target &#8211; ie did they buy anything.<\/p>\n<p><a href=\"https:\/\/www.google.co.uk\/analytics\/\" target=\"_blank\" rel=\"nofollow\">Google Analytics<\/a>\u00a0is Google feedback loop.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 29 Aug 2016 21:37:24 +0000","created_by":1,"updated_at":"Mon, 29 Aug 2016 21:38:49 +0000","updated_by":1,"published_at":"Mon, 29 Aug 2016 21:37:24 +0000","published_by":1},{"id":844,"title":"AD tools on Win10","slug":"ad-tools-on-win10","markdown":"\nA while ago I got a new laptop at work with Windows 10 Enterprise and for a while I just kept using my old Windows 7 Enterprise laptop for bits I hadn\u2019t yet transferred over. The last thing on the list was AD tools. This should just be a question of installing **[Remote Server Administration Tools for Windows 10 (KB2693643)](https:\/\/www.microsoft.com\/en-gb\/download\/details.aspx?id=45520)**. Unfortunately\n\n> Remote Server Administration Tools for Windows 10 is available only in English (United States) for this release.\n\nSo we need to install **English (United States) language package**. We can do this by\n\n- **Start** > **Settings** > **Time & Language** > **Region & Language**\n- Click on **Add a language** and select\u00a0**English (United States)**\n- Under **English (United States)\u00a0**select\u00a0\u201c**Language pack available**\u201c\n- Click on **Options**\n- Click the option to download and install the Language Pack\n- Restart Computer\n\n\n","html":"<p>A while ago I got a new laptop at work with Windows 10 Enterprise and for a while I just kept using my old Windows 7 Enterprise laptop for bits I hadn&#8217;t yet transferred over. The last thing on the list was AD tools. This should just be a question of installing <strong><a href=\"https:\/\/www.microsoft.com\/en-gb\/download\/details.aspx?id=45520\" target=\"_blank\" rel=\"nofollow\">Remote Server Administration Tools for Windows 10 (KB2693643)<\/a><\/strong>. Unfortunately<\/p>\n<blockquote><p>Remote Server Administration Tools for Windows 10 is available only in English (United States) for this release.<\/p><\/blockquote>\n<p>So we need to install <strong>English (United States) language package<\/strong>. We can do this by<\/p>\n<ul>\n<li><strong>Start<\/strong> &gt; <strong>Settings<\/strong> &gt; <strong>Time &amp; Language<\/strong> &gt; <strong>Region &amp; Language<\/strong><\/li>\n<li>Click on <strong>Add a language<\/strong> and select\u00a0<strong>English (United States)<\/strong><\/li>\n<li>Under <strong>English (United States)\u00a0<\/strong>select\u00a0&#8220;<strong>Language pack available<\/strong>&#8220;<\/li>\n<li>Click on <strong>Options<\/strong><\/li>\n<li>Click the option to download and install the Language Pack<\/li>\n<li>Restart Computer<\/li>\n<\/ul>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 03 Sep 2016 21:26:13 +0000","created_by":1,"updated_at":"Sat, 03 Sep 2016 21:26:13 +0000","updated_by":1,"published_at":"Sat, 03 Sep 2016 21:26:13 +0000","published_by":1},{"id":846,"title":"Care Quality Commission (CQC)","slug":"cqc","markdown":"\nToday one of our older SSIS packages failed which loads data into our warehouse, it turns out one of the fields had been expanded as the business had started to use a different standard for one of the codes. Despite not being told about this, it causing it fail and generate extra work\u00a0on an already busy\u00a0Monday it was actually a really good thing.\n\nFirstly, once we identified the problem (and fixed it), our main business contact was aware of it, was able to explain why it was happening. The change in a nutshell was to change from using a internal-only generated code to using the national standard \u2013 [Care Quality Commission (CQC)](https:\/\/www.cqc.org.uk\/) ID.\n\nPart of the next step of the change will be to bring on-board the [CQC ](https:\/\/www.cqc.org.uk\/)data which include the Care Home ratings. This will create a unified view of placements and ensuring no-one is in Care Home rated as inadequate.\n\n[CQC](https:\/\/www.cqc.org.uk\/)\u00a0provides the data either by [CSV\\Spreadsheet](https:\/\/www.cqc.org.uk\/content\/how-get-and-re-use-cqc-information-and-data#directory) or an [API](https:\/\/anypoint.mulesoft.com\/apiplatform\/openanswers-co-uk\/#\/portals\/organizations\/262a9203-e08f-4d1d-809d-2fc07032e8e8\/apis\/10878\/versions\/11228).\n\nInitial I thought importing the data dumps would be a good way forward, however after playing with the API, it looks like this might be a much better way forward. Below is a PowerShell script I knocked up to test the API out.\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/84c133de01f29191e65852acbfa89c22\/498f9a9cec327070b8e21a50020371e90a2c4b5e.json?file=cqc.ps1\"><\/div>\u00a0\n\nIt\u2019s really good to see that APIs are being generated, its just a shame these aren\u2019t being embedded directly into the software. Still, its a long journey, but at least its started.\n\n\n","html":"<p>Today one of our older SSIS packages failed which loads data into our warehouse, it turns out one of the fields had been expanded as the business had started to use a different standard for one of the codes. Despite not being told about this, it causing it fail and generate extra work\u00a0on an already busy\u00a0Monday it was actually a really good thing.<\/p>\n<p>Firstly, once we identified the problem (and fixed it), our main business contact was aware of it, was able to explain why it was happening. The change in a nutshell was to change from using a internal-only generated code to using the national standard &#8211; <a href=\"https:\/\/www.cqc.org.uk\/\" target=\"_blank\" rel=\"nofollow\">Care Quality Commission (CQC)<\/a> ID.<\/p>\n<p>Part of the next step of the change will be to bring on-board the <a href=\"https:\/\/www.cqc.org.uk\/\" target=\"_blank\" rel=\"nofollow\">CQC <\/a>data which include the Care Home ratings. This will create a unified view of placements and ensuring no-one is in Care Home rated as inadequate.<\/p>\n<p><a href=\"https:\/\/www.cqc.org.uk\/\" target=\"_blank\" rel=\"nofollow\">CQC<\/a>\u00a0provides the data either by <a href=\"https:\/\/www.cqc.org.uk\/content\/how-get-and-re-use-cqc-information-and-data#directory\" target=\"_blank\" rel=\"nofollow\">CSV\\Spreadsheet<\/a> or an <a href=\"https:\/\/anypoint.mulesoft.com\/apiplatform\/openanswers-co-uk\/#\/portals\/organizations\/262a9203-e08f-4d1d-809d-2fc07032e8e8\/apis\/10878\/versions\/11228\" target=\"_blank\" rel=\"nofollow\">API<\/a>.<\/p>\n<p>Initial I thought importing the data dumps would be a good way forward, however after playing with the API, it looks like this might be a much better way forward. Below is a PowerShell script I knocked up to test the API out.<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/84c133de01f29191e65852acbfa89c22\/498f9a9cec327070b8e21a50020371e90a2c4b5e.json?file=cqc.ps1\"><\/div>\n<p>&nbsp;<\/p>\n<p>It&#8217;s really good to see that APIs are being generated, its just a shame these aren&#8217;t being embedded directly into the software. Still, its a long journey, but at least its started.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 05 Sep 2016 23:36:05 +0000","created_by":1,"updated_at":"Mon, 05 Sep 2016 23:36:05 +0000","updated_by":1,"published_at":"Mon, 05 Sep 2016 23:36:05 +0000","published_by":1},{"id":849,"title":"Another year, another SQL Saturday","slug":"another-year-another-sql-saturday","markdown":"\nUnfortunately this year I\u2019ve not been able to make any of the pre-cons, however the (free) community day looks epic \u2013 the hardest part is going to be selecting which session to attend, the final one looking the worst. Aghhh!!! I\u2019m going to have to roll a dice or something!\n\nCDC \u2013 Change Data Capture in Detail  \n[Uwe Ricken](https:\/\/twitter.com\/dbBerater)\n\nWhat\u2019s new in the SQL Server 2016 for a BI Professional  \n[Prathy Kamasani](https:\/\/twitter.com\/pkamasani)\n\nExploring the Azure SQL Database  \n[Murilo Miranda](https:\/\/twitter.com\/murilocmiranda)\n\nAll things time-related  \n[Kennie Pontoppidan](https:\/\/twitter.com\/kennienp)\n\nData-driven personal decisions with PowerBI and Machine Learning  \n[Ruben Pertusa Lopez](https:\/\/twitter.com\/rpertusa)\n\nOne session that really peak my inter-geek, which had me looking at getting a Microsoft Band \u2013 only to find out they are running the stocks low at the moment (they release the first and second one in October, so it looks like the 3 will be out soon).\n\n#### **The (Consumer) Internet of Things on your arm \u2013 MS Band & PowerBI connected**\n\nThe Internet of Things (IOT) gets more and more attraction - not only on the business but also on the customer side. Connected fridges, cars and smart watches - always and everywhere connected! In this session Wolfgang will show you some possibilities of the Microsoft Band 2 SDK: how-to connect and read sensor data out of this device. But what should be done with that data? Power BI seems to be an ideal candidate for analyzing and presenting those kind of data. The different types of real-time analytics (Stream Analytics, Power BI API, ..) will be presented and their pros and cons will be envisioned. The challenge: Let's prepare a real-time dashboard of Band2 data in Power BI in 60 minutes!\n\n[Wolfgang Strasser](https:\/\/twitter.com\/wstrasser)\n\nIt\u2019s also good to see the a [small local company getting heavily involved :p](http:\/\/www.red-gate.com\/blog\/communities\/sql-saturday-cambridge)\n\nAnd not forgetting the [Micro:Bit](https:\/\/www.microbit.co.uk\/) sessions on\n\n#### **Imagine If \u2013 Train the Trainer Micro:bit session**\n\nWant to help inspire young people and deliver a Micro:bit workshop? If you are a teacher, parent or anyone interested in inspiring the next generation of technical experts; then come along to the Micro:bit session to get you started on how you could deliver a micro:bit workshop for either Primary or Secondary school children to code and create. In this session you will be taken through a workshop setup and approach (introduction, 3 coding tasks and a quiz) as well as getting hands on with the BBC micro:bit This session requires external registration via http:\/\/microbit_opt1.eventbrite.co.uk\n\n[Amy Nicholson](https:\/\/twitter.com\/amykatenicho)\n\n\n","html":"<p>Unfortunately this year I&#8217;ve not been able to make any of the pre-cons, however the (free) community day looks epic &#8211; the hardest part is going to be selecting which session to attend, the final one looking the worst. Aghhh!!! I&#8217;m going to have to roll a dice or something!<\/p>\n<p>CDC &#8211; Change Data Capture in Detail<br \/>\n<a href=\"https:\/\/twitter.com\/dbBerater\" target=\"_blank\" rel=\"nofollow\">Uwe Ricken<\/a><\/p>\n<p>What&#8217;s new in the SQL Server 2016 for a BI Professional<br \/>\n<a href=\"https:\/\/twitter.com\/pkamasani\" target=\"_blank\" rel=\"nofollow\">Prathy Kamasani<\/a><\/p>\n<p>Exploring the Azure SQL Database<br \/>\n<a href=\"https:\/\/twitter.com\/murilocmiranda\" target=\"_blank\" rel=\"nofollow\">Murilo Miranda<\/a><\/p>\n<p>All things time-related<br \/>\n<a href=\"https:\/\/twitter.com\/kennienp\" target=\"_blank\" rel=\"nofollow\">Kennie Pontoppidan<\/a><\/p>\n<p>Data-driven personal decisions with PowerBI and Machine Learning<br \/>\n<a href=\"https:\/\/twitter.com\/rpertusa\" target=\"_blank\" rel=\"nofollow\">Ruben Pertusa Lopez<\/a><\/p>\n<p>One session that really peak my inter-geek, which had me looking at getting a Microsoft Band &#8211; only to find out they are running the stocks low at the moment (they release the first and second one in October, so it looks like the 3 will be out soon).<\/p>\n<h4><strong>The (Consumer) Internet of Things on your arm &#8211; MS Band &amp; PowerBI connected<\/strong><\/h4>\n<pre>The Internet of Things (IOT) gets more and more attraction - not only on the business but also on the customer side. Connected fridges, cars and smart watches - always and everywhere connected! In this session Wolfgang will show you some possibilities of the Microsoft Band 2 SDK: how-to connect and read sensor data out of this device. But what should be done with that data? \r\nPower BI seems to be an ideal candidate for analyzing and presenting those kind of data. The different types of real-time analytics (Stream Analytics, Power BI API, ..) will be presented and their pros and cons will be envisioned. \r\nThe challenge: Let's prepare a real-time dashboard of Band2 data in Power BI in 60 minutes!<\/pre>\n<p style=\"text-align: right;\"><a href=\"https:\/\/twitter.com\/wstrasser\" target=\"_blank\" rel=\"nofollow\">Wolfgang Strasser<\/a><\/p>\n<p style=\"text-align: left;\">It&#8217;s also good to see the a <a href=\"http:\/\/www.red-gate.com\/blog\/communities\/sql-saturday-cambridge\" target=\"_blank\" rel=\"nofollow\">small local company getting heavily involved :p<\/a><\/p>\n<p style=\"text-align: left;\">And not forgetting the <a href=\"https:\/\/www.microbit.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Micro:Bit<\/a> sessions on<\/p>\n<h4><strong>Imagine If &#8211; Train the Trainer Micro:bit session<\/strong><\/h4>\n<pre>Want to help inspire young people and deliver a Micro:bit workshop?\r\n\r\nIf you are a teacher, parent or anyone interested in inspiring the next generation of technical experts; then come along to the Micro:bit session to get you started on how you could deliver a micro:bit workshop for either Primary or Secondary school children to code and create. \r\n\r\nIn this session you will be taken through a workshop setup and approach (introduction, 3 coding tasks and a quiz) as well as getting hands on with the BBC micro:bit\r\n\r\nThis session requires external registration via http:\/\/microbit_opt1.eventbrite.co.uk<\/pre>\n<p style=\"text-align: right;\"><a href=\"https:\/\/twitter.com\/amykatenicho\" target=\"_blank\" rel=\"nofollow\">Amy Nicholson<\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 07 Sep 2016 22:00:38 +0000","created_by":1,"updated_at":"Wed, 07 Sep 2016 22:08:12 +0000","updated_by":1,"published_at":"Wed, 07 Sep 2016 22:00:38 +0000","published_by":1},{"id":854,"title":"Wooo!!! Fixed in SQL Server 2016!","slug":"wooo-fixed-in-sql-server-2016","markdown":"\nhttps:\/\/twitter.com\/matt40k\/710468378050339000\n\nIt\u2019s nice to see Microsoft fixing old bugs \u2013 the I noticed today they updated the MSDN article about [Actions in Multidimensional Models](https:\/\/msdn.microsoft.com\/en-gb\/library\/ms175345.aspx).\n\n[![SSAS supports HTTPS actions](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/https-support.png?fit=589%2C109&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/https-support.png?ssl=1)\n\nIt now supports HTTPS!\n\nWoot!!\n\n[https:\/\/connect.microsoft.com\/SQLServer\/feedback\/details\/692837\/cannot-specify-https-in-an-analysis-services-report-action](https:\/\/connect.microsoft.com\/SQLServer\/feedback\/details\/692837\/cannot-specify-https-in-an-analysis-services-report-action)\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\n","html":"<p>https:\/\/twitter.com\/matt40k\/710468378050339000<\/p>\n<p>It&#8217;s nice to see Microsoft fixing old bugs &#8211; the I noticed today they updated the MSDN article about <a href=\"https:\/\/msdn.microsoft.com\/en-gb\/library\/ms175345.aspx\" target=\"_blank\" rel=\"nofollow\">Actions in Multidimensional Models<\/a>.<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/https-support.png?ssl=1\"><img class=\"alignnone size-full wp-image-855\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/https-support.png?fit=589%2C109&#038;ssl=1\" alt=\"SSAS supports HTTPS actions\" srcset=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/https-support.png?w=589&amp;ssl=1 589w, https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/https-support.png?resize=300%2C56&amp;ssl=1 300w\" sizes=\"(max-width: 589px) 100vw, 589px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>It now supports HTTPS!<\/p>\n<p>Woot!!<\/p>\n<p><a href=\"https:\/\/connect.microsoft.com\/SQLServer\/feedback\/details\/692837\/cannot-specify-https-in-an-analysis-services-report-action\" target=\"_blank\" rel=\"nofollow\">https:\/\/connect.microsoft.com\/SQLServer\/feedback\/details\/692837\/cannot-specify-https-in-an-analysis-services-report-action<\/a><\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Mon, 12 Sep 2016 21:44:31 +0000","created_by":1,"updated_at":"Mon, 12 Sep 2016 21:44:31 +0000","updated_by":1,"published_at":"Mon, 12 Sep 2016 21:44:31 +0000","published_by":1},{"id":858,"title":"SQLPrompt","slug":"sqlprompt","markdown":"\nSo [one](https:\/\/www.red-gate.com\/)\u00a0of the [really nice sponsors](https:\/\/www.red-gate.com\/) at [SQL Saturday](http:\/\/www.sqlsaturday.com\/) had a vending machine that was rigged up to release a treat when you sent a tweet. Like so\n\n> I'm at [#sqlsatcambridge](https:\/\/twitter.com\/hashtag\/sqlsatcambridge?src=hash) home of [@redgate](https:\/\/twitter.com\/redgate) [#redgatetreat](https:\/\/twitter.com\/hashtag\/redgatetreat?src=hash) [#red668](https:\/\/twitter.com\/hashtag\/red668?src=hash)\n> \n> \u2014 Matt Smith (@matt40k) [September 10, 2016](https:\/\/twitter.com\/matt40k\/status\/774598227639300096)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\nand give you\u2026\n\n![](https:\/\/i2.wp.com\/pbs.twimg.com\/media\/Cr_vWlRWgAALy4l.jpg?resize=513%2C385&ssl=1)\n\nIn mine had a [SQL Prompt](https:\/\/www.red-gate.com\/products\/sql-development\/sql-prompt\/) license. At first I was a bit disappointed, I hoping for\u00a0[SQL Test](https:\/\/www.red-gate.com\/products\/sql-development\/sql-test\/) license or a full blown [SQL toolbelt](https:\/\/www.red-gate.com\/products\/sql-development\/sql-toolbelt\/)\u00a0but the more I\u2019ve been using it, the more I\u2019m loving it.\n\nLike the\u00a0IntelliSense\u2026 or the fact press table next to the * expands it out into the list of columns\n\n[![sqlprompt_1](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_1.png?fit=700%2C245&ssl=1)](https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_1.png?ssl=1)\n\nThe fact it re-opens the tables you had open the last time you were in SQL Management Studio, that it has a history. I\u2019d like to say I never close the wrong window, especially when I haven\u2019t saved them, but I do. Luckily with SQL Prompt it allows me reopen it.\n\n[![sqlprompt_2](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_2.png?fit=700%2C444&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_2.png?ssl=1)\n\nIt even stops DBAs going to jail :p\n\n> I would literally kill for : GROUP BY EVERYTHING , ie group by everything im not aggregating.\n> \n> \u2014 Dave Ballantyne (@davebally) [September 26, 2016](https:\/\/twitter.com\/davebally\/status\/780385934487543808)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\n> [@davebally](https:\/\/twitter.com\/davebally) looks like it does \u2013 might be cheaper then 20 yrs in jail for murder \ud83d\ude00 [#SQLPrompt](https:\/\/twitter.com\/hashtag\/SQLPrompt?src=hash) [pic.twitter.com\/kphVNuYvms](https:\/\/t.co\/kphVNuYvms)\n> \n> \u2014 Matt Smith (@matt40k) [September 26, 2016](https:\/\/twitter.com\/matt40k\/status\/780389729573404672)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\n\u00a0\n\n\u00a0\n\n\n","html":"<p>So <a href=\"https:\/\/www.red-gate.com\/\" target=\"_blank\" rel=\"nofollow\">one<\/a>\u00a0of the <a href=\"https:\/\/www.red-gate.com\/\" target=\"_blank\" rel=\"nofollow\">really nice sponsors<\/a> at <a href=\"http:\/\/www.sqlsaturday.com\/\" target=\"_blank\" rel=\"nofollow\">SQL Saturday<\/a> had a vending machine that was rigged up to release a treat when you sent a tweet. Like so<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">I&#39;m at <a href=\"https:\/\/twitter.com\/hashtag\/sqlsatcambridge?src=hash\" target=\"_blank\" rel=\"nofollow\">#sqlsatcambridge<\/a> home of <a href=\"https:\/\/twitter.com\/redgate\" target=\"_blank\" rel=\"nofollow\">@redgate<\/a> <a href=\"https:\/\/twitter.com\/hashtag\/redgatetreat?src=hash\" target=\"_blank\" rel=\"nofollow\">#redgatetreat<\/a> <a href=\"https:\/\/twitter.com\/hashtag\/red668?src=hash\" target=\"_blank\" rel=\"nofollow\">#red668<\/a><\/p>\n<p>&mdash; Matt Smith (@matt40k) <a href=\"https:\/\/twitter.com\/matt40k\/status\/774598227639300096\" target=\"_blank\" rel=\"nofollow\">September 10, 2016<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>and give you&#8230;<\/p>\n<p><img class=\"alignnone \" src=\"https:\/\/i2.wp.com\/pbs.twimg.com\/media\/Cr_vWlRWgAALy4l.jpg?resize=513%2C385&#038;ssl=1\" alt=\"\" data-recalc-dims=\"1\" \/><\/p>\n<p>In mine had a <a href=\"https:\/\/www.red-gate.com\/products\/sql-development\/sql-prompt\/\" target=\"_blank\" rel=\"nofollow\">SQL Prompt<\/a> license. At first I was a bit disappointed, I hoping for\u00a0<a href=\"https:\/\/www.red-gate.com\/products\/sql-development\/sql-test\/\" target=\"_blank\" rel=\"nofollow\">SQL Test<\/a> license or a full blown <a href=\"https:\/\/www.red-gate.com\/products\/sql-development\/sql-toolbelt\/\" target=\"_blank\" rel=\"nofollow\">SQL toolbelt<\/a>\u00a0but the more I&#8217;ve been using it, the more I&#8217;m loving it.<\/p>\n<p>Like the\u00a0IntelliSense&#8230; or the fact press table next to the * expands it out into the list of columns<\/p>\n<p><a href=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_1.png?ssl=1\"><img class=\"alignnone size-full wp-image-859\" src=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_1.png?fit=700%2C245&#038;ssl=1\" alt=\"sqlprompt_1\" srcset=\"https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_1.png?w=944&amp;ssl=1 944w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_1.png?resize=300%2C105&amp;ssl=1 300w, https:\/\/i2.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_1.png?resize=768%2C269&amp;ssl=1 768w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>The fact it re-opens the tables you had open the last time you were in SQL Management Studio, that it has a history. I&#8217;d like to say I never close the wrong window, especially when I haven&#8217;t saved them, but I do. Luckily with SQL Prompt it allows me reopen it.<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_2.png?ssl=1\"><img class=\"alignnone size-full wp-image-860\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_2.png?fit=700%2C444&#038;ssl=1\" alt=\"sqlprompt_2\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_2.png?w=819&amp;ssl=1 819w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_2.png?resize=300%2C190&amp;ssl=1 300w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/SQLPrompt_2.png?resize=768%2C487&amp;ssl=1 768w\" sizes=\"(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>It even stops DBAs going to jail :p<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">I would literally kill for  : GROUP BY EVERYTHING , ie group by everything im not aggregating.<\/p>\n<p>&mdash; Dave Ballantyne (@davebally) <a href=\"https:\/\/twitter.com\/davebally\/status\/780385934487543808\" target=\"_blank\" rel=\"nofollow\">September 26, 2016<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\"><a href=\"https:\/\/twitter.com\/davebally\" target=\"_blank\" rel=\"nofollow\">@davebally<\/a> looks like it does &#8211; might be cheaper then 20 yrs in jail for murder \ud83d\ude00 <a href=\"https:\/\/twitter.com\/hashtag\/SQLPrompt?src=hash\" target=\"_blank\" rel=\"nofollow\">#SQLPrompt<\/a> <a href=\"https:\/\/t.co\/kphVNuYvms\" target=\"_blank\" rel=\"nofollow\">pic.twitter.com\/kphVNuYvms<\/a><\/p>\n<p>&mdash; Matt Smith (@matt40k) <a href=\"https:\/\/twitter.com\/matt40k\/status\/780389729573404672\" target=\"_blank\" rel=\"nofollow\">September 26, 2016<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>&nbsp;<\/p>\n<p>&nbsp;<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 01 Oct 2016 22:07:24 +0000","created_by":1,"updated_at":"Sat, 01 Oct 2016 22:12:49 +0000","updated_by":1,"published_at":"Sat, 01 Oct 2016 22:07:24 +0000","published_by":1},{"id":862,"title":"Are hybrid shops missing the point?","slug":"are-hybrid-shops-missing-the-point","markdown":"\nWith rise of the internet high street businesses are rushing to adapt so they don\u2019t become a thing of the past. However in their rush are they being\u00a0a storm trooper? Are they missing the point?\n\nFirst, lets look at two successful hybrid business. [Hughes](https:\/\/www.hughes.co.uk\/), a electrical store [based in\u00a0East Anglia](http:\/\/www.hughes.co.uk\/information\/aboutus)\u00a0and [Argos](http:\/\/www.argos.co.uk\/), a\u00a0British catalogue retailer operating in the United Kingdom. If we focus on Argos as its more well known business.\n\nIf you order online you can see the in store stock. You can then go in store and collect it. High street shops have become showrooms and mini warehouses.\n\nCompare this to [Game](http:\/\/www.game.co.uk\/) and [Staples](http:\/\/www.staples.co.uk\/), these stores compete against each other. Online vs instore. The prices are different, online prices are cheaper. When you order online to collect in store, they post your order to the store. You order comes from the central stock, it can\u2019t come from your local store.\n\nIt breeds resentment between local stores and corporate HQ. It leads to poor customer service.\n\nI recently cancelled an online order with Staples because they claimed to do next-day delivery, I arrived in the store the next day only to find my order hadn\u2019t arrived. So I phoned up, cancelled it and bought it instore. So it cost them\n\n- to answer my phone call, because I couldn\u2019t cancel via the website\n- to post my order\n- to receive my order, instore\n- to post back my order to their central warehouse\n- to answer my phone call chasing the refund\n- to answer my phone call chasing the refund, again\n- to answer my tweet, again chasing the refund\n- to then refund my money (not sure if they have to pay a card charge)\n\nAll these actions have a staff cost, after all, staff don\u2019t work for free.\n\n[![Missing](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/image1.jpg?fit=700%2C908&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/image1.jpg?ssl=1)\n\n\n","html":"<p>With rise of the internet high street businesses are rushing to adapt so they don&#8217;t become a thing of the past. However in their rush are they being\u00a0a storm trooper? Are they missing the point?<\/p>\n<p>First, lets look at two successful hybrid business. <a href=\"https:\/\/www.hughes.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Hughes<\/a>, a electrical store <a href=\"http:\/\/www.hughes.co.uk\/information\/aboutus\" target=\"_blank\" rel=\"nofollow\">based in\u00a0East Anglia<\/a>\u00a0and <a href=\"http:\/\/www.argos.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Argos<\/a>, a\u00a0British catalogue retailer operating in the United Kingdom. If we focus on Argos as its more well known business.<\/p>\n<p>If you order online you can see the in store stock. You can then go in store and collect it. High street shops have become showrooms and mini warehouses.<\/p>\n<p>Compare this to <a href=\"http:\/\/www.game.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Game<\/a> and <a href=\"http:\/\/www.staples.co.uk\/\" target=\"_blank\" rel=\"nofollow\">Staples<\/a>, these stores compete against each other. Online vs instore. The prices are different, online prices are cheaper. When you order online to collect in store, they post your order to the store. You order comes from the central stock, it can&#8217;t come from your local store.<\/p>\n<p>It breeds resentment between local stores and corporate HQ. It leads to poor customer service.<\/p>\n<p>I recently cancelled an online order with Staples because they claimed to do next-day delivery, I arrived in the store the next day only to find my order hadn&#8217;t arrived. So I phoned up, cancelled it and bought it instore. So it cost them<\/p>\n<ul>\n<li>to answer my phone call, because I couldn&#8217;t cancel via the website<\/li>\n<li>to post my order<\/li>\n<li>to receive my order, instore<\/li>\n<li>to post back my order to their central warehouse<\/li>\n<li>to answer my phone call chasing the refund<\/li>\n<li>to answer my phone call chasing the refund, again<\/li>\n<li>to answer my tweet, again chasing the refund<\/li>\n<li>to then refund my money (not sure if they have to pay a card charge)<\/li>\n<\/ul>\n<p>All these actions have a staff cost, after all, staff don&#8217;t work for free.<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/image1.jpg?ssl=1\"><img class=\"size-full wp-image-864 alignright\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/image1.jpg?fit=700%2C908&#038;ssl=1\" alt=\"Missing\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/image1.jpg?w=740&amp;ssl=1 740w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/09\/image1.jpg?resize=231%2C300&amp;ssl=1 231w\" sizes=\"(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sat, 01 Oct 2016 22:37:55 +0000","created_by":1,"updated_at":"Sat, 01 Oct 2016 22:37:55 +0000","updated_by":1,"published_at":"Sat, 01 Oct 2016 22:37:55 +0000","published_by":1},{"id":871,"title":"Where has SIMS Bulk Import gone?","slug":"where-has-sims-bulk-import-gone","markdown":"\n> Cut-down version, I\u2019m not working with SIMS anymore and I can\u2019t pass on my work without them getting a large bill from Capita for using the business objects.\n\nYears and years ago I was working on a SIMS help desk at a Local Authority (LA). I had a school\u00a0log a call asking about importing email addresses. Like many schools this school had just purchased a messaging service that allows sending emails and texts, the problem was they needed them in SIMS .net, as you can imagine the idea of manually retyping 1,000+ email addresses was rather daunting. So, after putting a call into Capita Partner Team asking for the API documentation I spend the evening building a simple import process. The next day I phoned the school to give them the good news and we imported their email addresses. A few days later a few more schools asked the same question and I decided to continue spending my evenings expanding (it imports email, telephone and User defined fields from XML, CSV and Excel spreadsheets) and refining the tool. I\u2019ve always developed in my own time, I\u2019ve never claimed overtime etc and I\u2019ve never charged a penny for using it.\n\nSIMS Bulk Import uses the SIMS .net business objects (API), its uses the the SIMS .net DLLs. Its the exact same .NET libraries that the SIMS .net library uses.\n\nAt the time we were in a partnership with BT, who had a procedure for raising new business ideas. The process involved working out what type of change it was \u2013 in this case it was a efficiency saving. To put it simply this means you can\u2019t charge more then what you can save, in this case labour.\n\nCapita charge the school. [Then they charge the partner for write access](https:\/\/matt40k.uk\/wp-content\/uploads\/2016\/10\/capita_sims_-_partner_management_document_-_apr16.pdf),\u00a0which the partner then charges\u00a0on the school so the **schools end up paying twice\u00a0**for support on one thing.\n\nWhen you take into account the Capita charge, the handling of money costs (invoicing, collecting and chasing etc), the helpdesk costs, the fact people expect a certain standard, ie you\u2019re going to have to invest alot more in terms of development \u2013 including documentation. It just doesn\u2019t make sense. It\u2019s actually more cost effective\u00a0to hire a temp to manually key in all those details!! Nuts!!\n\nSo at this point I basically decide I\u2019ll give it away. I really didn\u2019t want to see my hard work go to waste. I basically managed to wangle it into the public domain without finding a massive Capita bill land on my desk!! Its been in a wild for many, many years (with Capita knowledge)\u00a0with a grand total of ZERO corrupt SIMS databases. I find this quite an achievement. Don\u2019t get me wrong, SIMS Bulk Import has failed a number of\u00a0times, but it\u2019s never left your SIMS system in a worse state (unless you\u2019ve done something stupid like successfully imported the same email address to every pupil in SIMS!)\n\nA few years later I switched teams and stopped working with SIMS .net. SIMS Bulk Import has been stable for a while and I\u2019ve had a few commits from individuals. I\u2019m now at the stage where I\u2019m going to leave the LA and go work somewhere else and its unlikely to have a SIMS .net license let alone API access. I needed to find a new owner for SIMS Bulk Import. Anyone who\u2019s talked to me would have described SIMS Bulk Import as the poor man\u2019s [Salamander Active Directory](http:\/\/www.salamandersoft.co.uk\/active-directory\/), it is simply put the next logical step if you work out how you\u2019d improve SIMS Bulk Import, its what I would have done to make SIMS Bulk Import into a commercial product.\u00a0Luckily Richard agreed to take it on and even help me recover some of the costs of SIMS Bulk Import. Before you shoot off to [SalamanderSoft](http:\/\/www.salamandersoft.co.uk\/) to download it, let me save you the disappointment. Capita has said they would charge them a license fee for each school using it, ie it wouldn\u2019t be free. At this point I guess you can see where I\u2019m going with this? SIMS Bulk Import isn\u2019t worth paying for and Richard already has the expanded version (that **IS**\u00a0worth paying for).\n\nSo in short, your options are:\n\n1. Except you can\u2019t bulk import anymore and get typing or copy and pasting \\ hire a temp\n2. Look at automating your processes and buy\u00a0[Salamander Active Directory](http:\/\/www.salamandersoft.co.uk\/active-directory\/)\n3. Wait for Capita to come out with their own product \u2013 I suspect they will and charge. They do a limited SQL script that injects the records directly into the database, ironically bypassing the business objects (but hey, they support it so its all good right?)\n4. Switch MIS who doesn\u2019t charge for partner access \\ gives you bulk import routines ([Eduware Network](https:\/\/eduwarenetwork.com\/) has a list of MIS suppliers)\n\nOption 5 is carry on using it. I\u2019m sure even with me saying, no, don\u2019t do that (and I\u2019m sure Capita will agree) \u2013 someone will. So a few comments.\n\nMake sure you have the latest (or should that be last) version \u2013 its **2.5.0**\n\nIt should be digital signed, think of it as SSL for your applications. If you right-click on **SIMSBulkImport.exe** or the .msi installer you should see an extra tab \u2013 **Digital Signature**\u00a0and you should see its signed by me \u2013 **Open Source Developer, Matt40k**. If your copy doesn\u2019t have the signature its possible code has been injected and it is unsafe.\n\n[![digitalsignature](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/10\/digitalSignature.png?fit=396%2C280&ssl=1)](https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/10\/digitalSignature.png?ssl=1)\n\nYou should be OK as it uses whatever version of\u00a0SIMS API you have installed, so it\u2019ll just break one day and by break I mean it won\u2019t let you login or will just give you all import failed (if it does fail in terms of SIMS database corrupt then some thing terrible has happened with Capita API, but I digress).\n\nA few people have forked my code, for whatever reasons, I would just point out that the most up-to-date fork is **80** commits behind mine. That\u2019s a fair amount of work that missing from those forks.\n\nAnyway, hopefully you\u2019ve found it useful whilst it last.\n\n\n","html":"<blockquote><p>Cut-down version, I&#8217;m not working with SIMS anymore and I can&#8217;t pass on my work without them getting a large bill from Capita for using the business objects.<\/p><\/blockquote>\n<p>Years and years ago I was working on a SIMS help desk at a Local Authority (LA). I had a school\u00a0log a call asking about importing email addresses. Like many schools this school had just purchased a messaging service that allows sending emails and texts, the problem was they needed them in SIMS .net, as you can imagine the idea of manually retyping 1,000+ email addresses was rather daunting. So, after putting a call into Capita Partner Team asking for the API documentation I spend the evening building a simple import process. The next day I phoned the school to give them the good news and we imported their email addresses. A few days later a few more schools asked the same question and I decided to continue spending my evenings expanding (it imports email, telephone and User defined fields from XML, CSV and Excel spreadsheets) and refining the tool. I&#8217;ve always developed in my own time, I&#8217;ve never claimed overtime etc and I&#8217;ve never charged a penny for using it.<\/p>\n<p>SIMS Bulk Import uses the SIMS .net business objects (API), its uses the the SIMS .net DLLs. Its the exact same .NET libraries that the SIMS .net library uses.<\/p>\n<p>At the time we were in a partnership with BT, who had a procedure for raising new business ideas. The process involved working out what type of change it was &#8211; in this case it was a efficiency saving. To put it simply this means you can&#8217;t charge more then what you can save, in this case labour.<\/p>\n<p>Capita charge the school. <a href=\"https:\/\/matt40k.uk\/wp-content\/uploads\/2016\/10\/capita_sims_-_partner_management_document_-_apr16.pdf\">Then they charge the partner for write access<\/a>,\u00a0which the partner then charges\u00a0on the school so the <strong>schools end up paying twice\u00a0<\/strong>for support on one thing.<\/p>\n<p>When you take into account the Capita charge, the handling of money costs (invoicing, collecting and chasing etc), the helpdesk costs, the fact people expect a certain standard, ie you&#8217;re going to have to invest alot more in terms of development &#8211; including documentation. It just doesn&#8217;t make sense. It&#8217;s actually more cost effective\u00a0to hire a temp to manually key in all those details!! Nuts!!<\/p>\n<p>So at this point I basically decide I&#8217;ll give it away. I really didn&#8217;t want to see my hard work go to waste. I basically managed to wangle it into the public domain without finding a massive Capita bill land on my desk!! Its been in a wild for many, many years (with Capita knowledge)\u00a0with a grand total of ZERO corrupt SIMS databases. I find this quite an achievement. Don&#8217;t get me wrong, SIMS Bulk Import has failed a number of\u00a0times, but it&#8217;s never left your SIMS system in a worse state (unless you&#8217;ve done something stupid like successfully imported the same email address to every pupil in SIMS!)<\/p>\n<p>A few years later I switched teams and stopped working with SIMS .net. SIMS Bulk Import has been stable for a while and I&#8217;ve had a few commits from individuals. I&#8217;m now at the stage where I&#8217;m going to leave the LA and go work somewhere else and its unlikely to have a SIMS .net license let alone API access. I needed to find a new owner for SIMS Bulk Import. Anyone who&#8217;s talked to me would have described SIMS Bulk Import as the poor man&#8217;s <a href=\"http:\/\/www.salamandersoft.co.uk\/active-directory\/\" target=\"_blank\" rel=\"nofollow\">Salamander Active Directory<\/a>, it is simply put the next logical step if you work out how you&#8217;d improve SIMS Bulk Import, its what I would have done to make SIMS Bulk Import into a commercial product.\u00a0Luckily Richard agreed to take it on and even help me recover some of the costs of SIMS Bulk Import. Before you shoot off to <a href=\"http:\/\/www.salamandersoft.co.uk\/\" target=\"_blank\" rel=\"nofollow\">SalamanderSoft<\/a> to download it, let me save you the disappointment. Capita has said they would charge them a license fee for each school using it, ie it wouldn&#8217;t be free. At this point I guess you can see where I&#8217;m going with this? SIMS Bulk Import isn&#8217;t worth paying for and Richard already has the expanded version (that <strong>IS<\/strong>\u00a0worth paying for).<\/p>\n<p>So in short, your options are:<\/p>\n<ol>\n<li>Except you can&#8217;t bulk import anymore and get typing or copy and pasting \\ hire a temp<\/li>\n<li>Look at automating your processes and buy\u00a0<a href=\"http:\/\/www.salamandersoft.co.uk\/active-directory\/\" target=\"_blank\" rel=\"nofollow\">Salamander Active Directory<\/a><\/li>\n<li>Wait for Capita to come out with their own product &#8211; I suspect they will and charge. They do a limited SQL script that injects the records directly into the database, ironically bypassing the business objects (but hey, they support it so its all good right?)<\/li>\n<li>Switch MIS who doesn&#8217;t charge for partner access \\ gives you bulk import routines (<a href=\"https:\/\/eduwarenetwork.com\/\" target=\"_blank\" rel=\"nofollow\">Eduware Network<\/a> has a list of MIS suppliers)<\/li>\n<\/ol>\n<p>Option 5 is carry on using it. I&#8217;m sure even with me saying, no, don&#8217;t do that (and I&#8217;m sure Capita will agree) &#8211; someone will. So a few comments.<\/p>\n<p>Make sure you have the latest (or should that be last) version &#8211; its <strong>2.5.0<\/strong><\/p>\n<p>It should be digital signed, think of it as SSL for your applications. If you right-click on <strong>SIMSBulkImport.exe<\/strong> or the .msi installer you should see an extra tab &#8211; <strong>Digital Signature<\/strong>\u00a0and you should see its signed by me &#8211; <strong>Open Source Developer, Matt40k<\/strong>. If your copy doesn&#8217;t have the signature its possible code has been injected and it is unsafe.<\/p>\n<p><a href=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/10\/digitalSignature.png?ssl=1\"><img class=\"alignnone size-full wp-image-873\" src=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/10\/digitalSignature.png?fit=396%2C280&#038;ssl=1\" alt=\"digitalsignature\" srcset=\"https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/10\/digitalSignature.png?w=396&amp;ssl=1 396w, https:\/\/i0.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/10\/digitalSignature.png?resize=300%2C212&amp;ssl=1 300w\" sizes=\"(max-width: 396px) 100vw, 396px\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>You should be OK as it uses whatever version of\u00a0SIMS API you have installed, so it&#8217;ll just break one day and by break I mean it won&#8217;t let you login or will just give you all import failed (if it does fail in terms of SIMS database corrupt then some thing terrible has happened with Capita API, but I digress).<\/p>\n<p>A few people have forked my code, for whatever reasons, I would just point out that the most up-to-date fork is <strong>80<\/strong> commits behind mine. That&#8217;s a fair amount of work that missing from those forks.<\/p>\n<p>Anyway, hopefully you&#8217;ve found it useful whilst it last.<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Thu, 06 Oct 2016 11:36:10 +0000","created_by":1,"updated_at":"Thu, 06 Oct 2016 11:36:10 +0000","updated_by":1,"published_at":"Thu, 06 Oct 2016 11:36:10 +0000","published_by":1},{"id":884,"title":"Comments","slug":"comments","markdown":"\nOne of the annoying things about working with multiple languages is they each have their differences \u2013 obviously, otherwise there would only be 1 language! Although there is good reason to have these differences they still have elements that are a pain. One of the most annoying things, other then \u201cdo you require a semicolon at the end of the statement?\u201d is comments. Comments aren\u2019t executed or complied but they help developers read code. Remember, the code is a interpretive language, its designed to be gateway between the machines and humans, if you write something complex your more then likely need to be include more comments explain what it does or look at refactoring so other developers can continue your work.\n\nThe few options are:\n\n**Double dash (\u2013)**\n\n> \u2014 Single line quote\n\n**Single Hash (#)**\n\n> # Single line quote\n\n**Double forward-slash (\/\/)**\n\n> \/\/ string domain = \u201cmatt40k.uk\u201d;\n\nAll of these are single line quotes, as in each line needs the require comment and the comment continues till the end of the line \\ carriage break.\n\nYou also got:\n\n**Forward-slash and asterisk (\/*) **\n\n> \/* Multi-Line  \n>  quote *\/\n\nForward-slash and asterisk marks (**\/***) the start of the comment, the comment continues until the asterisk marks and Backward-slash (***\/**). The code must close any open\u00a0Forward-slash and asterisk marks (**\/***) comments in order to compile.\n\nWith\u00a0Forward-slash and asterisk, you can comment in-line, for example\n\n> Select * from \/* Change the code to the right *\/ sys.tables\n\nThis is valid T-SQL that will return the all the columns for meta data about tables on the selected database\n\nYou can also use this across multiple lines, for example\n\n> select\n> \n> TableSchema = schema_name(schema_id)\n> \n> ,TableName = name\n> \n> \/*  \n>  You could also add\n> \n> other tables\n> \n> \u00a0\n> \n> *\/  \n>  from\n> \n> sys.tables\n\n\u00a0\n\n**Power Query Formula (M) Language**\n\nDouble dash (\u2013) **No**  \n Single hash (#) **Yes**  \n Double forward-slash (\/\/)\u00a0**No**  \n Forward-slash and asterisk (\/*) **Yes**\n\n**Transact-SQL (TSQL)**\n\nDouble dash (\u2013) **Yes**  \n Single hash (#) **No**  \n Double forward-slash (\/\/)\u00a0**No**  \n Forward-slash and asterisk (\/*) **Yes**\n\n**C sharp (C#)**\n\nDouble dash (\u2013) **No**  \n Single hash (#) **No**  \n Double forward-slash (\/\/)\u00a0**Yes**  \n Forward-slash and asterisk (\/*) **Yes**\n\n\u00a0\n\nFun fact, my most commonly used comment?\n\n**To-Do**\n\n\n","html":"<p>One of the annoying things about working with multiple languages is they each have their differences &#8211; obviously, otherwise there would only be 1 language! Although there is good reason to have these differences they still have elements that are a pain. One of the most annoying things, other then &#8220;do you require a semicolon at the end of the statement?&#8221; is comments. Comments aren&#8217;t executed or complied but they help developers read code. Remember, the code is a interpretive language, its designed to be gateway between the machines and humans, if you write something complex your more then likely need to be include more comments explain what it does or look at refactoring so other developers can continue your work.<\/p>\n<p>The few options are:<\/p>\n<p><strong>Double dash (&#8211;)<\/strong><\/p>\n<blockquote><p>&#8212; Single line quote<\/p><\/blockquote>\n<p><strong>Single Hash (#)<\/strong><\/p>\n<blockquote><p># Single line quote<\/p><\/blockquote>\n<p><b>Double forward-slash (\/\/)<\/b><\/p>\n<blockquote><p>\/\/ string domain = &#8220;matt40k.uk&#8221;;<\/p><\/blockquote>\n<p>All of these are single line quotes, as in each line needs the require comment and the comment continues till the end of the line \\ carriage break.<\/p>\n<p>You also got:<\/p>\n<p><strong>Forward-slash and asterisk (\/*) <\/strong><\/p>\n<blockquote><p>\/* Multi-Line<br \/>\nquote *\/<\/p><\/blockquote>\n<p>Forward-slash and asterisk marks (<strong>\/*<\/strong>) the start of the comment, the comment continues until the asterisk marks and Backward-slash (<strong>*\/<\/strong>). The code must close any open&nbsp;Forward-slash and asterisk marks (<strong>\/*<\/strong>) comments in order to compile.<\/p>\n<p>With&nbsp;Forward-slash and asterisk, you can comment in-line, for example<\/p>\n<blockquote><p>Select * from \/* Change the code to the right *\/ sys.tables<\/p><\/blockquote>\n<p>This is valid T-SQL that will return the all the columns for meta data about tables on the selected database<\/p>\n<p>You can also use this across multiple lines, for example<\/p>\n<blockquote><p>select<\/p>\n<p>TableSchema = schema_name(schema_id)<\/p>\n<p>,TableName = name<\/p>\n<p>\/*<br \/>\nYou could also add<\/p>\n<p>other tables<\/p>\n<p>&nbsp;<\/p>\n<p>*\/<br \/>\nfrom<\/p>\n<p>sys.tables<\/p><\/blockquote>\n<p>&nbsp;<\/p>\n<p><strong>Power Query Formula (M) Language<\/strong><\/p>\n<p>Double dash (&#8211;) <strong>No<\/strong><br \/>\nSingle hash (#) <strong>Yes<\/strong><br \/>\nDouble forward-slash (\/\/)&nbsp;<strong>No<\/strong><br \/>\nForward-slash and asterisk (\/*) <strong>Yes<\/strong><\/p>\n<p><strong>Transact-SQL (TSQL)<\/strong><\/p>\n<p>Double dash (&#8211;) <strong>Yes<\/strong><br \/>\nSingle hash (#) <strong>No<\/strong><br \/>\nDouble forward-slash (\/\/)&nbsp;<strong>No<\/strong><br \/>\nForward-slash and asterisk (\/*) <strong>Yes<\/strong><\/p>\n<p><strong>C sharp (C#)<\/strong><\/p>\n<p>Double dash (&#8211;) <strong>No<\/strong><br \/>\nSingle hash (#) <strong>No<\/strong><br \/>\nDouble forward-slash (\/\/)&nbsp;<strong>Yes<\/strong><br \/>\nForward-slash and asterisk (\/*) <strong>Yes<\/strong><\/p>\n<p>&nbsp;<\/p>\n<p>Fun fact, my most commonly used comment?<\/p>\n<p><strong>To-Do<\/strong><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Sun, 16 Oct 2016 22:48:13 +0000","created_by":1,"updated_at":"Mon, 17 Oct 2016 07:51:19 +0000","updated_by":1,"published_at":"Sun, 16 Oct 2016 22:48:13 +0000","published_by":1},{"id":897,"title":"Microsoft SQL Server on Linux","slug":"microsoft-sql-server-on-linux","markdown":"\nThis is absolutely amazing, Microsoft, running SQL Server, in Linux Redhat (RHEL)!\n\n<iframe allowfullscreen=\"\" frameborder=\"0\" height=\"720\" src=\"https:\/\/channel9.msdn.com\/Shows\/Data-Exposed\/More-with-SQL-Server-on-Linux\/player\" width=\"1280\"><\/iframe>\n\n\n","html":"<p>This is absolutely amazing, Microsoft, running SQL Server, in Linux Redhat (RHEL)!<\/p>\n<p><iframe src=\"https:\/\/channel9.msdn.com\/Shows\/Data-Exposed\/More-with-SQL-Server-on-Linux\/player\" width=\"1280\" height=\"720\" allowFullScreen frameBorder=\"0\"><\/iframe><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Fri, 11 Nov 2016 14:54:29 +0000","created_by":1,"updated_at":"Fri, 11 Nov 2016 14:54:54 +0000","updated_by":1,"published_at":"Fri, 11 Nov 2016 14:54:29 +0000","published_by":1},{"id":900,"title":"Dangers of distribution lists","slug":"dangers-of-distribution-lists","markdown":"\nDistribution list are amazing things, they allow us to send mail to our team without having to remember who exactly is in our team, this is especial true in this modern age where we are part of many different teams, sometimes without even realising. These lists can contain hundreds or even thousands of members and the latest NHS IT\u00a0bug has left IT departments maybe wanting to double-check their distribution lists \u2013 hopefully before\u00a0the security team comes a knocking.\n\n> NHS 850k reply-all email fail: State health service blames Accenture for config cockup < by me [https:\/\/t.co\/TZ1AOqsdKC](https:\/\/t.co\/TZ1AOqsdKC)\n> \n> \u2014 Gareth Corfield (@GazTheJourno) [November 15, 2016](https:\/\/twitter.com\/GazTheJourno\/status\/798494144062689280)\n\n<script async=\"\" charset=\"utf-8\" src=\"\/\/platform.twitter.com\/widgets.js\"><\/script>\n\nLuckily, this is really easy in Excel 2016. Built into Excel 2016 is PowerQuery and one of the out-of-box connectors is Active Directory. With a bit of PowerQuery magic, you can easily pull this data out.\n\nSo we want to:\n\n- Connect to our Active Directory\n- List out all our Groups\n- Filter to email-able Groups\n- Include - the group owner\n- the members\n- any security \\ restrictions on who can email the list\n\nNote: If your unluckily enough to be running an old version of Excel, it possible to do the same thing in [Power BI Desktop](https:\/\/powerbi.microsoft.com\/en-us\/), which is a [free download](https:\/\/powerbi.microsoft.com\/en-us\/).\n\nBelow is the M code to do this:\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/ad9aa51201e73f112e790655fb90049a.json\"><\/div>[For more help on how to enter the M code into Excel see my previous post.](https:\/\/matt40k.uk\/2016\/06\/getting-a-list-of-ad-groups-and-their-members-using-powerquery\/)\n\nI\u2019ll update this post later with a few useful DAX calculations and hopefully a useful template (both\u00a0Excel file and a sexy PowerBI report)\u00a0\u2013 *the later will take a while as I have to build a test VM.*\n\n\n","html":"<p>Distribution list are amazing things, they allow us to send mail to our team without having to remember who exactly is in our team, this is especial true in this modern age where we are part of many different teams, sometimes without even realising. These lists can contain hundreds or even thousands of members and the latest NHS IT\u00a0bug has left IT departments maybe wanting to double-check their distribution lists &#8211; hopefully before\u00a0the security team comes a knocking.<\/p>\n<blockquote class=\"twitter-tweet\" data-width=\"550\">\n<p lang=\"en\" dir=\"ltr\">NHS 850k reply-all email fail: State health service blames Accenture for config cockup &lt; by me <a href=\"https:\/\/t.co\/TZ1AOqsdKC\" target=\"_blank\" rel=\"nofollow\">https:\/\/t.co\/TZ1AOqsdKC<\/a><\/p>\n<p>&mdash; Gareth Corfield (@GazTheJourno) <a href=\"https:\/\/twitter.com\/GazTheJourno\/status\/798494144062689280\" target=\"_blank\" rel=\"nofollow\">November 15, 2016<\/a><\/p><\/blockquote>\n<p><script async src=\"\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>Luckily, this is really easy in Excel 2016. Built into Excel 2016 is PowerQuery and one of the out-of-box connectors is Active Directory. With a bit of PowerQuery magic, you can easily pull this data out.<\/p>\n<p>So we want to:<\/p>\n<ul>\n<li>Connect to our Active Directory<\/li>\n<li>List out all our Groups<\/li>\n<li>Filter to email-able Groups<\/li>\n<li>Include\n<ul>\n<li>the group owner<\/li>\n<li>the members<\/li>\n<li>any security \\ restrictions on who can email the list<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<p>Note: If your unluckily enough to be running an old version of Excel, it possible to do the same thing in <a href=\"https:\/\/powerbi.microsoft.com\/en-us\/\" target=\"_blank\" rel=\"nofollow\">Power BI Desktop<\/a>, which is a <a href=\"https:\/\/powerbi.microsoft.com\/en-us\/\" target=\"_blank\" rel=\"nofollow\">free download<\/a>.<\/p>\n<p>Below is the M code to do this:<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/ad9aa51201e73f112e790655fb90049a.json\"><\/div>\n<p><a href=\"https:\/\/matt40k.uk\/2016\/06\/getting-a-list-of-ad-groups-and-their-members-using-powerquery\/\">For more help on how to enter the M code into Excel see my previous post.<\/a><\/p>\n<p>I&#8217;ll update this post later with a few useful DAX calculations and hopefully a useful template (both\u00a0Excel file and a sexy PowerBI report)\u00a0&#8211; <em>the later will take a while as I have to build a test VM.<\/em><\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Tue, 15 Nov 2016 23:23:15 +0000","created_by":1,"updated_at":"Tue, 15 Nov 2016 23:23:15 +0000","updated_by":1,"published_at":"Tue, 15 Nov 2016 23:23:15 +0000","published_by":1},{"id":939,"title":"Pretty time","slug":"pretty-time","markdown":"\nThis week I\u2019ve been working on another new cube which had the time spent, which is in minutes. To pretty it up it wanted to be in days, mins and hours.\n\nHere is a simplified version of the final output\n\n[![prettytime](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/11\/prettytime.png?fit=266%2C38&ssl=1)](https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/11\/prettytime.png?ssl=1)\n\nand the hopefully easier to understand MDX code\n\n<style>.gist table { margin-bottom: 0; }<\/style><div class=\"gist-oembed\" data-gist=\"matt40k\/b45d73245d88405c06722d65e1a0bdfe.json\"><\/div>Adding the days option isn\u2019t much more work \u2013 it does however make the code\u00a0look alot more angry. Also you have the issue of what is a day \u2013 is it 24 hours? Is it the working hours, or is it less, is it the realistic billable time after you deduce admin time?\n\n\n","html":"<p>This week I&#8217;ve been working on another new cube which had the time spent, which is in minutes. To pretty it up it wanted to be in days, mins and hours.<\/p>\n<p>Here is a simplified version of the final output<\/p>\n<p><a href=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/11\/prettytime.png?ssl=1\"><img class=\"alignnone size-full wp-image-948\" src=\"https:\/\/i1.wp.com\/matt40k.uk\/wp-content\/uploads\/2016\/11\/prettytime.png?fit=266%2C38&#038;ssl=1\" alt=\"prettytime\" data-recalc-dims=\"1\" \/><\/a><\/p>\n<p>and the hopefully easier to understand MDX code<\/p>\n<style>.gist table { margin-bottom: 0; }<\/style>\n<div class=\"gist-oembed\" data-gist=\"matt40k\/b45d73245d88405c06722d65e1a0bdfe.json\"><\/div>\n<p>Adding the days option isn&#8217;t much more work &#8211; it does however make the code\u00a0look alot more angry. Also you have the issue of what is a day &#8211; is it 24 hours? Is it the working hours, or is it less, is it the realistic billable time after you deduce admin time?<\/p>\n","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"Wed, 30 Nov 2016 22:17:23 +0000","created_by":1,"updated_at":"Wed, 30 Nov 2016 22:17:23 +0000","updated_by":1,"published_at":"Wed, 30 Nov 2016 22:17:23 +0000","published_by":1}],"tags":[{"id":53,"name":"Active Directory","slug":"active-directory","description":""},{"id":21,"name":"Advise","slug":"advise","description":"Blog posts where I try to give advise."},{"id":43,"name":"API","slug":"api","description":""},{"id":41,"name":"bing","slug":"bing","description":""},{"id":50,"name":"bug","slug":"bug","description":""},{"id":34,"name":"C#","slug":"csharp","description":"C#"},{"id":46,"name":"Cambridge","slug":"cambridge","description":""},{"id":52,"name":"Comments","slug":"comments","description":""},{"id":49,"name":"Connect","slug":"connect","description":""},{"id":47,"name":"East Anglia","slug":"east-anglia","description":""},{"id":39,"name":"Geospatial","slug":"geospatial","description":""},{"id":42,"name":"google","slug":"google","description":""},{"id":22,"name":"IPv6","slug":"ipv6","description":""},{"id":36,"name":"M","slug":"m","description":""},{"id":40,"name":"machine learning","slug":"machine-learning","description":""},{"id":31,"name":"MDX","slug":"mdx","description":"MultiDimensional eXpressions"},{"id":48,"name":"MSDN","slug":"msdn","description":""},{"id":37,"name":"OpenData","slug":"opendata","description":""},{"id":44,"name":"PASS","slug":"pass","description":""},{"id":30,"name":"Power BI","slug":"powerbi","description":"Power BI is a cloud-based business analytics service"},{"id":35,"name":"PowerQuery","slug":"powerquery","description":""},{"id":23,"name":"PowerShell","slug":"powershell","description":""},{"id":24,"name":"Rant","slug":"rant","description":"My ranting posts"},{"id":51,"name":"SQLPrompt","slug":"sqlprompt","description":""},{"id":45,"name":"SQLSaturday","slug":"sqlsaturday","description":""},{"id":33,"name":"T-SQL","slug":"tsql","description":"Transact-SQL"},{"id":25,"name":"Vision","slug":"vision","description":"My visionary blog posts"},{"id":38,"name":"xml","slug":"xml","description":""}],"posts_tags":[{"tag_id":21,"post_id":18},{"tag_id":25,"post_id":31},{"tag_id":21,"post_id":61},{"tag_id":21,"post_id":87},{"tag_id":24,"post_id":87},{"tag_id":24,"post_id":123},{"tag_id":33,"post_id":134},{"tag_id":23,"post_id":151},{"tag_id":22,"post_id":232},{"tag_id":37,"post_id":238},{"tag_id":37,"post_id":374},{"tag_id":33,"post_id":380},{"tag_id":34,"post_id":478},{"tag_id":33,"post_id":487},{"tag_id":23,"post_id":503},{"tag_id":33,"post_id":524},{"tag_id":39,"post_id":529},{"tag_id":37,"post_id":529},{"tag_id":33,"post_id":529},{"tag_id":38,"post_id":557},{"tag_id":33,"post_id":673},{"tag_id":33,"post_id":739},{"tag_id":30,"post_id":746},{"tag_id":34,"post_id":768},{"tag_id":37,"post_id":780},{"tag_id":36,"post_id":782},{"tag_id":30,"post_id":782},{"tag_id":35,"post_id":782},{"tag_id":41,"post_id":837},{"tag_id":42,"post_id":837},{"tag_id":40,"post_id":837},{"tag_id":43,"post_id":846},{"tag_id":37,"post_id":846},{"tag_id":46,"post_id":849},{"tag_id":47,"post_id":849},{"tag_id":44,"post_id":849},{"tag_id":45,"post_id":849},{"tag_id":50,"post_id":854},{"tag_id":49,"post_id":854},{"tag_id":48,"post_id":854},{"tag_id":51,"post_id":858},{"tag_id":33,"post_id":858},{"tag_id":34,"post_id":884},{"tag_id":52,"post_id":884},{"tag_id":36,"post_id":884},{"tag_id":35,"post_id":884},{"tag_id":23,"post_id":884},{"tag_id":33,"post_id":884},{"tag_id":53,"post_id":900},{"tag_id":35,"post_id":900},{"tag_id":31,"post_id":939}],"users":[{"id":1,"slug":"matt","bio":false,"website":"https:\/\/matt40k.uk","created_at":"Sun, 22 Feb 2015 02:28:51 +0000","created_by":1,"email":"matt@matt40k.uk","name":"matt"}]},"meta":{"exported_on":"Sat, 07 Jan 2017 15:28:44 +0000","version":"000"}}